{"cells":[{"cell_type":"markdown","metadata":{"id":"xZ0IEwYcRzAl"},"source":["# Requirements"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1686623214646,"user":{"displayName":"Antonio Santos","userId":"03265893617080544823"},"user_tz":180},"id":"NI4_17gjk3dU","outputId":"0c7359f4-6347-4e78-bc11-67d523107e5f"},"outputs":[{"name":"stdout","output_type":"stream","text":["1\n"]}],"source":["print(1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k-JXF71-k4O3"},"outputs":[],"source":["#import os\n","#os.kill(os.getpid(), 9)"]},{"cell_type":"markdown","metadata":{"id":"TlRP-duNXnpK"},"source":["## Iniciation"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28287,"status":"ok","timestamp":1686744562943,"user":{"displayName":"Antonio Santos","userId":"03265893617080544823"},"user_tz":180},"id":"iCeN-zCbXqfV","outputId":"7d2d11b2-b7df-45c1-ba0c-4005ce1959c5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":102874,"status":"ok","timestamp":1686744665812,"user":{"displayName":"Antonio Santos","userId":"03265893617080544823"},"user_tz":180},"id":"uOyfTgUDztSD","outputId":"4fd718f9-850d-4ab3-aa51-dafc489ba869"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found existing installation: torch 2.0.1+cu118\n","Uninstalling torch-2.0.1+cu118:\n","  Successfully uninstalled torch-2.0.1+cu118\n","Found existing installation: torchvision 0.15.2+cu118\n","Uninstalling torchvision-0.15.2+cu118:\n","  Successfully uninstalled torchvision-0.15.2+cu118\n","Found existing installation: torchaudio 2.0.2+cu118\n","Uninstalling torchaudio-2.0.2+cu118:\n","  Successfully uninstalled torchaudio-2.0.2+cu118\n","Looking in indexes: https://download.pytorch.org/whl/cu118, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torch\n","  Downloading https://download.pytorch.org/whl/cu118/torch-2.0.1%2Bcu118-cp310-cp310-linux_x86_64.whl (2267.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m927.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchvision\n","  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.15.2%2Bcu118-cp310-cp310-linux_x86_64.whl (6.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m108.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchaudio\n","  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.0.2%2Bcu118-cp310-cp310-linux_x86_64.whl (4.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-\u003etorch) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-\u003etorch) (16.0.5)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1)\n","Requirement already satisfied: pillow!=8.3.*,\u003e=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (8.4.0)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-\u003etorch) (2.1.2)\n","Requirement already satisfied: urllib3\u003c1.27,\u003e=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etorchvision) (1.26.15)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etorchvision) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etorchvision) (2.0.12)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etorchvision) (3.4)\n","Requirement already satisfied: mpmath\u003e=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy-\u003etorch) (1.3.0)\n","Installing collected packages: torch, torchvision, torchaudio\n","Successfully installed torch-2.0.1+cu118 torchaudio-2.0.2+cu118 torchvision-0.15.2+cu118\n"]}],"source":["!pip uninstall torch torchvision torchaudio -y\n","!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1686744665813,"user":{"displayName":"Antonio Santos","userId":"03265893617080544823"},"user_tz":180},"id":"dSxd1Sjk6_2a","outputId":"fb94c17a-925d-4075-a458-bb45ae7b4e54"},"outputs":[{"name":"stdout","output_type":"stream","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2022 NVIDIA Corporation\n","Built on Wed_Sep_21_10:33:58_PDT_2022\n","Cuda compilation tools, release 11.8, V11.8.89\n","Build cuda_11.8.r11.8/compiler.31833905_0\n"]}],"source":["!nvcc --version"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2192,"status":"ok","timestamp":1686744668000,"user":{"displayName":"Antonio Santos","userId":"03265893617080544823"},"user_tz":180},"id":"K0WhAIMi0KX1","outputId":"0ca9826e-5a68-4421-dd87-6e4e7970b21d"},"outputs":[{"name":"stdout","output_type":"stream","text":["2.0.1+cu118\n"]}],"source":["import torch\n","print(torch.__version__)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":552,"status":"ok","timestamp":1686744668550,"user":{"displayName":"Antonio Santos","userId":"03265893617080544823"},"user_tz":180},"id":"ejMJGR8w0nmM","outputId":"f2097ad6-3b82-446f-b42a-4ead1a5008c6"},"outputs":[{"name":"stdout","output_type":"stream","text":["absl-py==1.4.0\n","alabaster==0.7.13\n","albumentations==1.2.1\n","altair==4.2.2\n","anyio==3.6.2\n","appdirs==1.4.4\n","argon2-cffi==21.3.0\n","argon2-cffi-bindings==21.2.0\n","array-record==0.2.0\n","arviz==0.15.1\n","astropy==5.2.2\n","astunparse==1.6.3\n","attrs==23.1.0\n","audioread==3.0.0\n","autograd==1.5\n","Babel==2.12.1\n","backcall==0.2.0\n","beautifulsoup4==4.11.2\n","bleach==6.0.0\n","blis==0.7.9\n","blosc2==2.0.0\n","bokeh==2.4.3\n","branca==0.6.0\n","build==0.10.0\n","CacheControl==0.12.11\n","cached-property==1.5.2\n","cachetools==5.3.0\n","catalogue==2.0.8\n","certifi==2022.12.7\n","cffi==1.15.1\n","chardet==4.0.0\n","charset-normalizer==2.0.12\n","chex==0.1.7\n","click==8.1.3\n","cloudpickle==2.2.1\n","cmake==3.25.2\n","cmdstanpy==1.1.0\n","colorcet==3.0.1\n","colorlover==0.3.0\n","community==1.0.0b1\n","confection==0.0.4\n","cons==0.4.5\n","contextlib2==0.6.0.post1\n","contourpy==1.0.7\n","convertdate==2.4.0\n","cryptography==40.0.2\n","cufflinks==0.17.3\n","cupy-cuda11x==11.0.0\n","cvxopt==1.3.0\n","cvxpy==1.3.1\n","cycler==0.11.0\n","cymem==2.0.7\n","Cython==0.29.34\n","dask==2022.12.1\n","datascience==0.17.6\n","db-dtypes==1.1.1\n","dbus-python==1.2.16\n","debugpy==1.6.6\n","decorator==4.4.2\n","defusedxml==0.7.1\n","distributed==2022.12.1\n","dlib==19.24.1\n","dm-tree==0.1.8\n","docutils==0.16\n","dopamine-rl==4.0.6\n","duckdb==0.7.1\n","earthengine-api==0.1.350\n","easydict==1.10\n","ecos==2.0.12\n","editdistance==0.6.2\n","en-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl#sha256=0964370218b7e1672a30ac50d72cdc6b16f7c867496f1d60925691188f4d2510\n","entrypoints==0.4\n","ephem==4.1.4\n","et-xmlfile==1.1.0\n","etils==1.2.0\n","etuples==0.3.8\n","exceptiongroup==1.1.1\n","fastai==2.7.12\n","fastcore==1.5.29\n","fastdownload==0.0.7\n","fastjsonschema==2.16.3\n","fastprogress==1.0.3\n","fastrlock==0.8.1\n","filelock==3.12.0\n","firebase-admin==5.3.0\n","Flask==2.2.4\n","flatbuffers==23.3.3\n","flax==0.6.9\n","folium==0.14.0\n","fonttools==4.39.3\n","frozendict==2.3.7\n","fsspec==2023.4.0\n","future==0.18.3\n","gast==0.4.0\n","GDAL==3.3.2\n","gdown==4.6.6\n","gensim==4.3.1\n","geographiclib==2.0\n","geopy==2.3.0\n","gin-config==0.5.0\n","glob2==0.7\n","google==2.0.3\n","google-api-core==2.11.0\n","google-api-python-client==2.84.0\n","google-auth==2.17.3\n","google-auth-httplib2==0.1.0\n","google-auth-oauthlib==1.0.0\n","google-cloud-bigquery==3.9.0\n","google-cloud-bigquery-storage==2.19.1\n","google-cloud-core==2.3.2\n","google-cloud-datastore==2.15.1\n","google-cloud-firestore==2.11.0\n","google-cloud-language==2.9.1\n","google-cloud-storage==2.8.0\n","google-cloud-translate==3.11.1\n","google-colab @ file:///colabtools/dist/google-colab-1.0.0.tar.gz#sha256=70a96627d58c4e40efb1a3f3c9c7a7099adf3699a83d4a633f21c7a54bd0c212\n","google-crc32c==1.5.0\n","google-pasta==0.2.0\n","google-resumable-media==2.5.0\n","googleapis-common-protos==1.59.0\n","googledrivedownloader==0.4\n","graphviz==0.20.1\n","greenlet==2.0.2\n","grpcio==1.54.0\n","grpcio-status==1.48.2\n","gspread==3.4.2\n","gspread-dataframe==3.0.8\n","gym==0.25.2\n","gym-notices==0.0.8\n","h5netcdf==1.1.0\n","h5py==3.8.0\n","holidays==0.25\n","holoviews==1.15.4\n","html5lib==1.1\n","httpimport==1.3.0\n","httplib2==0.21.0\n","humanize==4.6.0\n","hyperopt==0.2.7\n","idna==3.4\n","imageio==2.25.1\n","imageio-ffmpeg==0.4.8\n","imagesize==1.4.1\n","imbalanced-learn==0.10.1\n","imgaug==0.4.0\n","importlib-resources==5.12.0\n","imutils==0.5.4\n","inflect==6.0.4\n","iniconfig==2.0.0\n","intel-openmp==2023.1.0\n","ipykernel==5.5.6\n","ipython==7.34.0\n","ipython-genutils==0.2.0\n","ipython-sql==0.4.1\n","ipywidgets==7.7.1\n","itsdangerous==2.1.2\n","jax==0.4.10\n","jaxlib @ https://storage.googleapis.com/jax-releases/cuda11/jaxlib-0.4.10+cuda11.cudnn86-cp310-cp310-manylinux2014_x86_64.whl#sha256=fe53205ef12727c80ed5ac2d4506d6732c0c3db69ede4565a7d4df98e609af84\n","jieba==0.42.1\n","Jinja2==3.1.2\n","joblib==1.2.0\n","jsonpickle==3.0.1\n","jsonschema==4.3.3\n","jupyter-client==6.1.12\n","jupyter-console==6.1.0\n","jupyter-server==1.24.0\n","jupyter_core==5.3.0\n","jupyterlab-pygments==0.2.2\n","jupyterlab-widgets==3.0.7\n","kaggle==1.5.13\n","keras==2.12.0\n","kiwisolver==1.4.4\n","korean-lunar-calendar==0.3.1\n","langcodes==3.3.0\n","lazy_loader==0.2\n","libclang==16.0.0\n","librosa==0.10.0.post2\n","lightgbm==3.3.5\n","lit==16.0.5\n","llvmlite==0.39.1\n","locket==1.0.0\n","logical-unification==0.4.5\n","LunarCalendar==0.0.9\n","lxml==4.9.2\n","Markdown==3.4.3\n","markdown-it-py==2.2.0\n","MarkupSafe==2.1.2\n","matplotlib==3.7.1\n","matplotlib-inline==0.1.6\n","matplotlib-venn==0.11.9\n","mdurl==0.1.2\n","miniKanren==1.0.3\n","missingno==0.5.2\n","mistune==0.8.4\n","mizani==0.8.1\n","mkl==2019.0\n","ml-dtypes==0.1.0\n","mlxtend==0.14.0\n","more-itertools==9.1.0\n","moviepy==1.0.3\n","mpmath==1.3.0\n","msgpack==1.0.5\n","multipledispatch==0.6.0\n","multitasking==0.0.11\n","murmurhash==1.0.9\n","music21==8.1.0\n","natsort==8.3.1\n","nbclient==0.7.4\n","nbconvert==6.5.4\n","nbformat==5.8.0\n","nest-asyncio==1.5.6\n","networkx==3.1\n","nibabel==3.0.2\n","nltk==3.8.1\n","notebook==6.4.8\n","numba==0.56.4\n","numexpr==2.8.4\n","numpy==1.22.4\n","oauth2client==4.1.3\n","oauthlib==3.2.2\n","opencv-contrib-python==4.7.0.72\n","opencv-python==4.7.0.72\n","opencv-python-headless==4.7.0.72\n","openpyxl==3.0.10\n","opt-einsum==3.3.0\n","optax==0.1.5\n","orbax-checkpoint==0.2.1\n","osqp==0.6.2.post8\n","packaging==23.1\n","palettable==3.3.3\n","pandas==1.5.3\n","pandas-datareader==0.10.0\n","pandas-gbq==0.17.9\n","pandocfilters==1.5.0\n","panel==0.14.4\n","param==1.13.0\n","parso==0.8.3\n","partd==1.4.0\n","pathlib==1.0.1\n","pathy==0.10.1\n","patsy==0.5.3\n","pexpect==4.8.0\n","pickleshare==0.7.5\n","Pillow==8.4.0\n","pip-tools==6.13.0\n","platformdirs==3.3.0\n","plotly==5.13.1\n","plotnine==0.10.1\n","pluggy==1.0.0\n","polars==0.17.3\n","pooch==1.6.0\n","portpicker==1.3.9\n","prefetch-generator==1.0.3\n","preshed==3.0.8\n","prettytable==0.7.2\n","proglog==0.1.10\n","progressbar2==4.2.0\n","prometheus-client==0.16.0\n","promise==2.3\n","prompt-toolkit==3.0.38\n","prophet==1.1.3\n","proto-plus==1.22.2\n","protobuf==3.20.3\n","psutil==5.9.5\n","psycopg2==2.9.6\n","ptyprocess==0.7.0\n","py-cpuinfo==9.0.0\n","py4j==0.10.9.7\n","pyarrow==9.0.0\n","pyasn1==0.5.0\n","pyasn1-modules==0.3.0\n","pycocotools==2.0.6\n","pycparser==2.21\n","pyct==0.5.0\n","pydantic==1.10.7\n","pydata-google-auth==1.7.0\n","pydot==1.4.2\n","pydot-ng==2.0.0\n","pydotplus==2.0.2\n","PyDrive==1.3.1\n","pyerfa==2.0.0.3\n","pygame==2.3.0\n","Pygments==2.14.0\n","PyGObject==3.36.0\n","pymc==5.1.2\n","PyMeeus==0.5.12\n","pymystem3==0.2.0\n","PyOpenGL==3.1.6\n","pyparsing==3.0.9\n","pyproject_hooks==1.0.0\n","pyrsistent==0.19.3\n","PySocks==1.7.1\n","pytensor==2.10.1\n","pytest==7.2.2\n","python-apt==0.0.0\n","python-dateutil==2.8.2\n","python-louvain==0.16\n","python-slugify==8.0.1\n","python-utils==3.5.2\n","pytz==2022.7.1\n","pytz-deprecation-shim==0.1.0.post0\n","pyviz-comms==2.2.1\n","PyWavelets==1.4.1\n","PyYAML==6.0\n","pyzmq==23.2.1\n","qdldl==0.1.7\n","qudida==0.0.4\n","regex==2022.10.31\n","requests==2.27.1\n","requests-oauthlib==1.3.1\n","requests-unixsocket==0.2.0\n","requirements-parser==0.5.0\n","rich==13.3.4\n","rpy2==3.5.5\n","rsa==4.9\n","scikit-image==0.19.3\n","scikit-learn==1.2.2\n","scipy==1.10.1\n","scs==3.2.3\n","seaborn==0.12.2\n","Send2Trash==1.8.0\n","shapely==2.0.1\n","six==1.16.0\n","sklearn-pandas==2.2.0\n","smart-open==6.3.0\n","sniffio==1.3.0\n","snowballstemmer==2.2.0\n","sortedcontainers==2.4.0\n","soundfile==0.12.1\n","soupsieve==2.4.1\n","soxr==0.3.5\n","spacy==3.5.2\n","spacy-legacy==3.0.12\n","spacy-loggers==1.0.4\n","Sphinx==3.5.4\n","sphinxcontrib-applehelp==1.0.4\n","sphinxcontrib-devhelp==1.0.2\n","sphinxcontrib-htmlhelp==2.0.1\n","sphinxcontrib-jsmath==1.0.1\n","sphinxcontrib-qthelp==1.0.3\n","sphinxcontrib-serializinghtml==1.1.5\n","SQLAlchemy==2.0.10\n","sqlparse==0.4.4\n","srsly==2.4.6\n","statsmodels==0.13.5\n","sympy==1.11.1\n","tables==3.8.0\n","tabulate==0.8.10\n","tblib==1.7.0\n","tenacity==8.2.2\n","tensorboard==2.12.2\n","tensorboard-data-server==0.7.0\n","tensorboard-plugin-wit==1.8.1\n","tensorflow==2.12.0\n","tensorflow-datasets==4.9.2\n","tensorflow-estimator==2.12.0\n","tensorflow-gcs-config==2.12.0\n","tensorflow-hub==0.13.0\n","tensorflow-io-gcs-filesystem==0.32.0\n","tensorflow-metadata==1.13.1\n","tensorflow-probability==0.20.1\n","tensorstore==0.1.36\n","termcolor==2.3.0\n","terminado==0.17.1\n","text-unidecode==1.3\n","textblob==0.17.1\n","tf-slim==1.1.0\n","thinc==8.1.9\n","threadpoolctl==3.1.0\n","tifffile==2023.4.12\n","tinycss2==1.2.1\n","toml==0.10.2\n","tomli==2.0.1\n","toolz==0.12.0\n","torch==2.0.1+cu118\n","torchaudio==2.0.2+cu118\n","torchdata==0.6.1\n","torchsummary==1.5.1\n","torchtext==0.15.2\n","torchvision==0.15.2+cu118\n","tornado==6.3.1\n","tqdm==4.65.0\n","traitlets==5.7.1\n","triton==2.0.0\n","tweepy==4.13.0\n","typer==0.7.0\n","types-setuptools==67.8.0.0\n","typing_extensions==4.5.0\n","tzdata==2023.3\n","tzlocal==4.3\n","uritemplate==4.1.1\n","urllib3==1.26.15\n","vega-datasets==0.9.0\n","wasabi==1.1.1\n","wcwidth==0.2.6\n","webcolors==1.13\n","webencodings==0.5.1\n","websocket-client==1.5.1\n","Werkzeug==2.3.0\n","widgetsnbextension==3.6.4\n","wordcloud==1.8.2.2\n","wrapt==1.14.1\n","xarray==2022.12.0\n","xarray-einstats==0.5.1\n","xgboost==1.7.5\n","xlrd==2.0.1\n","yellowbrick==1.5\n","yfinance==0.2.18\n","zict==3.0.0\n","zipp==3.15.0\n"]}],"source":["!pip freeze"]},{"cell_type":"markdown","metadata":{"id":"yUSNtuVeTUwl"},"source":["## Optimazer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HZMtCepVRDaJ"},"outputs":[],"source":["# Based on https://github.com/pytorch/pytorch/pull/3740\n","import torch\n","import math\n","\n","\n","class AdamW(torch.optim.Optimizer):\n","    \"\"\"Implements AdamW algorithm.\n","\n","    It has been proposed in `Fixing Weight Decay Regularization in Adam`_.\n","\n","    Arguments:\n","        params (iterable): iterable of parameters to optimize or dicts defining\n","            parameter groups\n","        lr (float, optional): learning rate (default: 1e-3)\n","        betas (Tuple[float, float], optional): coefficients used for computing\n","            running averages of gradient and its square (default: (0.9, 0.999))\n","        eps (float, optional): term added to the denominator to improve\n","            numerical stability (default: 1e-8)\n","        weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n","\n","    .. Fixing Weight Decay Regularization in Adam:\n","    https://arxiv.org/abs/1711.05101\n","    \"\"\"\n","\n","    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8,\n","                 weight_decay=0):\n","        defaults = dict(lr=lr, betas=betas, eps=eps,\n","                        weight_decay=weight_decay)\n","        super(AdamW, self).__init__(params, defaults)\n","\n","    def step(self, closure=None):\n","        \"\"\"Performs a single optimization step.\n","\n","        Arguments:\n","            closure (callable, optional): A closure that reevaluates the model\n","                and returns the loss.\n","        \"\"\"\n","        loss = None\n","        if closure is not None:\n","            loss = closure()\n","\n","        for group in self.param_groups:\n","            for p in group['params']:\n","                if p.grad is None:\n","                    continue\n","                grad = p.grad.data\n","                if grad.is_sparse:\n","                    raise RuntimeError('AdamW does not support sparse gradients, please consider SparseAdam instead')\n","\n","                state = self.state[p]\n","\n","                # State initialization\n","                if len(state) == 0:\n","                    state['step'] = 0\n","                    # Exponential moving average of gradient values\n","                    state['exp_avg'] = torch.zeros_like(p.data)\n","                    # Exponential moving average of squared gradient values\n","                    state['exp_avg_sq'] = torch.zeros_like(p.data)\n","\n","                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n","                beta1, beta2 = group['betas']\n","\n","                state['step'] += 1\n","\n","                # according to the paper, this penalty should come after the bias correction\n","                # if group['weight_decay'] != 0:\n","                #     grad = grad.add(group['weight_decay'], p.data)\n","\n","                # Decay the first and second moment running average coefficient\n","                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n","                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n","\n","                denom = exp_avg_sq.sqrt().add_(group['eps'])\n","\n","                bias_correction1 = 1 - beta1 ** state['step']\n","                bias_correction2 = 1 - beta2 ** state['step']\n","                step_size = group['lr'] * math.sqrt(bias_correction2) / bias_correction1\n","\n","                # w = w - wd * lr * w\n","                if group['weight_decay'] != 0:\n","                    p.data.add_(-group['weight_decay'] * group['lr'], p.data)\n","\n","                # w = w - lr * w.grad\n","                p.data.addcdiv_(-step_size, exp_avg, denom)\n","\n","                # w = w - wd * lr * w - lr * w.grad\n","                # See http://www.fast.ai/2018/07/02/adam-weight-decay/\n","\n","        return loss"]},{"cell_type":"markdown","metadata":{"id":"pTW3yt84TQMf"},"source":["## Losses"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MR5-L7m_SCwH"},"outputs":[],"source":["import numpy as np\n","import torch\n","import torch.nn.functional as F\n","from torch import nn\n","from torch.autograd import Variable\n","\n","try:\n","    from itertools import ifilterfalse\n","except ImportError:  # py3k\n","    from itertools import filterfalse\n","\n","eps = 1e-6\n","\n","def dice_round(preds, trues):\n","    preds = preds.float()\n","    return soft_dice_loss(preds, trues)\n","\n","\n","def iou_round(preds, trues):\n","    preds = preds.float()\n","    return jaccard(preds, trues)\n","\n","\n","def soft_dice_loss(outputs, targets, per_image=False):\n","    batch_size = outputs.size()[0]\n","    if not per_image:\n","        batch_size = 1\n","    dice_target = targets.contiguous().view(batch_size, -1).float()\n","    dice_output = outputs.contiguous().view(batch_size, -1)\n","    intersection = torch.sum(dice_output * dice_target, dim=1)\n","    union = torch.sum(dice_output, dim=1) + torch.sum(dice_target, dim=1) + eps\n","    loss = (1 - (2 * intersection + eps) / union).mean()\n","    return loss\n","\n","\n","def jaccard(outputs, targets, per_image=False):\n","    batch_size = outputs.size()[0]\n","    if not per_image:\n","        batch_size = 1\n","    dice_target = targets.contiguous().view(batch_size, -1).float()\n","    dice_output = outputs.contiguous().view(batch_size, -1)\n","    intersection = torch.sum(dice_output * dice_target, dim=1)\n","    union = torch.sum(dice_output, dim=1) + torch.sum(dice_target, dim=1) - intersection + eps\n","    losses = 1 - (intersection + eps) / union\n","    return losses.mean()\n","\n","\n","class DiceLoss(nn.Module):\n","    def __init__(self, weight=None, size_average=True, per_image=False):\n","        super().__init__()\n","        self.size_average = size_average\n","        self.register_buffer('weight', weight)\n","        self.per_image = per_image\n","\n","    def forward(self, input, target):\n","        return soft_dice_loss(input, target, per_image=self.per_image)\n","\n","\n","class JaccardLoss(nn.Module):\n","    def __init__(self, weight=None, size_average=True, per_image=False):\n","        super().__init__()\n","        self.size_average = size_average\n","        self.register_buffer('weight', weight)\n","        self.per_image = per_image\n","\n","    def forward(self, input, target):\n","        return jaccard(input, target, per_image=self.per_image)\n","\n","\n","class StableBCELoss(nn.Module):\n","    def __init__(self):\n","        super(StableBCELoss, self).__init__()\n","\n","    def forward(self, input, target):\n","        input = input.float().view(-1)\n","        target = target.float().view(-1)\n","        neg_abs = - input.abs()\n","        # todo check correctness\n","        loss = input.clamp(min=0) - input * target + (1 + neg_abs.exp()).log()\n","        return loss.mean()\n","\n","\n","class ComboLoss(nn.Module):\n","    def __init__(self, weights, per_image=False):\n","        super().__init__()\n","        self.weights = weights\n","        self.bce = StableBCELoss()\n","        self.dice = DiceLoss(per_image=False)\n","        self.jaccard = JaccardLoss(per_image=False)\n","        self.lovasz = LovaszLoss(per_image=per_image)\n","        self.lovasz_sigmoid = LovaszLossSigmoid(per_image=per_image)\n","        self.focal = FocalLoss2d()\n","        self.mapping = {'bce': self.bce,\n","                        'dice': self.dice,\n","                        'focal': self.focal,\n","                        'jaccard': self.jaccard,\n","                        'lovasz': self.lovasz,\n","                        'lovasz_sigmoid': self.lovasz_sigmoid}\n","        self.expect_sigmoid = {'dice', 'focal', 'jaccard', 'lovasz_sigmoid'}\n","        self.values = {}\n","\n","    def forward(self, outputs, targets):\n","        loss = 0\n","        weights = self.weights\n","        sigmoid_input = torch.sigmoid(outputs)\n","        for k, v in weights.items():\n","            if not v:\n","                continue\n","            val = self.mapping[k](sigmoid_input if k in self.expect_sigmoid else outputs, targets)\n","            self.values[k] = val\n","            loss += self.weights[k] * val\n","        return loss\n","\n","\n","def lovasz_grad(gt_sorted):\n","    \"\"\"\n","    Computes gradient of the Lovasz extension w.r.t sorted errors\n","    See Alg. 1 in paper\n","    \"\"\"\n","    p = len(gt_sorted)\n","    gts = gt_sorted.sum()\n","    intersection = gts.float() - gt_sorted.float().cumsum(0)\n","    union = gts.float() + (1 - gt_sorted).float().cumsum(0)\n","    jaccard = 1. - intersection / union\n","    if p \u003e 1:  # cover 1-pixel case\n","        jaccard[1:p] = jaccard[1:p] - jaccard[0:-1]\n","    return jaccard\n","\n","\n","def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n","    \"\"\"\n","    Binary Lovasz hinge loss\n","      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n","      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n","      per_image: compute the loss per image instead of per batch\n","      ignore: void class id\n","    \"\"\"\n","    if per_image:\n","        loss = mean(lovasz_hinge_flat(*flatten_binary_scores(log.unsqueeze(0), lab.unsqueeze(0), ignore))\n","                    for log, lab in zip(logits, labels))\n","    else:\n","        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n","    return loss\n","\n","\n","def lovasz_hinge_flat(logits, labels):\n","    \"\"\"\n","    Binary Lovasz hinge loss\n","      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n","      labels: [P] Tensor, binary ground truth labels (0 or 1)\n","      ignore: label to ignore\n","    \"\"\"\n","    if len(labels) == 0:\n","        # only void pixels, the gradients should be 0\n","        return logits.sum() * 0.\n","    signs = 2. * labels.float() - 1.\n","    errors = (1. - logits * Variable(signs))\n","    errors_sorted, perm = torch.sort(errors, dim=0, descending=True)\n","    perm = perm.data\n","    gt_sorted = labels[perm]\n","    grad = lovasz_grad(gt_sorted)\n","    loss = torch.dot(F.relu(errors_sorted), Variable(grad))\n","    return loss\n","\n","\n","def flatten_binary_scores(scores, labels, ignore=None):\n","    \"\"\"\n","    Flattens predictions in the batch (binary case)\n","    Remove labels equal to 'ignore'\n","    \"\"\"\n","    scores = scores.view(-1)\n","    labels = labels.view(-1)\n","    if ignore is None:\n","        return scores, labels\n","    valid = (labels != ignore)\n","    vscores = scores[valid]\n","    vlabels = labels[valid]\n","    return vscores, vlabels\n","\n","\n","def lovasz_sigmoid(probas, labels, per_image=False, ignore=None):\n","    \"\"\"\n","    Multi-class Lovasz-Softmax loss\n","      probas: [B, C, H, W] Variable, class probabilities at each prediction (between 0 and 1)\n","      labels: [B, H, W] Tensor, ground truth labels (between 0 and C - 1)\n","      only_present: average only on classes present in ground truth\n","      per_image: compute the loss per image instead of per batch\n","      ignore: void class labels\n","    \"\"\"\n","    if per_image:\n","        loss = mean(lovasz_sigmoid_flat(*flatten_binary_scores(prob.unsqueeze(0), lab.unsqueeze(0), ignore))\n","                          for prob, lab in zip(probas, labels))\n","    else:\n","        loss = lovasz_sigmoid_flat(*flatten_binary_scores(probas, labels, ignore))\n","    return loss\n","\n","\n","def lovasz_sigmoid_flat(probas, labels):\n","    \"\"\"\n","    Multi-class Lovasz-Softmax loss\n","      probas: [P, C] Variable, class probabilities at each prediction (between 0 and 1)\n","      labels: [P] Tensor, ground truth labels (between 0 and C - 1)\n","      only_present: average only on classes present in ground truth\n","    \"\"\"\n","    fg = labels.float()\n","    errors = (Variable(fg) - probas).abs()\n","    errors_sorted, perm = torch.sort(errors, 0, descending=True)\n","    perm = perm.data\n","    fg_sorted = fg[perm]\n","    loss = torch.dot(errors_sorted, Variable(lovasz_grad(fg_sorted)))\n","    return loss\n","\n","\n","def mean(l, ignore_nan=False, empty=0):\n","    \"\"\"\n","    nanmean compatible with generators.\n","    \"\"\"\n","    l = iter(l)\n","    if ignore_nan:\n","        l = ifilterfalse(np.isnan, l)\n","    try:\n","        n = 1\n","        acc = next(l)\n","    except StopIteration:\n","        if empty == 'raise':\n","            raise ValueError('Empty mean')\n","        return empty\n","    for n, v in enumerate(l, 2):\n","        acc += v\n","    if n == 1:\n","        return acc\n","    return acc / n\n","\n","\n","class LovaszLoss(nn.Module):\n","    def __init__(self, ignore_index=255, per_image=True):\n","        super().__init__()\n","        self.ignore_index = ignore_index\n","        self.per_image = per_image\n","\n","    def forward(self, outputs, targets):\n","        outputs = outputs.contiguous()\n","        targets = targets.contiguous()\n","        return lovasz_hinge(outputs, targets, per_image=self.per_image, ignore=self.ignore_index)\n","\n","\n","class LovaszLossSigmoid(nn.Module):\n","    def __init__(self, ignore_index=255, per_image=True):\n","        super().__init__()\n","        self.ignore_index = ignore_index\n","        self.per_image = per_image\n","\n","    def forward(self, outputs, targets):\n","        outputs = outputs.contiguous()\n","        targets = targets.contiguous()\n","        return lovasz_sigmoid(outputs, targets, per_image=self.per_image, ignore=self.ignore_index)\n","\n","\n","class FocalLoss2d(nn.Module):\n","    def __init__(self, gamma=2, ignore_index=255):\n","        super().__init__()\n","        self.gamma = gamma\n","        self.ignore_index = ignore_index\n","\n","    def forward(self, outputs, targets):\n","        outputs = outputs.contiguous()\n","        targets = targets.contiguous()\n","        # eps = 1e-8\n","        non_ignored = targets.view(-1) != self.ignore_index\n","        targets = targets.view(-1)[non_ignored].float()\n","        outputs = outputs.contiguous().view(-1)[non_ignored]\n","        outputs = torch.clamp(outputs, eps, 1. - eps)\n","        targets = torch.clamp(targets, eps, 1. - eps)\n","        pt = (1 - targets) * (1 - outputs) + targets * outputs\n","        return (-(1. - pt) ** self.gamma * torch.log(pt)).mean()"]},{"cell_type":"markdown","metadata":{"id":"N5xl5qEyTN3v"},"source":["## Models"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":895454,"status":"ok","timestamp":1685409388850,"user":{"displayName":"Antonio Santos","userId":"03265893617080544823"},"user_tz":180},"id":"pDuOd5udSNOd","outputId":"31f5c395-b5cd-4638-d796-4dc9d04eb136"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading: \"http://data.lip6.fr/cadene/pretrainedmodels/dpn131-71dfe43e0.pth\" to /root/.cache/torch/hub/checkpoints/dpn131-71dfe43e0.pth\n","100%|██████████| 303M/303M [14:53\u003c00:00, 356kB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Sequential(\n","  (conv1_1): InputBlock(\n","    (conv): Conv2d(3, 128, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    (act): ReLU(inplace=True)\n","    (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  )\n","  (conv2_1): DualPathBlock(\n","    (c1x1_w_s1): BnActConv2d(\n","      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(128, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(128, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(160, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv2_2): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(304, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(160, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv2_3): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(320, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(160, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv2_4): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(336, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(160, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv3_1): DualPathBlock(\n","    (c1x1_w_s2): BnActConv2d(\n","      (bn): BatchNorm2d(352, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(352, 576, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","    )\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(352, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(352, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(320, 544, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv3_2): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(608, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(608, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(320, 544, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv3_3): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(320, 544, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv3_4): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(672, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(320, 544, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv3_5): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(704, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(704, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(320, 544, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv3_6): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(736, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(736, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(320, 544, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv3_7): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(768, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(320, 544, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv3_8): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(800, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(800, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(320, 544, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv4_1): DualPathBlock(\n","    (c1x1_w_s2): BnActConv2d(\n","      (bn): BatchNorm2d(832, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(832, 1088, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","    )\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(832, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(832, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv4_2): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(1120, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1120, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv4_3): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1152, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv4_4): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(1184, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1184, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv4_5): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(1216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1216, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv4_6): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(1248, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1248, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv4_7): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv4_8): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(1312, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1312, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv4_9): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1344, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv4_10): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(1376, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1376, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv4_11): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(1408, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1408, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv4_12): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(1440, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1440, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv4_13): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(1472, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1472, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv4_14): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(1504, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1504, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv4_15): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1536, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv4_16): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(1568, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1568, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv4_17): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(1600, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1600, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv4_18): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1632, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv4_19): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(1664, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1664, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv4_20): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(1696, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1696, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv4_21): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(1728, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1728, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv4_22): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(1760, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1760, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv4_23): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(1792, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1792, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv4_24): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1824, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv4_25): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(1856, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1856, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv4_26): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(1888, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1888, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv4_27): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(1920, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv4_28): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(1952, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1952, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv5_1): DualPathBlock(\n","    (c1x1_w_s2): BnActConv2d(\n","      (bn): BatchNorm2d(1984, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1984, 2304, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","    )\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(1984, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1984, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1280, 2176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv5_2): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(2432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(2432, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1280, 2176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv5_3): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(2560, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1280, 2176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv5_bn_ac): CatBnAct(\n","    (bn): BatchNorm2d(2688, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    (act): ReLU(inplace=True)\n","  )\n",") 45\n","DualPathBlock(\n","  (c1x1_a): BnActConv2d(\n","    (bn): BatchNorm2d(304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    (act): ReLU(inplace=True)\n","    (conv): Conv2d(304, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","  )\n","  (c3x3_b): BnActConv2d(\n","    (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    (act): ReLU(inplace=True)\n","    (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","  )\n","  (c1x1_c): BnActConv2d(\n","    (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    (act): ReLU(inplace=True)\n","    (conv): Conv2d(160, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","  )\n",")\n"]}],"source":["\"\"\" PyTorch implementation of DualPathNetworks\n","Ported to PyTorch by [Ross Wightman](https://github.com/rwightman/pytorch-dpn-pretrained)\n","\n","Based on original MXNet implementation https://github.com/cypw/DPNs with\n","many ideas from another PyTorch implementation https://github.com/oyam/pytorch-DPNs.\n","\n","This implementation is compatible with the pretrained weights\n","from cypw's MXNet implementation.\n","\"\"\"\n","import os\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.utils.model_zoo as model_zoo\n","from collections import OrderedDict\n","\n","__all__ = ['DPN', 'dpn68', 'dpn68b', 'dpn92', 'dpn98', 'dpn131', 'dpn107']\n","\n","pretrained_settings = {\n","    'dpn68': {\n","        'imagenet': {\n","            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/dpn68-66bebafa7.pth',\n","            'input_space': 'RGB',\n","            'input_size': [3, 224, 224],\n","            'input_range': [0, 1],\n","            'mean': [124 / 255, 117 / 255, 104 / 255],\n","            'std': [1 / (.0167 * 255)] * 3,\n","            'num_classes': 1000\n","        }\n","    },\n","    'dpn68b': {\n","        'imagenet+5k': {\n","            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/dpn68b_extra-84854c156.pth',\n","            'input_space': 'RGB',\n","            'input_size': [3, 224, 224],\n","            'input_range': [0, 1],\n","            'mean': [124 / 255, 117 / 255, 104 / 255],\n","            'std': [1 / (.0167 * 255)] * 3,\n","            'num_classes': 1000\n","        }\n","    },\n","    'dpn92': {\n","        # 'imagenet': {\n","        #     'url': 'http://data.lip6.fr/cadene/pretrainedmodels/dpn68-66bebafa7.pth',\n","        #     'input_space': 'RGB',\n","        #     'input_size': [3, 224, 224],\n","        #     'input_range': [0, 1],\n","        #     'mean': [124 / 255, 117 / 255, 104 / 255],\n","        #     'std': [1 / (.0167 * 255)] * 3,\n","        #     'num_classes': 1000\n","        # },\n","        'imagenet+5k': {\n","            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/dpn92_extra-b040e4a9b.pth',\n","            'input_space': 'RGB',\n","            'input_size': [3, 224, 224],\n","            'input_range': [0, 1],\n","            'mean': [124 / 255, 117 / 255, 104 / 255],\n","            'std': [1 / (.0167 * 255)] * 3,\n","            'num_classes': 1000\n","        }\n","    },\n","    'dpn98': {\n","        'imagenet': {\n","            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/dpn98-5b90dec4d.pth',\n","            'input_space': 'RGB',\n","            'input_size': [3, 224, 224],\n","            'input_range': [0, 1],\n","            'mean': [124 / 255, 117 / 255, 104 / 255],\n","            'std': [1 / (.0167 * 255)] * 3,\n","            'num_classes': 1000\n","        }\n","    },\n","    'dpn131': {\n","        'imagenet': {\n","            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/dpn131-71dfe43e0.pth',\n","            'input_space': 'RGB',\n","            'input_size': [3, 224, 224],\n","            'input_range': [0, 1],\n","            'mean': [124 / 255, 117 / 255, 104 / 255],\n","            'std': [1 / (.0167 * 255)] * 3,\n","            'num_classes': 1000\n","        }\n","    },\n","    'dpn107': {\n","        'imagenet+5k': {\n","            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/dpn107_extra-1ac7121e2.pth',\n","            'input_space': 'RGB',\n","            'input_size': [3, 224, 224],\n","            'input_range': [0, 1],\n","            'mean': [124 / 255, 117 / 255, 104 / 255],\n","            'std': [1 / (.0167 * 255)] * 3,\n","            'num_classes': 1000\n","        }\n","    }\n","}\n","\n","def dpn68(num_classes=1000, pretrained='imagenet'):\n","    model = DPN(\n","        small=True, num_init_features=10, k_r=128, groups=32,\n","        k_sec=(3, 4, 12, 3), inc_sec=(16, 32, 32, 64),\n","        num_classes=num_classes, test_time_pool=True)\n","    if pretrained:\n","        settings = pretrained_settings['dpn68'][pretrained]\n","        assert num_classes == settings['num_classes'], \\\n","            \"num_classes should be {}, but is {}\".format(settings['num_classes'], num_classes)\n","\n","        model.load_state_dict(model_zoo.load_url(settings['url']))\n","        model.input_space = settings['input_space']\n","        model.input_size = settings['input_size']\n","        model.input_range = settings['input_range']\n","        model.mean = settings['mean']\n","        model.std = settings['std']\n","    return model\n","\n","def dpn68b(num_classes=1000, pretrained='imagenet+5k'):\n","    model = DPN(\n","        small=True, num_init_features=10, k_r=128, groups=32,\n","        b=True, k_sec=(3, 4, 12, 3), inc_sec=(16, 32, 32, 64),\n","        num_classes=num_classes, test_time_pool=True)\n","    if pretrained:\n","        settings = pretrained_settings['dpn68b'][pretrained]\n","        assert num_classes == settings['num_classes'], \\\n","            \"num_classes should be {}, but is {}\".format(settings['num_classes'], num_classes)\n","\n","        model.load_state_dict(model_zoo.load_url(settings['url']))\n","        model.input_space = settings['input_space']\n","        model.input_size = settings['input_size']\n","        model.input_range = settings['input_range']\n","        model.mean = settings['mean']\n","        model.std = settings['std']\n","    return model\n","\n","def dpn92(num_classes=1000, pretrained='imagenet+5k'):\n","    model = DPN(\n","        num_init_features=64, k_r=96, groups=32,\n","        k_sec=(3, 4, 20, 3), inc_sec=(16, 32, 24, 128),\n","        num_classes=num_classes, test_time_pool=True)\n","    if pretrained:\n","        settings = pretrained_settings['dpn92'][pretrained]\n","        assert num_classes == settings['num_classes'], \\\n","            \"num_classes should be {}, but is {}\".format(settings['num_classes'], num_classes)\n","\n","        model.load_state_dict(model_zoo.load_url(settings['url']))\n","        model.input_space = settings['input_space']\n","        model.input_size = settings['input_size']\n","        model.input_range = settings['input_range']\n","        model.mean = settings['mean']\n","        model.std = settings['std']\n","    return model\n","\n","def dpn98(num_classes=1000, pretrained='imagenet'):\n","    model = DPN(\n","        num_init_features=96, k_r=160, groups=40,\n","        k_sec=(3, 6, 20, 3), inc_sec=(16, 32, 32, 128),\n","        num_classes=num_classes, test_time_pool=True)\n","    if pretrained:\n","        settings = pretrained_settings['dpn98'][pretrained]\n","        assert num_classes == settings['num_classes'], \\\n","            \"num_classes should be {}, but is {}\".format(settings['num_classes'], num_classes)\n","\n","        model.load_state_dict(model_zoo.load_url(settings['url']))\n","        model.input_space = settings['input_space']\n","        model.input_size = settings['input_size']\n","        model.input_range = settings['input_range']\n","        model.mean = settings['mean']\n","        model.std = settings['std']\n","    return model\n","\n","def dpn131(num_classes=1000, pretrained='imagenet'):\n","    model = DPN(\n","        num_init_features=128, k_r=160, groups=40,\n","        k_sec=(4, 8, 28, 3), inc_sec=(16, 32, 32, 128),\n","        num_classes=num_classes, test_time_pool=True)\n","    if pretrained:\n","        settings = pretrained_settings['dpn131'][pretrained]\n","        assert num_classes == settings['num_classes'], \\\n","            \"num_classes should be {}, but is {}\".format(settings['num_classes'], num_classes)\n","\n","        model.load_state_dict(model_zoo.load_url(settings['url']))\n","        model.input_space = settings['input_space']\n","        model.input_size = settings['input_size']\n","        model.input_range = settings['input_range']\n","        model.mean = settings['mean']\n","        model.std = settings['std']\n","    return model\n","\n","def dpn107(num_classes=1000, pretrained='imagenet+5k'):\n","    model = DPN(\n","        num_init_features=128, k_r=200, groups=50,\n","        k_sec=(4, 8, 20, 3), inc_sec=(20, 64, 64, 128),\n","        num_classes=num_classes, test_time_pool=True)\n","    if pretrained:\n","        settings = pretrained_settings['dpn107'][pretrained]\n","        assert num_classes == settings['num_classes'], \\\n","            \"num_classes should be {}, but is {}\".format(settings['num_classes'], num_classes)\n","\n","        model.load_state_dict(model_zoo.load_url(settings['url']))\n","        model.input_space = settings['input_space']\n","        model.input_size = settings['input_size']\n","        model.input_range = settings['input_range']\n","        model.mean = settings['mean']\n","        model.std = settings['std']\n","    return model\n","\n","\n","class CatBnAct(nn.Module):\n","    def __init__(self, in_chs, activation_fn=nn.ReLU(inplace=True)):\n","        super(CatBnAct, self).__init__()\n","        self.bn = nn.BatchNorm2d(in_chs, eps=0.001)\n","        self.act = activation_fn\n","\n","    def forward(self, x):\n","        x = torch.cat(x, dim=1) if isinstance(x, tuple) else x\n","        return self.act(self.bn(x))\n","\n","\n","class BnActConv2d(nn.Module):\n","    def __init__(self, in_chs, out_chs, kernel_size, stride,\n","                 padding=0, groups=1, activation_fn=nn.ReLU(inplace=True)):\n","        super(BnActConv2d, self).__init__()\n","        self.bn = nn.BatchNorm2d(in_chs, eps=0.001)\n","        self.act = activation_fn\n","        self.conv = nn.Conv2d(in_chs, out_chs, kernel_size, stride, padding, groups=groups, bias=False)\n","\n","    def forward(self, x):\n","        return self.conv(self.act(self.bn(x)))\n","\n","\n","class InputBlock(nn.Module):\n","    def __init__(self, num_init_features, kernel_size=7,\n","                 padding=3, activation_fn=nn.ReLU(inplace=True)):\n","        super(InputBlock, self).__init__()\n","        self.conv = nn.Conv2d(\n","            3, num_init_features, kernel_size=kernel_size, stride=2, padding=padding, bias=False)\n","        self.bn = nn.BatchNorm2d(num_init_features, eps=0.001)\n","        self.act = activation_fn\n","        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","\n","    def forward(self, x):\n","        x = self.conv(x)\n","        x = self.bn(x)\n","        x = self.act(x)\n","        x = self.pool(x)\n","        return x\n","\n","\n","class DualPathBlock(nn.Module):\n","    def __init__(\n","            self, in_chs, num_1x1_a, num_3x3_b, num_1x1_c, inc, groups, block_type='normal', b=False):\n","        super(DualPathBlock, self).__init__()\n","        self.num_1x1_c = num_1x1_c\n","        self.inc = inc\n","        self.b = b\n","        if block_type == 'proj':\n","            self.key_stride = 1\n","            self.has_proj = True\n","        elif block_type == 'down':\n","            self.key_stride = 2\n","            self.has_proj = True\n","        else:\n","            assert block_type == 'normal'\n","            self.key_stride = 1\n","            self.has_proj = False\n","\n","        if self.has_proj:\n","            # Using different member names here to allow easier parameter key matching for conversion\n","            if self.key_stride == 2:\n","                self.c1x1_w_s2 = BnActConv2d(\n","                    in_chs=in_chs, out_chs=num_1x1_c + 2 * inc, kernel_size=1, stride=2)\n","            else:\n","                self.c1x1_w_s1 = BnActConv2d(\n","                    in_chs=in_chs, out_chs=num_1x1_c + 2 * inc, kernel_size=1, stride=1)\n","        self.c1x1_a = BnActConv2d(in_chs=in_chs, out_chs=num_1x1_a, kernel_size=1, stride=1)\n","        self.c3x3_b = BnActConv2d(\n","            in_chs=num_1x1_a, out_chs=num_3x3_b, kernel_size=3,\n","            stride=self.key_stride, padding=1, groups=groups)\n","        if b:\n","            self.c1x1_c = CatBnAct(in_chs=num_3x3_b)\n","            self.c1x1_c1 = nn.Conv2d(num_3x3_b, num_1x1_c, kernel_size=1, bias=False)\n","            self.c1x1_c2 = nn.Conv2d(num_3x3_b, inc, kernel_size=1, bias=False)\n","        else:\n","            self.c1x1_c = BnActConv2d(in_chs=num_3x3_b, out_chs=num_1x1_c + inc, kernel_size=1, stride=1)\n","\n","    def forward(self, x):\n","        x_in = torch.cat(x, dim=1) if isinstance(x, tuple) else x\n","        if self.has_proj:\n","            if self.key_stride == 2:\n","                x_s = self.c1x1_w_s2(x_in)\n","            else:\n","                x_s = self.c1x1_w_s1(x_in)\n","            x_s1 = x_s[:, :self.num_1x1_c, :, :]\n","            x_s2 = x_s[:, self.num_1x1_c:, :, :]\n","        else:\n","            x_s1 = x[0]\n","            x_s2 = x[1]\n","        x_in = self.c1x1_a(x_in)\n","        x_in = self.c3x3_b(x_in)\n","        if self.b:\n","            x_in = self.c1x1_c(x_in)\n","            out1 = self.c1x1_c1(x_in)\n","            out2 = self.c1x1_c2(x_in)\n","        else:\n","            x_in = self.c1x1_c(x_in)\n","            out1 = x_in[:, :self.num_1x1_c, :, :]\n","            out2 = x_in[:, self.num_1x1_c:, :, :]\n","        resid = x_s1 + out1\n","        dense = torch.cat([x_s2, out2], dim=1)\n","        return resid, dense\n","\n","\n","class DPN(nn.Module):\n","    def __init__(self, small=False, num_init_features=64, k_r=96, groups=32,\n","                 b=False, k_sec=(3, 4, 20, 3), inc_sec=(16, 32, 24, 128),\n","                 num_classes=1000, test_time_pool=False):\n","        super(DPN, self).__init__()\n","        self.test_time_pool = test_time_pool\n","        self.b = b\n","        bw_factor = 1 if small else 4\n","        self.k_sec = k_sec\n","        self.out_channels = []\n","\n","        self.blocks = OrderedDict()\n","\n","        # conv1\n","        if small:\n","            self.blocks['conv1_1'] = InputBlock(num_init_features, kernel_size=3, padding=1)\n","        else:\n","            self.blocks['conv1_1'] = InputBlock(num_init_features, kernel_size=7, padding=3)\n","\n","        self.out_channels.append(num_init_features)\n","        # conv2\n","        bw = 64 * bw_factor\n","        inc = inc_sec[0]\n","        r = (k_r * bw) // (64 * bw_factor)\n","        self.blocks['conv2_1'] = DualPathBlock(num_init_features, r, r, bw, inc, groups, 'proj', b)\n","        in_chs = bw + 3 * inc\n","        for i in range(2, k_sec[0] + 1):\n","            self.blocks['conv2_' + str(i)] = DualPathBlock(in_chs, r, r, bw, inc, groups, 'normal', b)\n","            in_chs += inc\n","\n","        self.out_channels.append(in_chs)\n","        # conv3\n","        bw = 128 * bw_factor\n","        inc = inc_sec[1]\n","        r = (k_r * bw) // (64 * bw_factor)\n","        self.blocks['conv3_1'] = DualPathBlock(in_chs, r, r, bw, inc, groups, 'down', b)\n","        in_chs = bw + 3 * inc\n","        for i in range(2, k_sec[1] + 1):\n","            self.blocks['conv3_' + str(i)] = DualPathBlock(in_chs, r, r, bw, inc, groups, 'normal', b)\n","            in_chs += inc\n","\n","        self.out_channels.append(in_chs)\n","        # conv4\n","        bw = 256 * bw_factor\n","        inc = inc_sec[2]\n","        r = (k_r * bw) // (64 * bw_factor)\n","        self.blocks['conv4_1'] = DualPathBlock(in_chs, r, r, bw, inc, groups, 'down', b)\n","        in_chs = bw + 3 * inc\n","        for i in range(2, k_sec[2] + 1):\n","            self.blocks['conv4_' + str(i)] = DualPathBlock(in_chs, r, r, bw, inc, groups, 'normal', b)\n","            in_chs += inc\n","\n","        self.out_channels.append(in_chs)\n","        # conv5\n","        bw = 512 * bw_factor\n","        inc = inc_sec[3]\n","        r = (k_r * bw) // (64 * bw_factor)\n","        self.blocks['conv5_1'] = DualPathBlock(in_chs, r, r, bw, inc, groups, 'down', b)\n","        in_chs = bw + 3 * inc\n","        for i in range(2, k_sec[3] + 1):\n","            self.blocks['conv5_' + str(i)] = DualPathBlock(in_chs, r, r, bw, inc, groups, 'normal', b)\n","            in_chs += inc\n","        self.blocks['conv5_bn_ac'] = CatBnAct(in_chs)\n","        self.out_channels.append(in_chs)\n","\n","        self.features = nn.Sequential(self.blocks)\n","\n","        # Using 1x1 conv for the FC layer to allow the extra pooling scheme\n","        self.classifier = nn.Conv2d(in_chs, num_classes, kernel_size=1, bias=True)\n","\n","    def logits(self, features):\n","        if not self.training and self.test_time_pool:\n","            x = F.avg_pool2d(features, kernel_size=7, stride=1)\n","            out = self.classifier(x)\n","            # The extra test time pool should be pooling an img_size//32 - 6 size patch\n","            out = adaptive_avgmax_pool2d(out, pool_type='avgmax')\n","        else:\n","            x = adaptive_avgmax_pool2d(features, pool_type='avg')\n","            out = self.classifier(x)\n","        return out.view(out.size(0), -1)\n","\n","    def forward(self, input):\n","        x = self.features(input)\n","        x = self.logits(x)\n","        return x\n","\n","\"\"\" PyTorch selectable adaptive pooling\n","Adaptive pooling with the ability to select the type of pooling from:\n","    * 'avg' - Average pooling\n","    * 'max' - Max pooling\n","    * 'avgmax' - Sum of average and max pooling re-scaled by 0.5\n","    * 'avgmaxc' - Concatenation of average and max pooling along feature dim, doubles feature dim\n","\n","Both a functional and a nn.Module version of the pooling is provided.\n","\n","Author: Ross Wightman (rwightman)\n","\"\"\"\n","\n","def pooling_factor(pool_type='avg'):\n","    return 2 if pool_type == 'avgmaxc' else 1\n","\n","\n","def adaptive_avgmax_pool2d(x, pool_type='avg', padding=0, count_include_pad=False):\n","    \"\"\"Selectable global pooling function with dynamic input kernel size\n","    \"\"\"\n","    if pool_type == 'avgmaxc':\n","        x = torch.cat([\n","            F.avg_pool2d(\n","                x, kernel_size=(x.size(2), x.size(3)), padding=padding, count_include_pad=count_include_pad),\n","            F.max_pool2d(x, kernel_size=(x.size(2), x.size(3)), padding=padding)\n","        ], dim=1)\n","    elif pool_type == 'avgmax':\n","        x_avg = F.avg_pool2d(\n","                x, kernel_size=(x.size(2), x.size(3)), padding=padding, count_include_pad=count_include_pad)\n","        x_max = F.max_pool2d(x, kernel_size=(x.size(2), x.size(3)), padding=padding)\n","        x = 0.5 * (x_avg + x_max)\n","    elif pool_type == 'max':\n","        x = F.max_pool2d(x, kernel_size=(x.size(2), x.size(3)), padding=padding)\n","    else:\n","        if pool_type != 'avg':\n","            print('Invalid pool type %s specified. Defaulting to average pooling.' % pool_type)\n","        x = F.avg_pool2d(\n","            x, kernel_size=(x.size(2), x.size(3)), padding=padding, count_include_pad=count_include_pad)\n","    return x\n","\n","\n","class AdaptiveAvgMaxPool2d(torch.nn.Module):\n","    \"\"\"Selectable global pooling layer with dynamic input kernel size\n","    \"\"\"\n","    def __init__(self, output_size=1, pool_type='avg'):\n","        super(AdaptiveAvgMaxPool2d, self).__init__()\n","        self.output_size = output_size\n","        self.pool_type = pool_type\n","        if pool_type == 'avgmaxc' or pool_type == 'avgmax':\n","            self.pool = nn.ModuleList([nn.AdaptiveAvgPool2d(output_size), nn.AdaptiveMaxPool2d(output_size)])\n","        elif pool_type == 'max':\n","            self.pool = nn.AdaptiveMaxPool2d(output_size)\n","        else:\n","            if pool_type != 'avg':\n","                print('Invalid pool type %s specified. Defaulting to average pooling.' % pool_type)\n","            self.pool = nn.AdaptiveAvgPool2d(output_size)\n","\n","    def forward(self, x):\n","        if self.pool_type == 'avgmaxc':\n","            x = torch.cat([p(x) for p in self.pool], dim=1)\n","        elif self.pool_type == 'avgmax':\n","            x = 0.5 * torch.sum(torch.stack([p(x) for p in self.pool]), 0).squeeze(dim=0)\n","        else:\n","            x = self.pool(x)\n","        return x\n","\n","    def factor(self):\n","        return pooling_factor(self.pool_type)\n","\n","    def __repr__(self):\n","        return self.__class__.__name__ + ' (' \\\n","               + 'output_size=' + str(self.output_size) \\\n","               + ', pool_type=' + self.pool_type + ')'\n","\n","if __name__ == \"__main__\":\n","    import ssl\n","    ssl._create_default_https_context = ssl._create_unverified_context\n","    model = dpn131()\n","    print(model.features, len(model.features))\n","    print(model.features[2])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":312285,"status":"ok","timestamp":1685409702002,"user":{"displayName":"Antonio Santos","userId":"03265893617080544823"},"user_tz":180},"id":"d1Fm1qEnS6Wm","outputId":"ee498c87-eeed-4c73-d865-f80d6549c170"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading: \"http://data.lip6.fr/cadene/pretrainedmodels/se_resnext50_32x4d-a260b3a4.pth\" to /root/.cache/torch/hub/checkpoints/se_resnext50_32x4d-a260b3a4.pth\n","100%|██████████| 105M/105M [05:10\u003c00:00, 356kB/s]"]},{"name":"stdout","output_type":"stream","text":["SENet(\n","  (pool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n","  (layer0): Sequential(\n","    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu1): ReLU(inplace=True)\n","  )\n","  (layer1): Sequential(\n","    (0): SEResNeXtBottleneck(\n","      (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (se_module): SEModule(\n","        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","        (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n","        (relu): ReLU(inplace=True)\n","        (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n","        (sigmoid): Sigmoid()\n","      )\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): SEResNeXtBottleneck(\n","      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (se_module): SEModule(\n","        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","        (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n","        (relu): ReLU(inplace=True)\n","        (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n","        (sigmoid): Sigmoid()\n","      )\n","    )\n","    (2): SEResNeXtBottleneck(\n","      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (se_module): SEModule(\n","        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","        (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n","        (relu): ReLU(inplace=True)\n","        (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n","        (sigmoid): Sigmoid()\n","      )\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): SEResNeXtBottleneck(\n","      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (se_module): SEModule(\n","        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","        (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n","        (relu): ReLU(inplace=True)\n","        (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n","        (sigmoid): Sigmoid()\n","      )\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): SEResNeXtBottleneck(\n","      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (se_module): SEModule(\n","        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","        (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n","        (relu): ReLU(inplace=True)\n","        (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n","        (sigmoid): Sigmoid()\n","      )\n","    )\n","    (2): SEResNeXtBottleneck(\n","      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (se_module): SEModule(\n","        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","        (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n","        (relu): ReLU(inplace=True)\n","        (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n","        (sigmoid): Sigmoid()\n","      )\n","    )\n","    (3): SEResNeXtBottleneck(\n","      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (se_module): SEModule(\n","        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","        (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n","        (relu): ReLU(inplace=True)\n","        (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n","        (sigmoid): Sigmoid()\n","      )\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): SEResNeXtBottleneck(\n","      (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (se_module): SEModule(\n","        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n","        (relu): ReLU(inplace=True)\n","        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n","        (sigmoid): Sigmoid()\n","      )\n","      (downsample): Sequential(\n","        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): SEResNeXtBottleneck(\n","      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (se_module): SEModule(\n","        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n","        (relu): ReLU(inplace=True)\n","        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n","        (sigmoid): Sigmoid()\n","      )\n","    )\n","    (2): SEResNeXtBottleneck(\n","      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (se_module): SEModule(\n","        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n","        (relu): ReLU(inplace=True)\n","        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n","        (sigmoid): Sigmoid()\n","      )\n","    )\n","    (3): SEResNeXtBottleneck(\n","      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (se_module): SEModule(\n","        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n","        (relu): ReLU(inplace=True)\n","        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n","        (sigmoid): Sigmoid()\n","      )\n","    )\n","    (4): SEResNeXtBottleneck(\n","      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (se_module): SEModule(\n","        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n","        (relu): ReLU(inplace=True)\n","        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n","        (sigmoid): Sigmoid()\n","      )\n","    )\n","    (5): SEResNeXtBottleneck(\n","      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (se_module): SEModule(\n","        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n","        (relu): ReLU(inplace=True)\n","        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n","        (sigmoid): Sigmoid()\n","      )\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): SEResNeXtBottleneck(\n","      (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n","      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (se_module): SEModule(\n","        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","        (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n","        (relu): ReLU(inplace=True)\n","        (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n","        (sigmoid): Sigmoid()\n","      )\n","      (downsample): Sequential(\n","        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): SEResNeXtBottleneck(\n","      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (se_module): SEModule(\n","        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","        (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n","        (relu): ReLU(inplace=True)\n","        (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n","        (sigmoid): Sigmoid()\n","      )\n","    )\n","    (2): SEResNeXtBottleneck(\n","      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (se_module): SEModule(\n","        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","        (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n","        (relu): ReLU(inplace=True)\n","        (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n","        (sigmoid): Sigmoid()\n","      )\n","    )\n","  )\n","  (avg_pool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n","  (last_linear): Linear(in_features=2048, out_features=1000, bias=True)\n",")\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["\"\"\"\n","ResNet code gently borrowed from\n","https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py\n","\"\"\"\n","\n","from collections import OrderedDict\n","import math\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils import model_zoo\n","\n","__all__ = ['SENet', 'senet154', 'se_resnet50', 'se_resnet101', 'se_resnet152',\n","           'se_resnext50_32x4d', 'se_resnext101_32x4d']\n","\n","pretrained_settings = {\n","    'senet154': {\n","        'imagenet': {\n","            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/senet154-c7b49a05.pth',\n","            'input_space': 'RGB',\n","            'input_size': [3, 224, 224],\n","            'input_range': [0, 1],\n","            'mean': [0.485, 0.456, 0.406],\n","            'std': [0.229, 0.224, 0.225],\n","            'num_classes': 1000\n","        }\n","    },\n","    'se_resnet50': {\n","        'imagenet': {\n","            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnet50-ce0d4300.pth',\n","            'input_space': 'RGB',\n","            'input_size': [3, 224, 224],\n","            'input_range': [0, 1],\n","            'mean': [0.485, 0.456, 0.406],\n","            'std': [0.229, 0.224, 0.225],\n","            'num_classes': 1000\n","        }\n","    },\n","    'se_resnet101': {\n","        'imagenet': {\n","            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnet101-7e38fcc6.pth',\n","            'input_space': 'RGB',\n","            'input_size': [3, 224, 224],\n","            'input_range': [0, 1],\n","            'mean': [0.485, 0.456, 0.406],\n","            'std': [0.229, 0.224, 0.225],\n","            'num_classes': 1000\n","        }\n","    },\n","    'se_resnet152': {\n","        'imagenet': {\n","            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnet152-d17c99b7.pth',\n","            'input_space': 'RGB',\n","            'input_size': [3, 224, 224],\n","            'input_range': [0, 1],\n","            'mean': [0.485, 0.456, 0.406],\n","            'std': [0.229, 0.224, 0.225],\n","            'num_classes': 1000\n","        }\n","    },\n","    'se_resnext50_32x4d': {\n","        'imagenet': {\n","            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnext50_32x4d-a260b3a4.pth',\n","            'input_space': 'RGB',\n","            'input_size': [3, 224, 224],\n","            'input_range': [0, 1],\n","            'mean': [0.485, 0.456, 0.406],\n","            'std': [0.229, 0.224, 0.225],\n","            'num_classes': 1000\n","        }\n","    },\n","    'se_resnext101_32x4d': {\n","        'imagenet': {\n","            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnext101_32x4d-3b2fe3d8.pth',\n","            'input_space': 'RGB',\n","            'input_size': [3, 224, 224],\n","            'input_range': [0, 1],\n","            'mean': [0.485, 0.456, 0.406],\n","            'std': [0.229, 0.224, 0.225],\n","            'num_classes': 1000\n","        }\n","    },\n","}\n","\n","\n","class SEModule(nn.Module):\n","\n","    def __init__(self, channels, reduction, concat=False):\n","        super(SEModule, self).__init__()\n","        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n","        self.fc1 = nn.Conv2d(channels, channels // reduction, kernel_size=1,\n","                             padding=0)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.fc2 = nn.Conv2d(channels // reduction, channels, kernel_size=1,\n","                             padding=0)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        module_input = x\n","        x = self.avg_pool(x)\n","        x = self.fc1(x)\n","        x = self.relu(x)\n","        x = self.fc2(x)\n","        x = self.sigmoid(x)\n","        return module_input * x\n","\n","class SCSEModule(nn.Module):\n","    # according to https://arxiv.org/pdf/1808.08127.pdf concat is better\n","    def __init__(self, channels, reduction=16, concat=False):\n","        super(SCSEModule, self).__init__()\n","        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n","        self.fc1 = nn.Conv2d(channels, channels // reduction, kernel_size=1,\n","                             padding=0)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.fc2 = nn.Conv2d(channels // reduction, channels, kernel_size=1,\n","                             padding=0)\n","        self.sigmoid = nn.Sigmoid()\n","\n","        self.spatial_se = nn.Sequential(nn.Conv2d(channels, 1, kernel_size=1,\n","                                                  stride=1, padding=0, bias=False),\n","                                        nn.Sigmoid())\n","        self.concat = concat\n","\n","    def forward(self, x):\n","        module_input = x\n","\n","        x = self.avg_pool(x)\n","        x = self.fc1(x)\n","        x = self.relu(x)\n","        x = self.fc2(x)\n","        chn_se = self.sigmoid(x)\n","        chn_se = chn_se * module_input\n","\n","        spa_se = self.spatial_se(module_input)\n","        spa_se = module_input * spa_se\n","        if self.concat:\n","            return torch.cat([chn_se, spa_se], dim=1)\n","        else:\n","            return chn_se + spa_se\n","\n","class Bottleneck(nn.Module):\n","    \"\"\"\n","    Base class for bottlenecks that implements `forward()` method.\n","    \"\"\"\n","    def forward(self, x):\n","        residual = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out = self.relu(out)\n","\n","        out = self.conv3(out)\n","        out = self.bn3(out)\n","\n","        if self.downsample is not None:\n","            residual = self.downsample(x)\n","\n","        out = self.se_module(out) + residual\n","        out = self.relu(out)\n","\n","        return out\n","\n","\n","class SEBottleneck(Bottleneck):\n","    \"\"\"\n","    Bottleneck for SENet154.\n","    \"\"\"\n","    expansion = 4\n","\n","    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n","                 downsample=None):\n","        super(SEBottleneck, self).__init__()\n","        self.conv1 = nn.Conv2d(inplanes, planes * 2, kernel_size=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes * 2)\n","        self.conv2 = nn.Conv2d(planes * 2, planes * 4, kernel_size=3,\n","                               stride=stride, padding=1, groups=groups,\n","                               bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes * 4)\n","        self.conv3 = nn.Conv2d(planes * 4, planes * 4, kernel_size=1,\n","                               bias=False)\n","        self.bn3 = nn.BatchNorm2d(planes * 4)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.se_module = SEModule(planes * 4, reduction=reduction)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","\n","class SCSEBottleneck(Bottleneck):\n","    \"\"\"\n","    Bottleneck for SENet154.\n","    \"\"\"\n","    expansion = 4\n","\n","    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n","                 downsample=None):\n","        super(SCSEBottleneck, self).__init__()\n","        self.conv1 = nn.Conv2d(inplanes, planes * 2, kernel_size=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes * 2)\n","        self.conv2 = nn.Conv2d(planes * 2, planes * 4, kernel_size=3,\n","                               stride=stride, padding=1, groups=groups,\n","                               bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes * 4)\n","        self.conv3 = nn.Conv2d(planes * 4, planes * 4, kernel_size=1,\n","                               bias=False)\n","        self.bn3 = nn.BatchNorm2d(planes * 4)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.se_module = SCSEModule(planes * 4, reduction=reduction)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","\n","class SEResNetBottleneck(Bottleneck):\n","    \"\"\"\n","    ResNet bottleneck with a Squeeze-and-Excitation module. It follows Caffe\n","    implementation and uses `stride=stride` in `conv1` and not in `conv2`\n","    (the latter is used in the torchvision implementation of ResNet).\n","    \"\"\"\n","    expansion = 4\n","\n","    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n","                 downsample=None):\n","        super(SEResNetBottleneck, self).__init__()\n","        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False,\n","                               stride=stride)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, padding=1,\n","                               groups=groups, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(planes * 4)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.se_module = SEModule(planes * 4, reduction=reduction)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","\n","class SEResNeXtBottleneck(Bottleneck):\n","    \"\"\"\n","    ResNeXt bottleneck type C with a Squeeze-and-Excitation module.\n","    \"\"\"\n","    expansion = 4\n","\n","    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n","                 downsample=None, base_width=4):\n","        super(SEResNeXtBottleneck, self).__init__()\n","        width = math.floor(planes * (base_width / 64)) * groups\n","        self.conv1 = nn.Conv2d(inplanes, width, kernel_size=1, bias=False,\n","                               stride=1)\n","        self.bn1 = nn.BatchNorm2d(width)\n","        self.conv2 = nn.Conv2d(width, width, kernel_size=3, stride=stride,\n","                               padding=1, groups=groups, bias=False)\n","        self.bn2 = nn.BatchNorm2d(width)\n","        self.conv3 = nn.Conv2d(width, planes * 4, kernel_size=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(planes * 4)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.se_module = SEModule(planes * 4, reduction=reduction)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","\n","\n","class SCSEResNeXtBottleneck(Bottleneck):\n","    \"\"\"\n","    ResNeXt bottleneck type C with a Concurrent Spatial Squeeze-and-Excitation module.\n","    \"\"\"\n","    expansion = 4\n","\n","    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n","                 downsample=None, base_width=4, final=False):\n","        super(SCSEResNeXtBottleneck, self).__init__()\n","        width = math.floor(planes * (base_width / 64)) * groups\n","        self.conv1 = nn.Conv2d(inplanes, width, kernel_size=1, bias=False,\n","                               stride=1)\n","        self.bn1 = nn.BatchNorm2d(width)\n","        self.conv2 = nn.Conv2d(width, width, kernel_size=3, stride=stride,\n","                               padding=1, groups=groups, bias=False)\n","        self.bn2 = nn.BatchNorm2d(width)\n","        self.conv3 = nn.Conv2d(width, planes * 4, kernel_size=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(planes * 4)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.se_module = SCSEModule(planes * 4, reduction=reduction)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","\n","class SENet(nn.Module):\n","\n","    def __init__(self, block, layers, groups, reduction, dropout_p=0.2,\n","                 inplanes=128, input_3x3=True, downsample_kernel_size=3,\n","                 downsample_padding=1, num_classes=1000):\n","        \"\"\"\n","        Parameters\n","        ----------\n","        block (nn.Module): Bottleneck class.\n","            - For SENet154: SEBottleneck\n","            - For SE-ResNet models: SEResNetBottleneck\n","            - For SE-ResNeXt models:  SEResNeXtBottleneck\n","        layers (list of ints): Number of residual blocks for 4 layers of the\n","            network (layer1...layer4).\n","        groups (int): Number of groups for the 3x3 convolution in each\n","            bottleneck block.\n","            - For SENet154: 64\n","            - For SE-ResNet models: 1\n","            - For SE-ResNeXt models:  32\n","        reduction (int): Reduction ratio for Squeeze-and-Excitation modules.\n","            - For all models: 16\n","        dropout_p (float or None): Drop probability for the Dropout layer.\n","            If `None` the Dropout layer is not used.\n","            - For SENet154: 0.2\n","            - For SE-ResNet models: None\n","            - For SE-ResNeXt models: None\n","        inplanes (int):  Number of input channels for layer1.\n","            - For SENet154: 128\n","            - For SE-ResNet models: 64\n","            - For SE-ResNeXt models: 64\n","        input_3x3 (bool): If `True`, use three 3x3 convolutions instead of\n","            a single 7x7 convolution in layer0.\n","            - For SENet154: True\n","            - For SE-ResNet models: False\n","            - For SE-ResNeXt models: False\n","        downsample_kernel_size (int): Kernel size for downsampling convolutions\n","            in layer2, layer3 and layer4.\n","            - For SENet154: 3\n","            - For SE-ResNet models: 1\n","            - For SE-ResNeXt models: 1\n","        downsample_padding (int): Padding for downsampling convolutions in\n","            layer2, layer3 and layer4.\n","            - For SENet154: 1\n","            - For SE-ResNet models: 0\n","            - For SE-ResNeXt models: 0\n","        num_classes (int): Number of outputs in `last_linear` layer.\n","            - For all models: 1000\n","        \"\"\"\n","        super(SENet, self).__init__()\n","        self.inplanes = inplanes\n","        if input_3x3:\n","            layer0_modules = [\n","                ('conv1', nn.Conv2d(3, 64, 3, stride=2, padding=1,\n","                                    bias=False)),\n","                ('bn1', nn.BatchNorm2d(64)),\n","                ('relu1', nn.ReLU(inplace=True)),\n","                ('conv2', nn.Conv2d(64, 64, 3, stride=1, padding=1,\n","                                    bias=False)),\n","                ('bn2', nn.BatchNorm2d(64)),\n","                ('relu2', nn.ReLU(inplace=True)),\n","                ('conv3', nn.Conv2d(64, inplanes, 3, stride=1, padding=1,\n","                                    bias=False)),\n","                ('bn3', nn.BatchNorm2d(inplanes)),\n","                ('relu3', nn.ReLU(inplace=True)),\n","            ]\n","        else:\n","            layer0_modules = [\n","                ('conv1', nn.Conv2d(3, inplanes, kernel_size=7, stride=2,\n","                                    padding=3, bias=False)),\n","                ('bn1', nn.BatchNorm2d(inplanes)),\n","                ('relu1', nn.ReLU(inplace=True)),\n","            ]\n","        # To preserve compatibility with Caffe weights `ceil_mode=True`\n","        # is used instead of `padding=1`.\n","        self.pool = nn.MaxPool2d(3, stride=2, ceil_mode=True)\n","        self.layer0 = nn.Sequential(OrderedDict(layer0_modules))\n","        self.layer1 = self._make_layer(\n","            block,\n","            planes=64,\n","            blocks=layers[0],\n","            groups=groups,\n","            reduction=reduction,\n","            downsample_kernel_size=1,\n","            downsample_padding=0\n","        )\n","        self.layer2 = self._make_layer(\n","            block,\n","            planes=128,\n","            blocks=layers[1],\n","            stride=2,\n","            groups=groups,\n","            reduction=reduction,\n","            downsample_kernel_size=downsample_kernel_size,\n","            downsample_padding=downsample_padding\n","        )\n","        self.layer3 = self._make_layer(\n","            block,\n","            planes=256,\n","            blocks=layers[2],\n","            stride=2,\n","            groups=groups,\n","            reduction=reduction,\n","            downsample_kernel_size=downsample_kernel_size,\n","            downsample_padding=downsample_padding\n","        )\n","        self.layer4 = self._make_layer(\n","            block,\n","            planes=512,\n","            blocks=layers[3],\n","            stride=2,\n","            groups=groups,\n","            reduction=reduction,\n","            downsample_kernel_size=downsample_kernel_size,\n","            downsample_padding=downsample_padding\n","        )\n","        self.avg_pool = nn.AvgPool2d(7, stride=1)\n","        self.dropout = nn.Dropout(dropout_p) if dropout_p is not None else None\n","        self.last_linear = nn.Linear(512 * block.expansion, num_classes)\n","        self._initialize_weights()\n","\n","    def _make_layer(self, block, planes, blocks, groups, reduction, stride=1,\n","                    downsample_kernel_size=1, downsample_padding=0):\n","        downsample = None\n","        if stride != 1 or self.inplanes != planes * block.expansion:\n","            downsample = nn.Sequential(\n","                nn.Conv2d(self.inplanes, planes * block.expansion,\n","                          kernel_size=downsample_kernel_size, stride=stride,\n","                          padding=downsample_padding, bias=False),\n","                nn.BatchNorm2d(planes * block.expansion),\n","            )\n","\n","        layers = []\n","        layers.append(block(self.inplanes, planes, groups, reduction, stride,\n","                            downsample))\n","        self.inplanes = planes * block.expansion\n","        for i in range(1, blocks):\n","            layers.append(block(self.inplanes, planes, groups, reduction))\n","\n","        return nn.Sequential(*layers)\n","\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n","                m.weight.data = nn.init.kaiming_normal_(m.weight.data)\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","\n","    def features(self, x):\n","        x = self.layer0(x)\n","        x = self.pool(x)\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","        return x\n","\n","    def logits(self, x):\n","        x = self.avg_pool(x)\n","        if self.dropout is not None:\n","            x = self.dropout(x)\n","        x = x.view(x.size(0), -1)\n","        x = self.last_linear(x)\n","        return x\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = self.logits(x)\n","        return x\n","\n","\n","def initialize_pretrained_model(model, num_classes, settings):\n","    assert num_classes == settings['num_classes'], \\\n","        'num_classes should be {}, but is {}'.format(\n","            settings['num_classes'], num_classes)\n","    model.load_state_dict(model_zoo.load_url(settings['url']), strict=False)\n","    model.input_space = settings['input_space']\n","    model.input_size = settings['input_size']\n","    model.input_range = settings['input_range']\n","    model.mean = settings['mean']\n","    model.std = settings['std']\n","\n","\n","def senet154(num_classes=1000, pretrained='imagenet'):\n","    model = SENet(SEBottleneck, [3, 8, 36, 3], groups=64, reduction=16,\n","                  dropout_p=0.2, num_classes=num_classes)\n","    if pretrained is not None:\n","        settings = pretrained_settings['senet154'][pretrained]\n","        initialize_pretrained_model(model, num_classes, settings)\n","    return model\n","\n","def scsenet154(num_classes=1000, pretrained='imagenet'):\n","    print(\"scsenet154\")\n","    model = SENet(SCSEBottleneck, [3, 8, 36, 3], groups=64, reduction=16,\n","                  dropout_p=0.2, num_classes=num_classes)\n","    if pretrained is not None:\n","        settings = pretrained_settings['senet154'][pretrained]\n","        initialize_pretrained_model(model, num_classes, settings)\n","    return model\n","\n","\n","def se_resnet50(num_classes=1000, pretrained='imagenet'):\n","    model = SENet(SEResNetBottleneck, [3, 4, 6, 3], groups=1, reduction=16,\n","                  dropout_p=None, inplanes=64, input_3x3=False,\n","                  downsample_kernel_size=1, downsample_padding=0,\n","                  num_classes=num_classes)\n","    if pretrained is not None:\n","        settings = pretrained_settings['se_resnet50'][pretrained]\n","        initialize_pretrained_model(model, num_classes, settings)\n","    return model\n","\n","\n","def se_resnet101(num_classes=1000, pretrained='imagenet'):\n","    model = SENet(SEResNetBottleneck, [3, 4, 23, 3], groups=1, reduction=16,\n","                  dropout_p=None, inplanes=64, input_3x3=False,\n","                  downsample_kernel_size=1, downsample_padding=0,\n","                  num_classes=num_classes)\n","    if pretrained is not None:\n","        settings = pretrained_settings['se_resnet101'][pretrained]\n","        initialize_pretrained_model(model, num_classes, settings)\n","    return model\n","\n","\n","def se_resnet152(num_classes=1000, pretrained='imagenet'):\n","    model = SENet(SEResNetBottleneck, [3, 8, 36, 3], groups=1, reduction=16,\n","                  dropout_p=None, inplanes=64, input_3x3=False,\n","                  downsample_kernel_size=1, downsample_padding=0,\n","                  num_classes=num_classes)\n","    if pretrained is not None:\n","        settings = pretrained_settings['se_resnet152'][pretrained]\n","        initialize_pretrained_model(model, num_classes, settings)\n","    return model\n","\n","\n","def se_resnext50_32x4d(num_classes=1000, pretrained='imagenet'):\n","    model = SENet(SEResNeXtBottleneck, [3, 4, 6, 3], groups=32, reduction=16,\n","                  dropout_p=None, inplanes=64, input_3x3=False,\n","                  downsample_kernel_size=1, downsample_padding=0,\n","                  num_classes=num_classes)\n","    if pretrained is not None:\n","        settings = pretrained_settings['se_resnext50_32x4d'][pretrained]\n","        initialize_pretrained_model(model, num_classes, settings)\n","    return model\n","\n","\n","def scse_resnext50_32x4d(num_classes=1000, pretrained='imagenet'):\n","    model = SENet(SCSEResNeXtBottleneck, [3, 4, 6, 3], groups=32, reduction=16,\n","                  dropout_p=None, inplanes=64, input_3x3=False,\n","                  downsample_kernel_size=1, downsample_padding=0,\n","                  num_classes=num_classes)\n","    if pretrained is not None:\n","        settings = pretrained_settings['se_resnext50_32x4d'][pretrained]\n","        initialize_pretrained_model(model, num_classes, settings)\n","    return model\n","\n","\n","def se_resnext101_32x4d(num_classes=1000, pretrained='imagenet'):\n","    model = SENet(SEResNeXtBottleneck, [3, 4, 23, 3], groups=32, reduction=16,\n","                  dropout_p=None, inplanes=64, input_3x3=False,\n","                  downsample_kernel_size=1, downsample_padding=0,\n","                  num_classes=num_classes)\n","    if pretrained is not None:\n","        settings = pretrained_settings['se_resnext101_32x4d'][pretrained]\n","        initialize_pretrained_model(model, num_classes, settings)\n","    return model\n","if __name__ == '__main__':\n","    print(se_resnext50_32x4d())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eIU2hEMNTCf1"},"outputs":[],"source":["import numpy as np\n","\n","import torch\n","from torch import nn\n","import torch.nn.functional as F\n","import torchvision.models\n","\n","class ConvReluBN(nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size=3):\n","        super(ConvReluBN, self).__init__()\n","        self.layer = nn.Sequential(\n","            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, padding=1),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True)\n","        )\n","    def forward(self, x):\n","        return self.layer(x)\n","\n","\n","class ConvRelu(nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size=3):\n","        super(ConvRelu, self).__init__()\n","        self.layer = nn.Sequential(\n","            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, padding=1),\n","            nn.ReLU(inplace=True)\n","        )\n","    def forward(self, x):\n","        return self.layer(x)\n","\n","\n","class SCSEModule(nn.Module):\n","    # according to https://arxiv.org/pdf/1808.08127.pdf concat is better\n","    def __init__(self, channels, reduction=16, concat=False):\n","        super(SCSEModule, self).__init__()\n","        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n","        self.fc1 = nn.Conv2d(channels, channels // reduction, kernel_size=1,\n","                             padding=0)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.fc2 = nn.Conv2d(channels // reduction, channels, kernel_size=1,\n","                             padding=0)\n","        self.sigmoid = nn.Sigmoid()\n","\n","        self.spatial_se = nn.Sequential(nn.Conv2d(channels, 1, kernel_size=1,\n","                                                  stride=1, padding=0, bias=False),\n","                                        nn.Sigmoid())\n","        self.concat = concat\n","\n","    def forward(self, x):\n","        module_input = x\n","\n","        x = self.avg_pool(x)\n","        x = self.fc1(x)\n","        x = self.relu(x)\n","        x = self.fc2(x)\n","        chn_se = self.sigmoid(x)\n","        chn_se = chn_se * module_input\n","\n","        spa_se = self.spatial_se(module_input)\n","        spa_se = module_input * spa_se\n","        if self.concat:\n","            return torch.cat([chn_se, spa_se], dim=1)\n","        else:\n","            return chn_se + spa_se\n","\n","\n","class SeResNext50_Unet_Loc(nn.Module):\n","    def __init__(self, pretrained='imagenet', **kwargs):\n","        super(SeResNext50_Unet_Loc, self).__init__()\n","\n","        encoder_filters = [64, 256, 512, 1024, 2048]\n","        decoder_filters = np.asarray([64, 96, 128, 256, 512]) // 2\n","\n","        self.conv6 = ConvRelu(encoder_filters[-1], decoder_filters[-1])\n","        self.conv6_2 = ConvRelu(decoder_filters[-1] + encoder_filters[-2], decoder_filters[-1])\n","        self.conv7 = ConvRelu(decoder_filters[-1], decoder_filters[-2])\n","        self.conv7_2 = ConvRelu(decoder_filters[-2] + encoder_filters[-3], decoder_filters[-2])\n","        self.conv8 = ConvRelu(decoder_filters[-2], decoder_filters[-3])\n","        self.conv8_2 = ConvRelu(decoder_filters[-3] + encoder_filters[-4], decoder_filters[-3])\n","        self.conv9 = ConvRelu(decoder_filters[-3], decoder_filters[-4])\n","        self.conv9_2 = ConvRelu(decoder_filters[-4] + encoder_filters[-5], decoder_filters[-4])\n","        self.conv10 = ConvRelu(decoder_filters[-4], decoder_filters[-5])\n","\n","\n","        self.res = nn.Conv2d(decoder_filters[-5], 1, 1, stride=1, padding=0)\n","\n","        self._initialize_weights()\n","\n","        encoder = se_resnext50_32x4d(pretrained=pretrained)\n","\n","        # conv1_new = nn.Conv2d(6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","        # _w = encoder.layer0.conv1.state_dict()\n","        # _w['weight'] = torch.cat([0.5 * _w['weight'], 0.5 * _w['weight']], 1)\n","        # conv1_new.load_state_dict(_w)\n","        self.conv1 = nn.Sequential(encoder.layer0.conv1, encoder.layer0.bn1, encoder.layer0.relu1) #encoder.layer0.conv1\n","        self.conv2 = nn.Sequential(encoder.pool, encoder.layer1)\n","        self.conv3 = encoder.layer2\n","        self.conv4 = encoder.layer3\n","        self.conv5 = encoder.layer4\n","\n","\n","    def forward(self, x):\n","        batch_size, C, H, W = x.shape\n","\n","        enc1 = self.conv1(x)\n","        enc2 = self.conv2(enc1)\n","        enc3 = self.conv3(enc2)\n","        enc4 = self.conv4(enc3)\n","        enc5 = self.conv5(enc4)\n","\n","        dec6 = self.conv6(F.interpolate(enc5, scale_factor=2))\n","        dec6 = self.conv6_2(torch.cat([dec6, enc4\n","                ], 1))\n","\n","        dec7 = self.conv7(F.interpolate(dec6, scale_factor=2))\n","        dec7 = self.conv7_2(torch.cat([dec7, enc3\n","                ], 1))\n","\n","        dec8 = self.conv8(F.interpolate(dec7, scale_factor=2))\n","        dec8 = self.conv8_2(torch.cat([dec8, enc2\n","                ], 1))\n","\n","        dec9 = self.conv9(F.interpolate(dec8, scale_factor=2))\n","        dec9 = self.conv9_2(torch.cat([dec9,\n","                enc1\n","                ], 1))\n","\n","        dec10 = self.conv10(F.interpolate(dec9, scale_factor=2))\n","\n","        return self.res(dec10)\n","\n","\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Linear):\n","                m.weight.data = nn.init.kaiming_normal_(m.weight.data)\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","\n","\n","class SeResNext50_Unet_Double(nn.Module):\n","    def __init__(self, pretrained='imagenet', **kwargs):\n","        super(SeResNext50_Unet_Double, self).__init__()\n","\n","        encoder_filters = [64, 256, 512, 1024, 2048]\n","        decoder_filters = np.asarray([64, 96, 128, 256, 512]) // 2\n","\n","        self.conv6 = ConvRelu(encoder_filters[-1], decoder_filters[-1])\n","        self.conv6_2 = ConvRelu(decoder_filters[-1] + encoder_filters[-2], decoder_filters[-1])\n","        self.conv7 = ConvRelu(decoder_filters[-1], decoder_filters[-2])\n","        self.conv7_2 = ConvRelu(decoder_filters[-2] + encoder_filters[-3], decoder_filters[-2])\n","        self.conv8 = ConvRelu(decoder_filters[-2], decoder_filters[-3])\n","        self.conv8_2 = ConvRelu(decoder_filters[-3] + encoder_filters[-4], decoder_filters[-3])\n","        self.conv9 = ConvRelu(decoder_filters[-3], decoder_filters[-4])\n","        self.conv9_2 = ConvRelu(decoder_filters[-4] + encoder_filters[-5], decoder_filters[-4])\n","        self.conv10 = ConvRelu(decoder_filters[-4], decoder_filters[-5])\n","\n","\n","        self.res = nn.Conv2d(decoder_filters[-5] * 2, 5, 1, stride=1, padding=0)\n","\n","        self._initialize_weights()\n","\n","        encoder = se_resnext50_32x4d(pretrained=pretrained)\n","\n","        # conv1_new = nn.Conv2d(6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","        # _w = encoder.layer0.conv1.state_dict()\n","        # _w['weight'] = torch.cat([0.5 * _w['weight'], 0.5 * _w['weight']], 1)\n","        # conv1_new.load_state_dict(_w)\n","        self.conv1 = nn.Sequential(encoder.layer0.conv1, encoder.layer0.bn1, encoder.layer0.relu1) #encoder.layer0.conv1\n","        self.conv2 = nn.Sequential(encoder.pool, encoder.layer1)\n","        self.conv3 = encoder.layer2\n","        self.conv4 = encoder.layer3\n","        self.conv5 = encoder.layer4\n","\n","\n","    def forward1(self, x):\n","        batch_size, C, H, W = x.shape\n","\n","        enc1 = self.conv1(x)\n","        enc2 = self.conv2(enc1)\n","        enc3 = self.conv3(enc2)\n","        enc4 = self.conv4(enc3)\n","        enc5 = self.conv5(enc4)\n","\n","        dec6 = self.conv6(F.interpolate(enc5, scale_factor=2))\n","        dec6 = self.conv6_2(torch.cat([dec6, enc4\n","                ], 1))\n","\n","        dec7 = self.conv7(F.interpolate(dec6, scale_factor=2))\n","        dec7 = self.conv7_2(torch.cat([dec7, enc3\n","                ], 1))\n","\n","        dec8 = self.conv8(F.interpolate(dec7, scale_factor=2))\n","        dec8 = self.conv8_2(torch.cat([dec8, enc2\n","                ], 1))\n","\n","        dec9 = self.conv9(F.interpolate(dec8, scale_factor=2))\n","        dec9 = self.conv9_2(torch.cat([dec9,\n","                enc1\n","                ], 1))\n","\n","        dec10 = self.conv10(F.interpolate(dec9, scale_factor=2))\n","\n","        return dec10\n","\n","\n","    def forward(self, x):\n","\n","        dec10_0 = self.forward1(x[:, :3, :, :])\n","        dec10_1 = self.forward1(x[:, 3:, :, :])\n","\n","        dec10 = torch.cat([dec10_0, dec10_1], 1)\n","\n","        return self.res(dec10)\n","\n","\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Linear):\n","                m.weight.data = nn.init.kaiming_normal_(m.weight.data)\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","\n","\n","class Dpn92_Unet_Loc(nn.Module):\n","    def __init__(self, pretrained='imagenet+5k', **kwargs):\n","        super(Dpn92_Unet_Loc, self).__init__()\n","\n","        encoder_filters = [64, 336, 704, 1552, 2688]\n","        decoder_filters = np.asarray([64, 96, 128, 256, 512]) // 2\n","\n","        self.conv6 = ConvRelu(encoder_filters[-1], decoder_filters[-1])\n","        self.conv6_2 = nn.Sequential(ConvRelu(decoder_filters[-1]+encoder_filters[-2], decoder_filters[-1]), SCSEModule(decoder_filters[-1], reduction=16, concat=True))\n","        self.conv7 = ConvRelu(decoder_filters[-1] * 2, decoder_filters[-2])\n","        self.conv7_2 = nn.Sequential(ConvRelu(decoder_filters[-2]+encoder_filters[-3], decoder_filters[-2]), SCSEModule(decoder_filters[-2], reduction=16, concat=True))\n","        self.conv8 = ConvRelu(decoder_filters[-2] * 2, decoder_filters[-3])\n","        self.conv8_2 = nn.Sequential(ConvRelu(decoder_filters[-3]+encoder_filters[-4], decoder_filters[-3]), SCSEModule(decoder_filters[-3], reduction=16, concat=True))\n","        self.conv9 = ConvRelu(decoder_filters[-3] * 2, decoder_filters[-4])\n","        self.conv9_2 = nn.Sequential(ConvRelu(decoder_filters[-4]+encoder_filters[-5], decoder_filters[-4]), SCSEModule(decoder_filters[-4], reduction=16, concat=True))\n","        self.conv10 = ConvRelu(decoder_filters[-4] * 2, decoder_filters[-5])\n","\n","        self.res = nn.Conv2d(decoder_filters[-5], 1, 1, stride=1, padding=0)\n","\n","        self._initialize_weights()\n","\n","        encoder = dpn92(pretrained=pretrained)\n","\n","        # conv1_new = nn.Conv2d(6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","        # _w = encoder.blocks['conv1_1'].conv.state_dict()\n","        # _w['weight'] = torch.cat([0.5 * _w['weight'], 0.5 * _w['weight']], 1)\n","        # conv1_new.load_state_dict(_w)\n","\n","        self.conv1 = nn.Sequential(\n","                encoder.blocks['conv1_1'].conv,  # conv\n","                encoder.blocks['conv1_1'].bn,  # bn\n","                encoder.blocks['conv1_1'].act,  # relu\n","            )\n","        self.conv2 = nn.Sequential(\n","                encoder.blocks['conv1_1'].pool,  # maxpool\n","                *[b for k, b in encoder.blocks.items() if k.startswith('conv2_')]\n","            )\n","        self.conv3 = nn.Sequential(*[b for k, b in encoder.blocks.items() if k.startswith('conv3_')])\n","        self.conv4 = nn.Sequential(*[b for k, b in encoder.blocks.items() if k.startswith('conv4_')])\n","        self.conv5 = nn.Sequential(*[b for k, b in encoder.blocks.items() if k.startswith('conv5_')])\n","\n","    def forward(self, x):\n","        batch_size, C, H, W = x.shape\n","\n","        enc1 = self.conv1(x)\n","        enc2 = self.conv2(enc1)\n","        enc3 = self.conv3(enc2)\n","        enc4 = self.conv4(enc3)\n","        enc5 = self.conv5(enc4)\n","\n","        enc1 = (torch.cat(enc1, dim=1) if isinstance(enc1, tuple) else enc1)\n","        enc2 = (torch.cat(enc2, dim=1) if isinstance(enc2, tuple) else enc2)\n","        enc3 = (torch.cat(enc3, dim=1) if isinstance(enc3, tuple) else enc3)\n","        enc4 = (torch.cat(enc4, dim=1) if isinstance(enc4, tuple) else enc4)\n","        enc5 = (torch.cat(enc5, dim=1) if isinstance(enc5, tuple) else enc5)\n","\n","        dec6 = self.conv6(F.interpolate(enc5, scale_factor=2))\n","        dec6 = self.conv6_2(torch.cat([dec6, enc4], 1))\n","\n","        dec7 = self.conv7(F.interpolate(dec6, scale_factor=2))\n","        dec7 = self.conv7_2(torch.cat([dec7, enc3], 1))\n","\n","        dec8 = self.conv8(F.interpolate(dec7, scale_factor=2))\n","        dec8 = self.conv8_2(torch.cat([dec8, enc2], 1))\n","\n","        dec9 = self.conv9(F.interpolate(dec8, scale_factor=2))\n","        dec9 = self.conv9_2(torch.cat([dec9,\n","                enc1], 1))\n","\n","        dec10 = self.conv10(F.interpolate(dec9, scale_factor=2))\n","\n","        return self.res(dec10)\n","\n","\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Linear):\n","                m.weight.data = nn.init.kaiming_normal_(m.weight.data)\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","\n","\n","class Dpn92_Unet_Double(nn.Module):\n","    def __init__(self, pretrained='imagenet+5k', **kwargs):\n","        super(Dpn92_Unet_Double, self).__init__()\n","\n","        encoder_filters = [64, 336, 704, 1552, 2688]\n","        decoder_filters = np.asarray([64, 96, 128, 256, 512]) // 2\n","\n","        self.conv6 = ConvRelu(encoder_filters[-1], decoder_filters[-1])\n","        self.conv6_2 = nn.Sequential(ConvRelu(decoder_filters[-1]+encoder_filters[-2], decoder_filters[-1]), SCSEModule(decoder_filters[-1], reduction=16, concat=True))\n","        self.conv7 = ConvRelu(decoder_filters[-1] * 2, decoder_filters[-2])\n","        self.conv7_2 = nn.Sequential(ConvRelu(decoder_filters[-2]+encoder_filters[-3], decoder_filters[-2]), SCSEModule(decoder_filters[-2], reduction=16, concat=True))\n","        self.conv8 = ConvRelu(decoder_filters[-2] * 2, decoder_filters[-3])\n","        self.conv8_2 = nn.Sequential(ConvRelu(decoder_filters[-3]+encoder_filters[-4], decoder_filters[-3]), SCSEModule(decoder_filters[-3], reduction=16, concat=True))\n","        self.conv9 = ConvRelu(decoder_filters[-3] * 2, decoder_filters[-4])\n","        self.conv9_2 = nn.Sequential(ConvRelu(decoder_filters[-4]+encoder_filters[-5], decoder_filters[-4]), SCSEModule(decoder_filters[-4], reduction=16, concat=True))\n","        self.conv10 = ConvRelu(decoder_filters[-4] * 2, decoder_filters[-5])\n","\n","        self.res = nn.Conv2d(decoder_filters[-5] * 2, 5, 1, stride=1, padding=0)\n","\n","        self._initialize_weights()\n","\n","        encoder = dpn92(pretrained=pretrained)\n","\n","        # conv1_new = nn.Conv2d(6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","        # _w = encoder.blocks['conv1_1'].conv.state_dict()\n","        # _w['weight'] = torch.cat([0.5 * _w['weight'], 0.5 * _w['weight']], 1)\n","        # conv1_new.load_state_dict(_w)\n","\n","        self.conv1 = nn.Sequential(\n","                encoder.blocks['conv1_1'].conv,  # conv\n","                encoder.blocks['conv1_1'].bn,  # bn\n","                encoder.blocks['conv1_1'].act,  # relu\n","            )\n","        self.conv2 = nn.Sequential(\n","                encoder.blocks['conv1_1'].pool,  # maxpool\n","                *[b for k, b in encoder.blocks.items() if k.startswith('conv2_')]\n","            )\n","        self.conv3 = nn.Sequential(*[b for k, b in encoder.blocks.items() if k.startswith('conv3_')])\n","        self.conv4 = nn.Sequential(*[b for k, b in encoder.blocks.items() if k.startswith('conv4_')])\n","        self.conv5 = nn.Sequential(*[b for k, b in encoder.blocks.items() if k.startswith('conv5_')])\n","\n","\n","    def forward1(self, x):\n","        batch_size, C, H, W = x.shape\n","\n","        enc1 = self.conv1(x)\n","        enc2 = self.conv2(enc1)\n","        enc3 = self.conv3(enc2)\n","        enc4 = self.conv4(enc3)\n","        enc5 = self.conv5(enc4)\n","\n","        enc1 = (torch.cat(enc1, dim=1) if isinstance(enc1, tuple) else enc1)\n","        enc2 = (torch.cat(enc2, dim=1) if isinstance(enc2, tuple) else enc2)\n","        enc3 = (torch.cat(enc3, dim=1) if isinstance(enc3, tuple) else enc3)\n","        enc4 = (torch.cat(enc4, dim=1) if isinstance(enc4, tuple) else enc4)\n","        enc5 = (torch.cat(enc5, dim=1) if isinstance(enc5, tuple) else enc5)\n","\n","        dec6 = self.conv6(F.interpolate(enc5, scale_factor=2))\n","        dec6 = self.conv6_2(torch.cat([dec6, enc4], 1))\n","\n","        dec7 = self.conv7(F.interpolate(dec6, scale_factor=2))\n","        dec7 = self.conv7_2(torch.cat([dec7, enc3], 1))\n","\n","        dec8 = self.conv8(F.interpolate(dec7, scale_factor=2))\n","        dec8 = self.conv8_2(torch.cat([dec8, enc2], 1))\n","\n","        dec9 = self.conv9(F.interpolate(dec8, scale_factor=2))\n","        dec9 = self.conv9_2(torch.cat([dec9,\n","                enc1], 1))\n","\n","        dec10 = self.conv10(F.interpolate(dec9, scale_factor=2))\n","\n","        return dec10\n","\n","\n","    def forward(self, x):\n","\n","        dec10_0 = self.forward1(x[:, :3, :, :])\n","        dec10_1 = self.forward1(x[:, 3:, :, :])\n","\n","        dec10 = torch.cat([dec10_0, dec10_1], 1)\n","\n","        return self.res(dec10)\n","\n","\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Linear):\n","                m.weight.data = nn.init.kaiming_normal_(m.weight.data)\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","\n","\n","class Res34_Unet_Loc(nn.Module):\n","    def __init__(self, pretrained=True, **kwargs):\n","        super(Res34_Unet_Loc, self).__init__()\n","\n","        encoder_filters = [64, 64, 128, 256, 512]\n","        decoder_filters = np.asarray([48, 64, 96, 160, 320])\n","\n","        self.conv6 = ConvRelu(encoder_filters[-1], decoder_filters[-1])\n","        self.conv6_2 = ConvRelu(decoder_filters[-1] + encoder_filters[-2], decoder_filters[-1])\n","        self.conv7 = ConvRelu(decoder_filters[-1], decoder_filters[-2])\n","        self.conv7_2 = ConvRelu(decoder_filters[-2] + encoder_filters[-3], decoder_filters[-2])\n","        self.conv8 = ConvRelu(decoder_filters[-2], decoder_filters[-3])\n","        self.conv8_2 = ConvRelu(decoder_filters[-3] + encoder_filters[-4], decoder_filters[-3])\n","        self.conv9 = ConvRelu(decoder_filters[-3], decoder_filters[-4])\n","        self.conv9_2 = ConvRelu(decoder_filters[-4] + encoder_filters[-5], decoder_filters[-4])\n","        self.conv10 = ConvRelu(decoder_filters[-4], decoder_filters[-5])\n","\n","        self.res = nn.Conv2d(decoder_filters[-5], 1, 1, stride=1, padding=0)\n","\n","        self._initialize_weights()\n","\n","        encoder = torchvision.models.resnet34(pretrained=pretrained)\n","        self.conv1 = nn.Sequential(\n","                        encoder.conv1,\n","                        encoder.bn1,\n","                        encoder.relu)\n","        self.conv2 = nn.Sequential(\n","                        encoder.maxpool,\n","                        encoder.layer1)\n","        self.conv3 = encoder.layer2\n","        self.conv4 = encoder.layer3\n","        self.conv5 = encoder.layer4\n","\n","    def forward(self, x):\n","        batch_size, C, H, W = x.shape\n","\n","        enc1 = self.conv1(x)\n","        enc2 = self.conv2(enc1)\n","        enc3 = self.conv3(enc2)\n","        enc4 = self.conv4(enc3)\n","        enc5 = self.conv5(enc4)\n","\n","        dec6 = self.conv6(F.interpolate(enc5, scale_factor=2))\n","        dec6 = self.conv6_2(torch.cat([dec6, enc4\n","                ], 1))\n","\n","        dec7 = self.conv7(F.interpolate(dec6, scale_factor=2))\n","        dec7 = self.conv7_2(torch.cat([dec7, enc3\n","                ], 1))\n","\n","        dec8 = self.conv8(F.interpolate(dec7, scale_factor=2))\n","        dec8 = self.conv8_2(torch.cat([dec8, enc2\n","                ], 1))\n","\n","        dec9 = self.conv9(F.interpolate(dec8, scale_factor=2))\n","        dec9 = self.conv9_2(torch.cat([dec9,\n","                enc1\n","                ], 1))\n","\n","        dec10 = self.conv10(F.interpolate(dec9, scale_factor=2))\n","\n","        return self.res(dec10)\n","\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Linear):\n","                m.weight.data = nn.init.kaiming_normal_(m.weight.data)\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","\n","\n","class Res34_Unet_Double(nn.Module):\n","    def __init__(self, pretrained=True, **kwargs):\n","        super(Res34_Unet_Double, self).__init__()\n","\n","        encoder_filters = [64, 64, 128, 256, 512]\n","        decoder_filters = np.asarray([48, 64, 96, 160, 320])\n","\n","        self.conv6 = ConvRelu(encoder_filters[-1], decoder_filters[-1])\n","        self.conv6_2 = ConvRelu(decoder_filters[-1] + encoder_filters[-2], decoder_filters[-1])\n","        self.conv7 = ConvRelu(decoder_filters[-1], decoder_filters[-2])\n","        self.conv7_2 = ConvRelu(decoder_filters[-2] + encoder_filters[-3], decoder_filters[-2])\n","        self.conv8 = ConvRelu(decoder_filters[-2], decoder_filters[-3])\n","        self.conv8_2 = ConvRelu(decoder_filters[-3] + encoder_filters[-4], decoder_filters[-3])\n","        self.conv9 = ConvRelu(decoder_filters[-3], decoder_filters[-4])\n","        self.conv9_2 = ConvRelu(decoder_filters[-4] + encoder_filters[-5], decoder_filters[-4])\n","        self.conv10 = ConvRelu(decoder_filters[-4], decoder_filters[-5])\n","\n","        self.res = nn.Conv2d(decoder_filters[-5] * 2, 5, 1, stride=1, padding=0)\n","\n","        self._initialize_weights()\n","\n","        encoder = torchvision.models.resnet34(pretrained=pretrained)\n","        self.conv1 = nn.Sequential(\n","                        encoder.conv1,\n","                        encoder.bn1,\n","                        encoder.relu)\n","        self.conv2 = nn.Sequential(\n","                        encoder.maxpool,\n","                        encoder.layer1)\n","        self.conv3 = encoder.layer2\n","        self.conv4 = encoder.layer3\n","        self.conv5 = encoder.layer4\n","\n","    def forward1(self, x):\n","        batch_size, C, H, W = x.shape\n","\n","        enc1 = self.conv1(x)\n","        enc2 = self.conv2(enc1)\n","        enc3 = self.conv3(enc2)\n","        enc4 = self.conv4(enc3)\n","        enc5 = self.conv5(enc4)\n","\n","        dec6 = self.conv6(F.interpolate(enc5, scale_factor=2))\n","        dec6 = self.conv6_2(torch.cat([dec6, enc4\n","                ], 1))\n","\n","        dec7 = self.conv7(F.interpolate(dec6, scale_factor=2))\n","        dec7 = self.conv7_2(torch.cat([dec7, enc3\n","                ], 1))\n","\n","        dec8 = self.conv8(F.interpolate(dec7, scale_factor=2))\n","        dec8 = self.conv8_2(torch.cat([dec8, enc2\n","                ], 1))\n","\n","        dec9 = self.conv9(F.interpolate(dec8, scale_factor=2))\n","        dec9 = self.conv9_2(torch.cat([dec9,\n","                enc1\n","                ], 1))\n","\n","        dec10 = self.conv10(F.interpolate(dec9, scale_factor=2))\n","\n","        return dec10\n","\n","    def forward(self, x):\n","        dec10_0 = self.forward1(x[:, :3, :, :])\n","        dec10_1 = self.forward1(x[:, 3:, :, :])\n","        dec10 = torch.cat([dec10_0, dec10_1], 1)\n","        return self.res(dec10)\n","\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Linear):\n","                m.weight.data = nn.init.kaiming_normal_(m.weight.data)\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","\n","\n","class SeNet154_Unet_Loc(nn.Module):\n","    def __init__(self, pretrained='imagenet', **kwargs):\n","        super(SeNet154_Unet_Loc, self).__init__()\n","\n","        encoder_filters = [128, 256, 512, 1024, 2048]\n","        decoder_filters = np.asarray([48, 64, 96, 160, 320])\n","\n","        self.conv6 = ConvRelu(encoder_filters[-1], decoder_filters[-1])\n","        self.conv6_2 = ConvRelu(decoder_filters[-1] + encoder_filters[-2], decoder_filters[-1])\n","        self.conv7 = ConvRelu(decoder_filters[-1], decoder_filters[-2])\n","        self.conv7_2 = ConvRelu(decoder_filters[-2] + encoder_filters[-3], decoder_filters[-2])\n","        self.conv8 = ConvRelu(decoder_filters[-2], decoder_filters[-3])\n","        self.conv8_2 = ConvRelu(decoder_filters[-3] + encoder_filters[-4], decoder_filters[-3])\n","        self.conv9 = ConvRelu(decoder_filters[-3], decoder_filters[-4])\n","        self.conv9_2 = ConvRelu(decoder_filters[-4] + encoder_filters[-5], decoder_filters[-4])\n","        self.conv10 = ConvRelu(decoder_filters[-4], decoder_filters[-5])\n","\n","        self.res = nn.Conv2d(decoder_filters[-5], 1, 1, stride=1, padding=0)\n","\n","        self._initialize_weights()\n","\n","        encoder = senet154(pretrained=pretrained)\n","\n","        # conv1_new = nn.Conv2d(9, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        # _w = encoder.layer0.conv1.state_dict()\n","        # _w['weight'] = torch.cat([0.8 * _w['weight'], 0.1 * _w['weight'], 0.1 * _w['weight']], 1)\n","        # conv1_new.load_state_dict(_w)\n","        self.conv1 = nn.Sequential(encoder.layer0.conv1, encoder.layer0.bn1, encoder.layer0.relu1, encoder.layer0.conv2, encoder.layer0.bn2, encoder.layer0.relu2, encoder.layer0.conv3, encoder.layer0.bn3, encoder.layer0.relu3)\n","        self.conv2 = nn.Sequential(encoder.pool, encoder.layer1)\n","        self.conv3 = encoder.layer2\n","        self.conv4 = encoder.layer3\n","        self.conv5 = encoder.layer4\n","\n","\n","    def forward(self, x):\n","        batch_size, C, H, W = x.shape\n","\n","        enc1 = self.conv1(x)\n","        enc2 = self.conv2(enc1)\n","        enc3 = self.conv3(enc2)\n","        enc4 = self.conv4(enc3)\n","        enc5 = self.conv5(enc4)\n","\n","        dec6 = self.conv6(F.interpolate(enc5, scale_factor=2))\n","        dec6 = self.conv6_2(torch.cat([dec6, enc4\n","                ], 1))\n","\n","        dec7 = self.conv7(F.interpolate(dec6, scale_factor=2))\n","        dec7 = self.conv7_2(torch.cat([dec7, enc3\n","                ], 1))\n","\n","        dec8 = self.conv8(F.interpolate(dec7, scale_factor=2))\n","        dec8 = self.conv8_2(torch.cat([dec8, enc2\n","                ], 1))\n","\n","        dec9 = self.conv9(F.interpolate(dec8, scale_factor=2))\n","        dec9 = self.conv9_2(torch.cat([dec9,\n","                enc1\n","                ], 1))\n","\n","        dec10 = self.conv10(F.interpolate(dec9, scale_factor=2))\n","\n","        return self.res(dec10)\n","\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Linear):\n","                m.weight.data = nn.init.kaiming_normal_(m.weight.data)\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","\n","\n","class SeNet154_Unet_Double(nn.Module):\n","    def __init__(self, pretrained='imagenet', **kwargs):\n","        super(SeNet154_Unet_Double, self).__init__()\n","\n","        encoder_filters = [128, 256, 512, 1024, 2048]\n","        decoder_filters = np.asarray([48, 64, 96, 160, 320])\n","\n","        self.conv6 = ConvRelu(encoder_filters[-1], decoder_filters[-1])\n","        self.conv6_2 = ConvRelu(decoder_filters[-1] + encoder_filters[-2], decoder_filters[-1])\n","        self.conv7 = ConvRelu(decoder_filters[-1], decoder_filters[-2])\n","        self.conv7_2 = ConvRelu(decoder_filters[-2] + encoder_filters[-3], decoder_filters[-2])\n","        self.conv8 = ConvRelu(decoder_filters[-2], decoder_filters[-3])\n","        self.conv8_2 = ConvRelu(decoder_filters[-3] + encoder_filters[-4], decoder_filters[-3])\n","        self.conv9 = ConvRelu(decoder_filters[-3], decoder_filters[-4])\n","        self.conv9_2 = ConvRelu(decoder_filters[-4] + encoder_filters[-5], decoder_filters[-4])\n","        self.conv10 = ConvRelu(decoder_filters[-4], decoder_filters[-5])\n","\n","        self.res = nn.Conv2d(decoder_filters[-5] * 2, 5, 1, stride=1, padding=0)\n","\n","        self._initialize_weights()\n","\n","        encoder = senet154(pretrained=pretrained)\n","\n","        # conv1_new = nn.Conv2d(9, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        # _w = encoder.layer0.conv1.state_dict()\n","        # _w['weight'] = torch.cat([0.8 * _w['weight'], 0.1 * _w['weight'], 0.1 * _w['weight']], 1)\n","        # conv1_new.load_state_dict(_w)\n","        self.conv1 = nn.Sequential(encoder.layer0.conv1, encoder.layer0.bn1, encoder.layer0.relu1, encoder.layer0.conv2, encoder.layer0.bn2, encoder.layer0.relu2, encoder.layer0.conv3, encoder.layer0.bn3, encoder.layer0.relu3)\n","        self.conv2 = nn.Sequential(encoder.pool, encoder.layer1)\n","        self.conv3 = encoder.layer2\n","        self.conv4 = encoder.layer3\n","        self.conv5 = encoder.layer4\n","\n","    def forward1(self, x):\n","        batch_size, C, H, W = x.shape\n","\n","        enc1 = self.conv1(x)\n","        enc2 = self.conv2(enc1)\n","        enc3 = self.conv3(enc2)\n","        enc4 = self.conv4(enc3)\n","        enc5 = self.conv5(enc4)\n","\n","        dec6 = self.conv6(F.interpolate(enc5, scale_factor=2))\n","        dec6 = self.conv6_2(torch.cat([dec6, enc4\n","                ], 1))\n","\n","        dec7 = self.conv7(F.interpolate(dec6, scale_factor=2))\n","        dec7 = self.conv7_2(torch.cat([dec7, enc3\n","                ], 1))\n","\n","        dec8 = self.conv8(F.interpolate(dec7, scale_factor=2))\n","        dec8 = self.conv8_2(torch.cat([dec8, enc2\n","                ], 1))\n","\n","        dec9 = self.conv9(F.interpolate(dec8, scale_factor=2))\n","        dec9 = self.conv9_2(torch.cat([dec9,\n","                enc1\n","                ], 1))\n","\n","        dec10 = self.conv10(F.interpolate(dec9, scale_factor=2))\n","\n","        return dec10\n","\n","    def forward(self, x):\n","\n","        dec10_0 = self.forward1(x[:, :3, :, :])\n","        dec10_1 = self.forward1(x[:, 3:, :, :])\n","\n","        dec10 = torch.cat([dec10_0, dec10_1], 1)\n","\n","        return self.res(dec10)\n","\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Linear):\n","                m.weight.data = nn.init.kaiming_normal_(m.weight.data)\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()"]},{"cell_type":"markdown","metadata":{"id":"FXa807PbTjxn"},"source":["## Utils"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7Fs2XBvfToVf"},"outputs":[],"source":["import numpy as np\n","import cv2\n","\n","#### Augmentations\n","def shift_image(img, shift_pnt):\n","    M = np.float32([[1, 0, shift_pnt[0]], [0, 1, shift_pnt[1]]])\n","    res = cv2.warpAffine(img, M, (img.shape[1], img.shape[0]), borderMode=cv2.BORDER_REFLECT_101)\n","    return res\n","\n","\n","def rotate_image(image, angle, scale, rot_pnt):\n","    rot_mat = cv2.getRotationMatrix2D(rot_pnt, angle, scale)\n","    result = cv2.warpAffine(image, rot_mat, (image.shape[1], image.shape[0]), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT_101) #INTER_NEAREST\n","    return result\n","\n","\n","def gauss_noise(img, var=30):\n","    row, col, ch = img.shape\n","    mean = var\n","    sigma = var**0.5\n","    gauss = np.random.normal(mean,sigma,(row,col,ch))\n","    gauss = gauss.reshape(row,col,ch)\n","    gauss = (gauss - np.min(gauss)).astype(np.uint8)\n","    return np.clip(img.astype(np.int32) + gauss, 0, 255).astype('uint8')\n","\n","\n","def clahe(img, clipLimit=2.0, tileGridSize=(5,5)):\n","    img_yuv = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n","    clahe = cv2.createCLAHE(clipLimit=clipLimit, tileGridSize=tileGridSize)\n","    img_yuv[:, :, 0] = clahe.apply(img_yuv[:, :, 0])\n","    img_output = cv2.cvtColor(img_yuv, cv2.COLOR_LAB2RGB)\n","    return img_output\n","\n","\n","def _blend(img1, img2, alpha):\n","    return np.clip(img1 * alpha + (1 - alpha) * img2, 0, 255).astype('uint8')\n","\n","\n","_alpha = np.asarray([0.114, 0.587, 0.299]).reshape((1, 1, 3))\n","def _grayscale(img):\n","    return np.sum(_alpha * img, axis=2, keepdims=True)\n","\n","\n","def saturation(img, alpha):\n","    gs = _grayscale(img)\n","    return _blend(img, gs, alpha)\n","\n","\n","def brightness(img, alpha):\n","    gs = np.zeros_like(img)\n","    return _blend(img, gs, alpha)\n","\n","\n","def contrast(img, alpha):\n","    gs = _grayscale(img)\n","    gs = np.repeat(gs.mean(), 3)\n","    return _blend(img, gs, alpha)\n","\n","\n","def change_hsv(img, h, s, v):\n","    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n","    hsv = hsv.astype(int)\n","    hsv[:,:,0] += h\n","    hsv[:,:,0] = np.clip(hsv[:,:,0], 0, 255)\n","    hsv[:,:,1] += s\n","    hsv[:,:,1] = np.clip(hsv[:,:,1], 0, 255)\n","    hsv[:,:,2] += v\n","    hsv[:,:,2] = np.clip(hsv[:,:,2], 0, 255)\n","    hsv = hsv.astype('uint8')\n","    img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n","    return img\n","\n","def shift_channels(img, b_shift, g_shift, r_shift):\n","    img = img.astype(int)\n","    img[:,:,0] += b_shift\n","    img[:,:,0] = np.clip(img[:,:,0], 0, 255)\n","    img[:,:,1] += g_shift\n","    img[:,:,1] = np.clip(img[:,:,1], 0, 255)\n","    img[:,:,2] += r_shift\n","    img[:,:,2] = np.clip(img[:,:,2], 0, 255)\n","    img = img.astype('uint8')\n","    return img\n","\n","def invert(img):\n","    return 255 - img\n","\n","def channel_shuffle(img):\n","    ch_arr = [0, 1, 2]\n","    np.random.shuffle(ch_arr)\n","    img = img[..., ch_arr]\n","    return img\n","\n","#######\n","\n","\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","\n","def preprocess_inputs(x):\n","    x = np.asarray(x, dtype='float32')\n","    x /= 127\n","    x -= 1\n","    return x\n","\n","\n","def dice(im1, im2, empty_score=1.0):\n","    \"\"\"\n","    Computes the Dice coefficient, a measure of set similarity.\n","    Parameters\n","    ----------\n","    im1 : array-like, bool\n","        Any array of arbitrary size. If not boolean, will be converted.\n","    im2 : array-like, bool\n","        Any other array of identical size. If not boolean, will be converted.\n","    Returns\n","    -------\n","    dice : float\n","        Dice coefficient as a float on range [0,1].\n","        Maximum similarity = 1\n","        No similarity = 0\n","        Both are empty (sum eq to zero) = empty_score\n","\n","    Notes\n","    -----\n","    The order of inputs for `dice` is irrelevant. The result will be\n","    identical if `im1` and `im2` are switched.\n","    \"\"\"\n","    im1 = np.asarray(im1).astype(np.bool)\n","    im2 = np.asarray(im2).astype(np.bool)\n","\n","    if im1.shape != im2.shape:\n","        raise ValueError(\"Shape mismatch: im1 and im2 must have the same shape.\")\n","\n","    im_sum = im1.sum() + im2.sum()\n","    if im_sum == 0:\n","        return empty_score\n","\n","    # Compute Dice coefficient\n","    intersection = np.logical_and(im1, im2)\n","\n","    return 2. * intersection.sum() / im_sum\n","\n","\n","def iou(im1, im2, empty_score=1.0):\n","    im1 = np.asarray(im1).astype(np.bool)\n","    im2 = np.asarray(im2).astype(np.bool)\n","\n","    if im1.shape != im2.shape:\n","        raise ValueError(\"Shape mismatch: im1 and im2 must have the same shape.\")\n","\n","    union = np.logical_or(im1, im2)\n","    im_sum = union.sum()\n","    if im_sum == 0:\n","        return empty_score\n","\n","    # Compute Dice coefficient\n","    intersection = np.logical_and(im1, im2)\n","\n","    return intersection.sum() / im_sum"]},{"cell_type":"markdown","metadata":{"id":"Ifa7HjK2FVf3"},"source":["## modelMscale"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RoOkAXB2n4nS"},"outputs":[],"source":["import numpy as np\n","from tensorflow.keras import Model\n","from tensorflow.keras.layers import Conv2D, Activation, UpSampling2D, Concatenate, Input\n","from tensorflow.keras.applications import ResNet50\n","from tensorflow.keras.initializers import HeNormal\n","from tensorflow.keras import backend as K\n","\n","class ConvRelu(nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size=3):\n","        super(ConvRelu, self).__init__()\n","        self.layer = nn.Sequential(\n","            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, padding=1),\n","            nn.ReLU(inplace=True, )\n","        )\n","    #@autocast()\n","    def forward(self, x):\n","        return self.layer(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sDIsasbMn5W8"},"outputs":[],"source":["\"\"\"\n","ResNet code gently borrowed from\n","https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py\n","\"\"\"\n","\n","from collections import OrderedDict\n","import math\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils import model_zoo\n","\n","__all__ = ['SENet', 'senet154', 'se_resnet50', 'se_resnet101', 'se_resnet152',\n","           'se_resnext50_32x4d', 'se_resnext101_32x4d']\n","\n","pretrained_settings = {\n","    'senet154': {\n","        'imagenet': {\n","            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/senet154-c7b49a05.pth',\n","            'input_space': 'RGB',\n","            'input_size': [3, 224, 224],\n","            'input_range': [0, 1],\n","            'mean': [0.485, 0.456, 0.406],\n","            'std': [0.229, 0.224, 0.225],\n","            'num_classes': 1000\n","        }\n","    },\n","    'se_resnet50': {\n","        'imagenet': {\n","            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnet50-ce0d4300.pth',\n","            'input_space': 'RGB',\n","            'input_size': [3, 224, 224],\n","            'input_range': [0, 1],\n","            'mean': [0.485, 0.456, 0.406],\n","            'std': [0.229, 0.224, 0.225],\n","            'num_classes': 1000\n","        }\n","    },\n","    'se_resnet101': {\n","        'imagenet': {\n","            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnet101-7e38fcc6.pth',\n","            'input_space': 'RGB',\n","            'input_size': [3, 224, 224],\n","            'input_range': [0, 1],\n","            'mean': [0.485, 0.456, 0.406],\n","            'std': [0.229, 0.224, 0.225],\n","            'num_classes': 1000\n","        }\n","    },\n","    'se_resnet152': {\n","        'imagenet': {\n","            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnet152-d17c99b7.pth',\n","            'input_space': 'RGB',\n","            'input_size': [3, 224, 224],\n","            'input_range': [0, 1],\n","            'mean': [0.485, 0.456, 0.406],\n","            'std': [0.229, 0.224, 0.225],\n","            'num_classes': 1000\n","        }\n","    },\n","    'se_resnext50_32x4d': {\n","        'imagenet': {\n","            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnext50_32x4d-a260b3a4.pth',\n","            'input_space': 'RGB',\n","            'input_size': [3, 224, 224],\n","            'input_range': [0, 1],\n","            'mean': [0.485, 0.456, 0.406],\n","            'std': [0.229, 0.224, 0.225],\n","            'num_classes': 1000\n","        }\n","    },\n","    'se_resnext101_32x4d': {\n","        'imagenet': {\n","            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnext101_32x4d-3b2fe3d8.pth',\n","            'input_space': 'RGB',\n","            'input_size': [3, 224, 224],\n","            'input_range': [0, 1],\n","            'mean': [0.485, 0.456, 0.406],\n","            'std': [0.229, 0.224, 0.225],\n","            'num_classes': 1000\n","        }\n","    },\n","}\n","\n","\n","class SEModule(nn.Module):\n","\n","    def __init__(self, channels, reduction, concat=False):\n","        super(SEModule, self).__init__()\n","        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n","        self.fc1 = nn.Conv2d(channels, channels // reduction, kernel_size=1,\n","                             padding=0)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.fc2 = nn.Conv2d(channels // reduction, channels, kernel_size=1,\n","                             padding=0)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        module_input = x\n","        x = self.avg_pool(x)\n","        x = self.fc1(x)\n","        x = self.relu(x)\n","        x = self.fc2(x)\n","        x = self.sigmoid(x)\n","        return module_input * x\n","\n","class SCSEModule(nn.Module):\n","    # according to https://arxiv.org/pdf/1808.08127.pdf concat is better\n","    def __init__(self, channels, reduction=16, concat=False):\n","        super(SCSEModule, self).__init__()\n","        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n","        self.fc1 = nn.Conv2d(channels, channels // reduction, kernel_size=1,\n","                             padding=0)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.fc2 = nn.Conv2d(channels // reduction, channels, kernel_size=1,\n","                             padding=0)\n","        self.sigmoid = nn.Sigmoid()\n","\n","        self.spatial_se = nn.Sequential(nn.Conv2d(channels, 1, kernel_size=1,\n","                                                  stride=1, padding=0, bias=False),\n","                                        nn.Sigmoid())\n","        self.concat = concat\n","\n","    def forward(self, x):\n","        module_input = x\n","\n","        x = self.avg_pool(x)\n","        x = self.fc1(x)\n","        x = self.relu(x)\n","        x = self.fc2(x)\n","        chn_se = self.sigmoid(x)\n","        chn_se = chn_se * module_input\n","\n","        spa_se = self.spatial_se(module_input)\n","        spa_se = module_input * spa_se\n","        if self.concat:\n","            return torch.cat([chn_se, spa_se], dim=1)\n","        else:\n","            return chn_se + spa_se\n","\n","class Bottleneck(nn.Module):\n","    \"\"\"\n","    Base class for bottlenecks that implements `forward()` method.\n","    \"\"\"\n","    def forward(self, x):\n","        residual = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out = self.relu(out)\n","\n","        out = self.conv3(out)\n","        out = self.bn3(out)\n","\n","        if self.downsample is not None:\n","            residual = self.downsample(x)\n","\n","        out = self.se_module(out) + residual\n","        out = self.relu(out)\n","\n","        return out\n","\n","\n","class SEBottleneck(Bottleneck):\n","    \"\"\"\n","    Bottleneck for SENet154.\n","    \"\"\"\n","    expansion = 4\n","\n","    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n","                 downsample=None):\n","        super(SEBottleneck, self).__init__()\n","        self.conv1 = nn.Conv2d(inplanes, planes * 2, kernel_size=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes * 2)\n","        self.conv2 = nn.Conv2d(planes * 2, planes * 4, kernel_size=3,\n","                               stride=stride, padding=1, groups=groups,\n","                               bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes * 4)\n","        self.conv3 = nn.Conv2d(planes * 4, planes * 4, kernel_size=1,\n","                               bias=False)\n","        self.bn3 = nn.BatchNorm2d(planes * 4)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.se_module = SEModule(planes * 4, reduction=reduction)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","\n","class SCSEBottleneck(Bottleneck):\n","    \"\"\"\n","    Bottleneck for SENet154.\n","    \"\"\"\n","    expansion = 4\n","\n","    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n","                 downsample=None):\n","        super(SCSEBottleneck, self).__init__()\n","        self.conv1 = nn.Conv2d(inplanes, planes * 2, kernel_size=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes * 2)\n","        self.conv2 = nn.Conv2d(planes * 2, planes * 4, kernel_size=3,\n","                               stride=stride, padding=1, groups=groups,\n","                               bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes * 4)\n","        self.conv3 = nn.Conv2d(planes * 4, planes * 4, kernel_size=1,\n","                               bias=False)\n","        self.bn3 = nn.BatchNorm2d(planes * 4)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.se_module = SCSEModule(planes * 4, reduction=reduction)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","\n","class SEResNetBottleneck(Bottleneck):\n","    \"\"\"\n","    ResNet bottleneck with a Squeeze-and-Excitation module. It follows Caffe\n","    implementation and uses `stride=stride` in `conv1` and not in `conv2`\n","    (the latter is used in the torchvision implementation of ResNet).\n","    \"\"\"\n","    expansion = 4\n","\n","    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n","                 downsample=None):\n","        super(SEResNetBottleneck, self).__init__()\n","        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False,\n","                               stride=stride)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, padding=1,\n","                               groups=groups, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(planes * 4)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.se_module = SEModule(planes * 4, reduction=reduction)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","\n","class SEResNeXtBottleneck(Bottleneck):\n","    \"\"\"\n","    ResNeXt bottleneck type C with a Squeeze-and-Excitation module.\n","    \"\"\"\n","    expansion = 4\n","\n","    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n","                 downsample=None, base_width=4):\n","        super(SEResNeXtBottleneck, self).__init__()\n","        width = math.floor(planes * (base_width / 64)) * groups\n","        self.conv1 = nn.Conv2d(inplanes, width, kernel_size=1, bias=False,\n","                               stride=1)\n","        self.bn1 = nn.BatchNorm2d(width)\n","        self.conv2 = nn.Conv2d(width, width, kernel_size=3, stride=stride,\n","                               padding=1, groups=groups, bias=False)\n","        self.bn2 = nn.BatchNorm2d(width)\n","        self.conv3 = nn.Conv2d(width, planes * 4, kernel_size=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(planes * 4)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.se_module = SEModule(planes * 4, reduction=reduction)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","\n","\n","class SCSEResNeXtBottleneck(Bottleneck):\n","    \"\"\"\n","    ResNeXt bottleneck type C with a Concurrent Spatial Squeeze-and-Excitation module.\n","    \"\"\"\n","    expansion = 4\n","\n","    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n","                 downsample=None, base_width=4, final=False):\n","        super(SCSEResNeXtBottleneck, self).__init__()\n","        width = math.floor(planes * (base_width / 64)) * groups\n","        self.conv1 = nn.Conv2d(inplanes, width, kernel_size=1, bias=False,\n","                               stride=1)\n","        self.bn1 = nn.BatchNorm2d(width)\n","        self.conv2 = nn.Conv2d(width, width, kernel_size=3, stride=stride,\n","                               padding=1, groups=groups, bias=False)\n","        self.bn2 = nn.BatchNorm2d(width)\n","        self.conv3 = nn.Conv2d(width, planes * 4, kernel_size=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(planes * 4)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.se_module = SCSEModule(planes * 4, reduction=reduction)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","\n","class SENet(nn.Module):\n","\n","    def __init__(self, block, layers, groups, reduction, dropout_p=0.2,\n","                 inplanes=128, input_3x3=True, downsample_kernel_size=3,\n","                 downsample_padding=1, num_classes=1000):\n","        \"\"\"\n","        Parameters\n","        ----------\n","        block (nn.Module): Bottleneck class.\n","            - For SENet154: SEBottleneck\n","            - For SE-ResNet models: SEResNetBottleneck\n","            - For SE-ResNeXt models:  SEResNeXtBottleneck\n","        layers (list of ints): Number of residual blocks for 4 layers of the\n","            network (layer1...layer4).\n","        groups (int): Number of groups for the 3x3 convolution in each\n","            bottleneck block.\n","            - For SENet154: 64\n","            - For SE-ResNet models: 1\n","            - For SE-ResNeXt models:  32\n","        reduction (int): Reduction ratio for Squeeze-and-Excitation modules.\n","            - For all models: 16\n","        dropout_p (float or None): Drop probability for the Dropout layer.\n","            If `None` the Dropout layer is not used.\n","            - For SENet154: 0.2\n","            - For SE-ResNet models: None\n","            - For SE-ResNeXt models: None\n","        inplanes (int):  Number of input channels for layer1.\n","            - For SENet154: 128\n","            - For SE-ResNet models: 64\n","            - For SE-ResNeXt models: 64\n","        input_3x3 (bool): If `True`, use three 3x3 convolutions instead of\n","            a single 7x7 convolution in layer0.\n","            - For SENet154: True\n","            - For SE-ResNet models: False\n","            - For SE-ResNeXt models: False\n","        downsample_kernel_size (int): Kernel size for downsampling convolutions\n","            in layer2, layer3 and layer4.\n","            - For SENet154: 3\n","            - For SE-ResNet models: 1\n","            - For SE-ResNeXt models: 1\n","        downsample_padding (int): Padding for downsampling convolutions in\n","            layer2, layer3 and layer4.\n","            - For SENet154: 1\n","            - For SE-ResNet models: 0\n","            - For SE-ResNeXt models: 0\n","        num_classes (int): Number of outputs in `last_linear` layer.\n","            - For all models: 1000\n","        \"\"\"\n","        super(SENet, self).__init__()\n","        self.inplanes = inplanes\n","        if input_3x3:\n","            layer0_modules = [\n","                ('conv1', nn.Conv2d(3, 64, 3, stride=2, padding=1,\n","                                    bias=False)),\n","                ('bn1', nn.BatchNorm2d(64)),\n","                ('relu1', nn.ReLU(inplace=True)),\n","                ('conv2', nn.Conv2d(64, 64, 3, stride=1, padding=1,\n","                                    bias=False)),\n","                ('bn2', nn.BatchNorm2d(64)),\n","                ('relu2', nn.ReLU(inplace=True)),\n","                ('conv3', nn.Conv2d(64, inplanes, 3, stride=1, padding=1,\n","                                    bias=False)),\n","                ('bn3', nn.BatchNorm2d(inplanes)),\n","                ('relu3', nn.ReLU(inplace=True)),\n","            ]\n","        else:\n","            layer0_modules = [\n","                ('conv1', nn.Conv2d(3, inplanes, kernel_size=7, stride=2,\n","                                    padding=3, bias=False)),\n","                ('bn1', nn.BatchNorm2d(inplanes)),\n","                ('relu1', nn.ReLU(inplace=True)),\n","            ]\n","        # To preserve compatibility with Caffe weights `ceil_mode=True`\n","        # is used instead of `padding=1`.\n","        self.pool = nn.MaxPool2d(3, stride=2, ceil_mode=True)\n","        self.layer0 = nn.Sequential(OrderedDict(layer0_modules))\n","        self.layer1 = self._make_layer(\n","            block,\n","            planes=64,\n","            blocks=layers[0],\n","            groups=groups,\n","            reduction=reduction,\n","            downsample_kernel_size=1,\n","            downsample_padding=0\n","        )\n","        self.layer2 = self._make_layer(\n","            block,\n","            planes=128,\n","            blocks=layers[1],\n","            stride=2,\n","            groups=groups,\n","            reduction=reduction,\n","            downsample_kernel_size=downsample_kernel_size,\n","            downsample_padding=downsample_padding\n","        )\n","        self.layer3 = self._make_layer(\n","            block,\n","            planes=256,\n","            blocks=layers[2],\n","            stride=2,\n","            groups=groups,\n","            reduction=reduction,\n","            downsample_kernel_size=downsample_kernel_size,\n","            downsample_padding=downsample_padding\n","        )\n","        self.layer4 = self._make_layer(\n","            block,\n","            planes=512,\n","            blocks=layers[3],\n","            stride=2,\n","            groups=groups,\n","            reduction=reduction,\n","            downsample_kernel_size=downsample_kernel_size,\n","            downsample_padding=downsample_padding\n","        )\n","        self.avg_pool = nn.AvgPool2d(7, stride=1)\n","        self.dropout = nn.Dropout(dropout_p) if dropout_p is not None else None\n","        self.last_linear = nn.Linear(512 * block.expansion, num_classes)\n","        self._initialize_weights()\n","\n","    def _make_layer(self, block, planes, blocks, groups, reduction, stride=1,\n","                    downsample_kernel_size=1, downsample_padding=0):\n","        downsample = None\n","        if stride != 1 or self.inplanes != planes * block.expansion:\n","            downsample = nn.Sequential(\n","                nn.Conv2d(self.inplanes, planes * block.expansion,\n","                          kernel_size=downsample_kernel_size, stride=stride,\n","                          padding=downsample_padding, bias=False),\n","                nn.BatchNorm2d(planes * block.expansion),\n","            )\n","\n","        layers = []\n","        layers.append(block(self.inplanes, planes, groups, reduction, stride,\n","                            downsample))\n","        self.inplanes = planes * block.expansion\n","        for i in range(1, blocks):\n","            layers.append(block(self.inplanes, planes, groups, reduction))\n","\n","        return nn.Sequential(*layers)\n","\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n","                m.weight.data = nn.init.kaiming_normal_(m.weight.data)\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","\n","    def features(self, x):\n","        x = self.layer0(x)\n","        x = self.pool(x)\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","        return x\n","\n","    def logits(self, x):\n","        x = self.avg_pool(x)\n","        if self.dropout is not None:\n","            x = self.dropout(x)\n","        x = x.view(x.size(0), -1)\n","        x = self.last_linear(x)\n","        return x\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = self.logits(x)\n","        return x\n","\n","\n","def initialize_pretrained_model(model, num_classes, settings):\n","    assert num_classes == settings['num_classes'], \\\n","        'num_classes should be {}, but is {}'.format(\n","            settings['num_classes'], num_classes)\n","    model.load_state_dict(model_zoo.load_url(settings['url']), strict=False)\n","    model.input_space = settings['input_space']\n","    model.input_size = settings['input_size']\n","    model.input_range = settings['input_range']\n","    model.mean = settings['mean']\n","    model.std = settings['std']\n","\n","\n","def senet154(num_classes=1000, pretrained='imagenet'):\n","    model = SENet(SEBottleneck, [3, 8, 36, 3], groups=64, reduction=16,\n","                  dropout_p=0.2, num_classes=num_classes)\n","    if pretrained is not None:\n","        settings = pretrained_settings['senet154'][pretrained]\n","        initialize_pretrained_model(model, num_classes, settings)\n","    return model\n","\n","def scsenet154(num_classes=1000, pretrained='imagenet'):\n","    print(\"scsenet154\")\n","    model = SENet(SCSEBottleneck, [3, 8, 36, 3], groups=64, reduction=16,\n","                  dropout_p=0.2, num_classes=num_classes)\n","    if pretrained is not None:\n","        settings = pretrained_settings['senet154'][pretrained]\n","        initialize_pretrained_model(model, num_classes, settings)\n","    return model\n","\n","\n","def se_resnet50(num_classes=1000, pretrained='imagenet'):\n","    model = SENet(SEResNetBottleneck, [3, 4, 6, 3], groups=1, reduction=16,\n","                  dropout_p=None, inplanes=64, input_3x3=False,\n","                  downsample_kernel_size=1, downsample_padding=0,\n","                  num_classes=num_classes)\n","    if pretrained is not None:\n","        settings = pretrained_settings['se_resnet50'][pretrained]\n","        initialize_pretrained_model(model, num_classes, settings)\n","    return model\n","\n","\n","def se_resnet101(num_classes=1000, pretrained='imagenet'):\n","    model = SENet(SEResNetBottleneck, [3, 4, 23, 3], groups=1, reduction=16,\n","                  dropout_p=None, inplanes=64, input_3x3=False,\n","                  downsample_kernel_size=1, downsample_padding=0,\n","                  num_classes=num_classes)\n","    if pretrained is not None:\n","        settings = pretrained_settings['se_resnet101'][pretrained]\n","        initialize_pretrained_model(model, num_classes, settings)\n","    return model\n","\n","\n","def se_resnet152(num_classes=1000, pretrained='imagenet'):\n","    model = SENet(SEResNetBottleneck, [3, 8, 36, 3], groups=1, reduction=16,\n","                  dropout_p=None, inplanes=64, input_3x3=False,\n","                  downsample_kernel_size=1, downsample_padding=0,\n","                  num_classes=num_classes)\n","    if pretrained is not None:\n","        settings = pretrained_settings['se_resnet152'][pretrained]\n","        initialize_pretrained_model(model, num_classes, settings)\n","    return model\n","\n","\n","def se_resnext50_32x4d(num_classes=1000, pretrained='imagenet'):\n","    model = SENet(SEResNeXtBottleneck, [3, 4, 6, 3], groups=32, reduction=16,\n","                  dropout_p=None, inplanes=64, input_3x3=False,\n","                  downsample_kernel_size=1, downsample_padding=0,\n","                  num_classes=num_classes)\n","    if pretrained is not None:\n","        settings = pretrained_settings['se_resnext50_32x4d'][pretrained]\n","        initialize_pretrained_model(model, num_classes, settings)\n","    return model\n","\n","\n","def scse_resnext50_32x4d(num_classes=1000, pretrained='imagenet'):\n","    model = SENet(SCSEResNeXtBottleneck, [3, 4, 6, 3], groups=32, reduction=16,\n","                  dropout_p=None, inplanes=64, input_3x3=False,\n","                  downsample_kernel_size=1, downsample_padding=0,\n","                  num_classes=num_classes)\n","    if pretrained is not None:\n","        settings = pretrained_settings['se_resnext50_32x4d'][pretrained]\n","        initialize_pretrained_model(model, num_classes, settings)\n","    return model\n","\n","\n","def se_resnext101_32x4d(num_classes=1000, pretrained='imagenet'):\n","    model = SENet(SEResNeXtBottleneck, [3, 4, 23, 3], groups=32, reduction=16,\n","                  dropout_p=None, inplanes=64, input_3x3=False,\n","                  downsample_kernel_size=1, downsample_padding=0,\n","                  num_classes=num_classes)\n","    if pretrained is not None:\n","        settings = pretrained_settings['se_resnext101_32x4d'][pretrained]\n","        initialize_pretrained_model(model, num_classes, settings)\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YEmiREpPoCWI"},"outputs":[],"source":["class SeResNext50_Unet_2Ssum(nn.Module):\n","    def __init__(self, pretrained='imagenet', **kwargs):\n","        super(SeResNext50_Unet_2Ssum, self).__init__()\n","\n","        encoder_filters = [64, 256, 512, 1024, 2048]\n","        decoder_filters = np.asarray([64, 96, 128, 256, 512]) // 2\n","\n","        self.conv6 = ConvRelu(encoder_filters[-1], decoder_filters[-1])\n","        self.conv6_2 = ConvRelu(decoder_filters[-1] + encoder_filters[-2], decoder_filters[-1])\n","        self.conv7 = ConvRelu(decoder_filters[-1], decoder_filters[-2])\n","        self.conv7_2 = ConvRelu(decoder_filters[-2] + encoder_filters[-3] , decoder_filters[-2] )\n","        self.conv8 = ConvRelu(decoder_filters[-2], decoder_filters[-3])\n","        self.conv8_2 = ConvRelu(decoder_filters[-3] + encoder_filters[-4] , decoder_filters[-3])\n","        self.conv9 = ConvRelu(decoder_filters[-3], decoder_filters[-4])\n","        self.conv9_2 = ConvRelu(decoder_filters[-4] + encoder_filters[-5], decoder_filters[-4])\n","\n","        # self.convx9_3 = ConvRelu(encoder_filters[-4], encoder_filters[-4])\n","\n","\n","        self.conv10 = ConvRelu(decoder_filters[-4], decoder_filters[-5])\n","        self.conv10_s = nn.Sequential(ConvRelu(decoder_filters[-5], decoder_filters[-5]),\n","                                      nn.Conv2d(decoder_filters[-5] , 1, 1, stride=1, padding=0),\n","                                      nn.Sigmoid())\n","        # self.convxx = nn.Sequential(ConvRelu(decoder_filters[-5]*2, decoder_filters[-5]*2),\n","        #                             nn.Conv2d(decoder_filters[-5] * 2, decoder_filters[-5], 1, stride=1, padding=0))\n","\n","        self.res = nn.Conv2d(decoder_filters[-5] * 2, 5, 1, stride=1, padding=0)\n","\n","        self._initialize_weights()\n","\n","        encoder = se_resnext50_32x4d(pretrained=pretrained)\n","        #encoder = torchvision.models.resnet50(pretrained=pretrained)\n","        self.conv1 = nn.Sequential(encoder.layer0.conv1, encoder.layer0.bn1, encoder.layer0.relu1) #encoder.layer0.conv1\n","        self.conv2 = nn.Sequential(encoder.pool, encoder.layer1)\n","        self.conv3 = encoder.layer2\n","        self.conv4 = encoder.layer3\n","        self.conv5 = encoder.layer4\n","\n","\n","    def forward1(self, x):\n","        batch_size, C, H, W = x.shape\n","        xx = F.interpolate(x, scale_factor=0.5, mode='bilinear', align_corners=False)\n","\n","        enc1 = self.conv1(x)\n","        enc2 = self.conv2(enc1)\n","        enc3 = self.conv3(enc2)\n","        enc4 = self.conv4(enc3)\n","        enc5 = self.conv5(enc4)\n","\n","        encx1 = self.conv1(xx)   # 64 128 128\n","        encx2 = self.conv2(encx1) # 64\n","        encx3 = self.conv3(encx2) # 32\n","        encx4 = self.conv4(encx3) # 16\n","        encx5 = self.conv5(encx4) # 8\n","\n","        dec6 = self.conv6(F.interpolate(enc5, scale_factor=2))\n","        dec6 = self.conv6_2(torch.cat([dec6, enc4 ], 1))\n","        dec7 = self.conv7(F.interpolate(dec6, scale_factor=2))\n","        dec7 = self.conv7_2(torch.cat([dec7, enc3], 1))\n","        dec8 = self.conv8(F.interpolate(dec7, scale_factor=2))\n","        dec8 = self.conv8_2(torch.cat([dec8, enc2], 1))\n","        dec9 = self.conv9(F.interpolate(dec8, scale_factor=2))\n","        dec9 = self.conv9_2(torch.cat([dec9,  enc1], 1))   #256\n","\n","        decx6 = self.conv6(F.interpolate(encx5, scale_factor=2))\n","        decx6 = self.conv6_2(torch.cat([decx6, encx4 ], 1))\n","        decx7 = self.conv7(F.interpolate(decx6, scale_factor=2))\n","        decx7 = self.conv7_2(torch.cat([decx7, encx3], 1))\n","        decx8 = self.conv8(F.interpolate(decx7, scale_factor=2))\n","        decx8 = self.conv8_2(torch.cat([decx8, encx2], 1))\n","        decx9 = self.conv9(F.interpolate(decx8, scale_factor=2))\n","        decx9 = self.conv9_2(torch.cat([decx9,  encx1], 1))   #128\n","        #decx9 = self.convx9_3(F.interpolate(decx9, scale_factor=4))\n","\n","\n","        dec10 = self.conv10(F.interpolate(dec9, scale_factor=2))\n","        alpha = self.conv10_s(dec10)\n","        decx10 = self.conv10(F.interpolate(decx9, scale_factor=4))\n","\n","        dec = alpha * dec10 + (1-alpha)*decx10\n","\n","        return dec\n","\n","    def forward(self, x):\n","        dec10_0 = self.forward1(x[:, :3, :, :])\n","        dec10_1 = self.forward1(x[:, 3:, :, :])\n","\n","        dec10 = torch.cat([dec10_0, dec10_1], 1)\n","\n","        return self.res(dec10)\n","\n","\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Linear):\n","                m.weight.data = nn.init.kaiming_normal_(m.weight.data)\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()"]},{"cell_type":"markdown","metadata":{"id":"Jbp9HIBOoO4H"},"source":["## modelMscale2"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4178,"status":"ok","timestamp":1685458792613,"user":{"displayName":"Antonio Santos","userId":"03265893617080544823"},"user_tz":180},"id":"8FP0bCaeP1Qw","outputId":"ec45231b-3ca6-408b-d575-a7002880a737"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: thop in /usr/local/lib/python3.10/dist-packages (0.1.1.post2209072238)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from thop) (2.0.1+cu118)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch-\u003ethop) (3.12.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch-\u003ethop) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch-\u003ethop) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch-\u003ethop) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-\u003ethop) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch-\u003ethop) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-\u003etorch-\u003ethop) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-\u003etorch-\u003ethop) (16.0.5)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-\u003etorch-\u003ethop) (2.1.2)\n","Requirement already satisfied: mpmath\u003e=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy-\u003etorch-\u003ethop) (1.3.0)\n"]}],"source":["!pip install thop"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BzErVOmmFYtF"},"outputs":[],"source":["import numpy as np\n","\n","import torch\n","from torch import nn\n","import torch.nn.functional as F\n","import torchvision.models\n","#import apex\n","import apex.parallel.sync_batchnorm as BN\n","#from .dpn import dpn92\n","from torch.nn.parameter import Parameter\n","from thop import profile\n","#from .antialias import Downsample as downsamp\n","\n","class ResidualDownSample(nn.Module):\n","    def __init__(self, in_channels, bias=False):\n","        super(ResidualDownSample, self).__init__()\n","        self.bot = nn.Sequential(downsamp(channels=in_channels,filt_size=3,stride=2),\n","                                nn.Conv2d(in_channels, in_channels*2, 1, stride=1, padding=0, bias=bias))\n","\n","    def forward(self, x):\n","        out = self.bot(x)\n","        return out\n","\n","class DownSample(nn.Module):\n","    def __init__(self, in_channels, scale_factor, stride=2, kernel_size=3):\n","        super(DownSample, self).__init__()\n","        self.scale_factor = int(np.log2(scale_factor))\n","\n","        modules_body = []\n","        for i in range(self.scale_factor):\n","            modules_body.append(ResidualDownSample(in_channels))\n","            in_channels = int(in_channels * stride)\n","\n","        self.body = nn.Sequential(*modules_body)\n","\n","    def forward(self, x):\n","        x = self.body(x)\n","        return x\n","\n","class ResidualUpSample(nn.Module):\n","    def __init__(self, in_channels, bias=False):\n","        super(ResidualUpSample, self).__init__()\n","\n","        self.bot = nn.Sequential(nn.Upsample(scale_factor=2, mode='bilinear', align_corners=bias),\n","                                nn.Conv2d(in_channels, in_channels//2, 1, stride=1, padding=0, bias=bias))\n","\n","    def forward(self, x):\n","        out = self.bot(x)\n","\n","        return out\n","\n","class UpSample(nn.Module):\n","    def __init__(self, in_channels, scale_factor, stride=2, kernel_size=3):\n","        super(UpSample, self).__init__()\n","        self.scale_factor = int(np.log2(scale_factor))\n","\n","        modules_body = []\n","        for i in range(self.scale_factor):\n","            modules_body.append(ResidualUpSample(in_channels))\n","            in_channels = int(in_channels // stride)\n","\n","        self.body = nn.Sequential(*modules_body)\n","\n","    def forward(self, x):\n","        x = self.body(x)\n","        return x\n","\n","\n","class ConvReluBN(nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size=3):\n","        super(ConvReluBN, self).__init__()\n","        self.layer = nn.Sequential(\n","            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, padding=1),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True)\n","        )\n","    def forward(self, x):\n","        return self.layer(x)\n","\n","\n","class ConvBNReluNkernel(nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size=1, BN = True):\n","        super(ConvBNReluNkernel, self).__init__()\n","        self.kernel_size = kernel_size\n","        if kernel_size == 5:\n","            self.conv= nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size = self.kernel_size, padding=2)\n","        if kernel_size == 3:\n","            self.conv= nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size = self.kernel_size, padding=1)\n","        if kernel_size == 1:\n","            self.conv= nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size = self.kernel_size, padding=0)\n","        if BN == True:\n","            self.BN = nn.BatchNorm2d(out_channels)\n","        self.relu = nn.ReLU(inplace=True)\n","\n","    def forward(self, x):\n","        y = self.relu(self.BN(self.conv(x)))\n","        return y\n","\n","\n","class Attention_block(nn.Module):\n","    def __init__(self, F_c, F_de,  reduction=16, concat=True):\n","        super(Attention_block,self).__init__()\n","        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n","        self.fc1 = nn.Conv2d(F_c, F_c//reduction, kernel_size=1, stride=1, padding=0, bias=False)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.fc2 =  nn.Conv2d(F_c//reduction, F_de, kernel_size=1, stride=1, padding=0, bias=False)\n","\n","        self.sigmoid = nn.Sigmoid()\n","\n","\n","        self.spatial_se = nn.Sequential(nn.Conv2d(F_de, 1, kernel_size=1,\n","                                                  stride=1, padding=0, bias=False),\n","                                        nn.Sigmoid())\n","        self.concat = concat\n","\n","    def forward(self,f, x):\n","        f=self.avg_pool(f)\n","        f = self.fc1(f)\n","        f = self.relu(f)\n","        f = self.fc2(f)\n","        chn_se = self.sigmoid(f)\n","        chn_se = chn_se * x\n","\n","        spa_se = self.spatial_se(x)\n","        spa_se = x * spa_se\n","\n","        if self.concat:\n","            return torch.cat([chn_se, spa_se], dim=1)\n","        else:\n","            return chn_se + spa_se\n","\n","\n","class ConvRelu(nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size=3):\n","        super(ConvRelu, self).__init__()\n","        self.layer = nn.Sequential(\n","            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, padding=1),\n","            nn.ReLU(inplace=True, )\n","        )\n","    #@autocast()\n","    def forward(self, x):\n","        return self.layer(x)\n","\n","class BasicResBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size=3, groups=16):\n","        super(BasicResBlock, self).__init__()\n","        self.layer = nn.Sequential(\n","            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, padding=1),\n","            nn.GroupNorm(num_groups=4, num_channels=out_channels),\n","            nn.ReLU(inplace=True)\n","        )\n","        # self.conv3 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, padding=1)\n","        # self.norm = nn.GroupNorm(num_groups=16, num_channels=out_channels)\n","        # self.relu= nn.ReLU(inplace=True)\n","    #@autocast()\n","    def forward(self, x):\n","        x = self.layer(x)\n","        # x = self.conv3(x)\n","        # x = self.norm(x)\n","        #\n","        # x = self.relu(x)\n","        return x\n","\n","class SCSEModule2(nn.Module):\n","    # according to https://arxiv.org/pdf/1808.08127.pdf concat is better\n","    def __init__(self, channels, reduction=16, concat=False):\n","        super(SCSEModule2, self).__init__()\n","        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n","        self.fc1 = nn.Conv2d(channels, channels // reduction, kernel_size=1,\n","                             padding=0)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.fc2 = nn.Conv2d(channels // reduction, channels, kernel_size=1,\n","                             padding=0)\n","        self.sigmoid = nn.Sigmoid()\n","\n","        self.spatial_se = nn.Sequential(nn.Conv2d(channels, 1, kernel_size=1,\n","                                                  stride=1, padding=0, bias=False),\n","                                        nn.Sigmoid())\n","        self.concat = concat\n","\n","    def forward(self, x):\n","        module_input = x\n","\n","        x = self.avg_pool(x)\n","        x = self.fc1(x)\n","        x = self.relu(x)\n","        x = self.fc2(x)\n","        chn_se = self.sigmoid(x)\n","        chn_se = chn_se * module_input + module_input\n","\n","        spa_se = self.spatial_se(module_input)\n","        #chn_se = chn_se * spa_se\n","        spa_se = module_input * spa_se + module_input\n","        if self.concat:\n","            return torch.cat([chn_se, spa_se], dim=1)\n","        else:\n","            return (chn_se + spa_se)/2\n","\n","\n","class SCSEModule(nn.Module):\n","    # according to https://arxiv.org/pdf/1808.08127.pdf concat is better\n","    def __init__(self, channels, reduction=16, concat=False):\n","        super(SCSEModule, self).__init__()\n","        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n","        self.fc1 = nn.Conv2d(channels, channels // reduction, kernel_size=1,\n","                             padding=0)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.fc2 = nn.Conv2d(channels // reduction, channels, kernel_size=1,\n","                             padding=0)\n","        self.sigmoid = nn.Sigmoid()\n","\n","        self.spatial_se = nn.Sequential(nn.Conv2d(channels, 1, kernel_size=1,\n","                                                  stride=1, padding=0, bias=False),\n","                                        nn.Sigmoid())\n","        self.concat = concat\n","\n","    def forward(self, x):\n","        module_input = x\n","\n","        x = self.avg_pool(x)\n","        x = self.fc1(x)\n","        x = self.relu(x)\n","        x = self.fc2(x)\n","        chn_se = self.sigmoid(x)\n","        chn_se = chn_se * module_input\n","\n","        spa_se = self.spatial_se(module_input)\n","        spa_se = module_input * spa_se\n","        if self.concat:\n","            return torch.cat([chn_se, spa_se], dim=1)\n","        else:\n","            return chn_se + spa_se\n","\n","\n","\n","class SeResNext50_Unet_MScale(nn.Module):\n","    def __init__(self, pretrained='imagenet', **kwargs):\n","        super(SeResNext50_Unet_MScale, self).__init__()\n","\n","        encoder_filters = [64, 256, 512, 1024, 2048]\n","        decoder_filters = [48,  128, 256, 256, 2048]\n","        f_filter = 24\n","\n","        # self.convF2 = ConvRelu(encoder_filters[1]+encoder_filters[1], encoder_filters[1])\n","        # self.convF3 = ConvRelu(encoder_filters[2]+encoder_filters[1], encoder_filters[2])\n","        # self.convF4 = ConvRelu(encoder_filters[3]+encoder_filters[1], encoder_filters[3])\n","\n","        # self.convF1 = nn.Sequential(ConvRelu(f_filter + encoder_filters[0], encoder_filters[0]), BasicResBlock(encoder_filters[0], encoder_filters[0]))\n","        # self.convF2 = nn.Sequential(ConvRelu(encoder_filters[1]+ encoder_filters[1], encoder_filters[1]), BasicResBlock(encoder_filters[1], encoder_filters[1]))\n","        # self.convF3 = nn.Sequential(ConvRelu(encoder_filters[1]+ encoder_filters[2], encoder_filters[2]), BasicResBlock(encoder_filters[2], encoder_filters[2]))\n","        self.convF1 = nn.Sequential( BasicResBlock(f_filter + encoder_filters[0], encoder_filters[0]))\n","        self.convF2 = nn.Sequential( BasicResBlock(f_filter + encoder_filters[1], encoder_filters[1]))\n","        #self.convF3 = nn.Sequential(BasicResBlock(f_filter +encoder_filters[2], encoder_filters[2]))\n","        #self.convF4 = nn.Sequential(ConvRelu(encoder_filters[1]+ encoder_filters[3], encoder_filters[3]), BasicResBlock(encoder_filters[3], encoder_filters[3]))\n","        self.xconv256 =  nn.Sequential(BasicResBlock(3, f_filter))\n","        self.xconv128 =  nn.Sequential(BasicResBlock(3, f_filter))\n","        #self.xconv64 = nn.Sequential(BasicResBlock(3, f_filter))\n","        #self.xconv32 =  nn.Sequential(ConvReluBN(in_channels=3, out_channels=64), encoder.layer1 )\n","        self.dconv5 = ConvRelu(encoder_filters[4], decoder_filters[3])\n","        self.dconv5_2 = ConvRelu(encoder_filters[3]+decoder_filters[3], decoder_filters[3])\n","\n","        self.dconv6 = ConvRelu(decoder_filters[3], decoder_filters[2])\n","        self.dconv6_2 = ConvRelu(encoder_filters[2]+decoder_filters[2], decoder_filters[2])\n","        self.dconv7 = ConvRelu(decoder_filters[2], decoder_filters[1])\n","        self.dconv7_2 = ConvRelu(encoder_filters[1]+decoder_filters[1], decoder_filters[1])\n","        self.dconv8 = ConvRelu(decoder_filters[1], decoder_filters[0])\n","        self.dconv8_2 = ConvRelu(encoder_filters[0]+decoder_filters[0], decoder_filters[0])\n","\n","        self.dconv9 = ConvRelu(decoder_filters[0], decoder_filters[0])\n","\n","        self.res = nn.Conv2d(decoder_filters[0]*2, 5, 1, stride=1, padding=0)\n","\n","        self._initialize_weights()\n","\n","        encoder = se_resnext50_32x4d(pretrained=pretrained)\n","        #encoder = torchvision.models.resnet50(pretrained=pretrained)\n","        self.conv1 = nn.Sequential(encoder.layer0.conv1, encoder.layer0.bn1, encoder.layer0.relu1) #encoder.layer0.conv1\n","        self.conv2 = nn.Sequential(encoder.pool, encoder.layer1)\n","        self.conv3 = encoder.layer2\n","        self.conv4 = encoder.layer3\n","        self.conv5 = encoder.layer4\n","\n","        #self.xconv128 =  nn.Sequential(ConvReluBN(in_channels=3, out_channels=64), encoder.layer1 )\n","        #self.xconv64 = nn.Sequential(ConvReluBN(in_channels=3, out_channels=64), encoder.layer1 )\n","        #self.xconv32 =  nn.Sequential(ConvReluBN(in_channels=3, out_channels=64), encoder.layer1 )\n","\n","    def forward1(self, x):\n","        batch_size, C, H, W = x.shape\n","        x256 = F.interpolate(x, scale_factor=0.5)\n","        x128 = F.interpolate(x, scale_factor=0.25)\n","        #x64 = F.interpolate(x, scale_factor=0.125)\n","        #x32 = F.interpolate(x, scale_factor=0.0625)\n","\n","        enc1 = self.conv1(x)\n","        enc2 = self.conv2(enc1)\n","        enc3 = self.conv3(enc2)\n","        enc4 = self.conv4(enc3)\n","        enc5 = self.conv5(enc4)\n","\n","        enc256 = self.xconv256(x256)\n","        enc128 = self.xconv128(x128)\n","        #enc64 = self.xconv64(x64)\n","        #enc32 = self.xconv32(x32)\n","\n","        enc1 = self.convF1(torch.cat([enc1, enc256],1))\n","        enc2 = self.convF2(torch.cat([enc2, enc128], 1))\n","        #enc3 = self.convF3(torch.cat([enc3, enc64], 1))\n","        #enc4 = self.convF4(torch.cat([enc4, enc32], 1))\n","\n","\n","        dec5 = self.dconv5(F.interpolate(enc5, scale_factor=2))\n","        dec5 = self.dconv5_2(torch.cat([dec5,enc4], 1))\n","        dec6 = self.dconv6(F.interpolate(dec5, scale_factor=2))\n","        dec6 = self.dconv6_2(torch.cat([dec6,enc3], 1))\n","        dec7 = self.dconv7(F.interpolate(dec6, scale_factor=2))\n","        dec7 = self.dconv7_2(torch.cat([dec7,enc2], 1))\n","        dec8 = self.dconv8(F.interpolate(dec7, scale_factor=2))\n","        dec8 = self.dconv8_2(torch.cat([dec8,enc1], 1))\n","\n","        dec9 = self.dconv9(F.interpolate(dec8,scale_factor=2))\n","\n","        return dec9\n","\n","    def forward(self, x):\n","        dec10_0 = self.forward1(x[:, :3, :, :])\n","        dec10_1 = self.forward1(x[:, 3:, :, :])\n","\n","        dec10 = torch.cat([dec10_0, dec10_1], 1)\n","\n","        return self.res(dec10)\n","\n","\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Linear):\n","                m.weight.data = nn.init.kaiming_normal_(m.weight.data)\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","\n","class SeResNext50_Unet_MScale2(nn.Module):\n","    def __init__(self, pretrained='imagenet', **kwargs):\n","        super(SeResNext50_Unet_MScale2, self).__init__()\n","\n","        encoder_filters = [64, 256, 512, 1024, 2048]\n","        decoder_filters = [48,  128, 256, 256, 2048]\n","        f_filter = 24\n","\n","        # self.convF2 = ConvRelu(encoder_filters[1]+encoder_filters[1], encoder_filters[1])\n","        # self.convF3 = ConvRelu(encoder_filters[2]+encoder_filters[1], encoder_filters[2])\n","        # self.convF4 = ConvRelu(encoder_filters[3]+encoder_filters[1], encoder_filters[3])\n","\n","        # self.convF1 = nn.Sequential(ConvRelu(f_filter + encoder_filters[0], encoder_filters[0]), BasicResBlock(encoder_filters[0], encoder_filters[0]))\n","        # self.convF2 = nn.Sequential(ConvRelu(encoder_filters[1]+ encoder_filters[1], encoder_filters[1]), BasicResBlock(encoder_filters[1], encoder_filters[1]))\n","        # self.convF3 = nn.Sequential(ConvRelu(encoder_filters[1]+ encoder_filters[2], encoder_filters[2]), BasicResBlock(encoder_filters[2], encoder_filters[2]))\n","        #self.convF1 = nn.Sequential( BasicResBlock(f_filter + encoder_filters[0], encoder_filters[0]))\n","        self.convF2 = nn.Sequential( BasicResBlock(f_filter + encoder_filters[1], encoder_filters[1]))\n","        #self.convF3 = nn.Sequential(BasicResBlock(f_filter +encoder_filters[2], encoder_filters[2]))\n","        #self.convF4 = nn.Sequential(ConvRelu(encoder_filters[1]+ encoder_filters[3], encoder_filters[3]), BasicResBlock(encoder_filters[3], encoder_filters[3]))\n","        #self.xconv256 =  nn.Sequential(BasicResBlock(3, f_filter))\n","        self.xconv128 =  nn.Sequential(BasicResBlock(3, f_filter))\n","        #self.xconv64 = nn.Sequential(BasicResBlock(3, f_filter))\n","        #self.xconv32 =  nn.Sequential(ConvReluBN(in_channels=3, out_channels=64), encoder.layer1 )\n","        #self.dconv5 = ConvRelu(encoder_filters[4], decoder_filters[3])\n","        #self.dconv5_2 = ConvRelu(encoder_filters[3]+decoder_filters[3], decoder_filters[3])\n","\n","        self.dconv6 = ConvReluBN(encoder_filters[3], decoder_filters[2])\n","        self.dconv6_2 = ConvRelu(encoder_filters[2]+decoder_filters[2], decoder_filters[2])\n","        self.dconv7 = ConvRelu(decoder_filters[2], decoder_filters[1])\n","        self.dconv7_2 = ConvRelu(encoder_filters[1]+decoder_filters[1], decoder_filters[1])\n","        self.dconv8 = ConvRelu(decoder_filters[1], decoder_filters[0])\n","        self.dconv8_2 = ConvRelu(encoder_filters[0]+decoder_filters[0], decoder_filters[0])\n","        self.dconv8_2 = nn.Sequential( ConvRelu(encoder_filters[0]+decoder_filters[0], decoder_filters[0]), SCSEModule(decoder_filters[0], reduction=2, concat=True))\n","\n","        self.dconv9 = ConvRelu(decoder_filters[0]*2, decoder_filters[0])\n","\n","        self.res = nn.Conv2d(decoder_filters[0]*2, 5, 1, stride=1, padding=0)\n","\n","        self._initialize_weights()\n","\n","        encoder = se_resnext50_32x4d(pretrained=pretrained)\n","        #encoder = torchvision.models.resnet50(pretrained=pretrained)\n","        self.conv1 = nn.Sequential(encoder.layer0.conv1, encoder.layer0.bn1, encoder.layer0.relu1) #encoder.layer0.conv1\n","        self.conv2 = nn.Sequential(encoder.pool, encoder.layer1)\n","        self.conv3 = encoder.layer2\n","        self.conv4 = encoder.layer3\n","        #self.conv5 = encoder.layer4\n","\n","        #self.xconv128 =  nn.Sequential(ConvReluBN(in_channels=3, out_channels=64), encoder.layer1 )\n","        #self.xconv64 = nn.Sequential(ConvReluBN(in_channels=3, out_channels=64), encoder.layer1 )\n","        #self.xconv32 =  nn.Sequential(ConvReluBN(in_channels=3, out_channels=64), encoder.layer1 )\n","\n","    def forward1(self, x):\n","        batch_size, C, H, W = x.shape\n","        #x256 = F.interpolate(x, scale_factor=0.5)\n","        x128 = F.interpolate(x, scale_factor=0.25)\n","        #x64 = F.interpolate(x, scale_factor=0.125)\n","        #x32 = F.interpolate(x, scale_factor=0.0625)\n","\n","        enc1 = self.conv1(x)\n","        enc2 = self.conv2(enc1)\n","        enc3 = self.conv3(enc2)\n","        enc4 = self.conv4(enc3)\n","        #enc5 = self.conv5(enc4)\n","\n","        #enc256 = self.xconv256(x256)\n","        enc128 = self.xconv128(x128)\n","        #enc64 = self.xconv64(x64)\n","        #enc32 = self.xconv32(x32)\n","\n","        #enc1 = self.convF1(torch.cat([enc1, enc256],1))\n","        enc2 = self.convF2(torch.cat([enc2, enc128], 1))\n","        #enc3 = self.convF3(torch.cat([enc3, enc64], 1))\n","        #enc4 = self.convF4(torch.cat([enc4, enc32], 1))\n","\n","\n","        #dec5 = self.dconv5(F.interpolate(enc5, scale_factor=2))\n","        #dec5 = self.dconv5_2(torch.cat([dec5,enc4], 1))\n","        dec6 = self.dconv6(F.interpolate(enc4, scale_factor=2))\n","        dec6 = self.dconv6_2(torch.cat([dec6,enc3], 1))\n","        dec7 = self.dconv7(F.interpolate(dec6, scale_factor=2))\n","        dec7 = self.dconv7_2(torch.cat([dec7,enc2], 1))\n","        dec8 = self.dconv8(F.interpolate(dec7, scale_factor=2))\n","        dec8 = self.dconv8_2(torch.cat([dec8,enc1], 1))\n","\n","        dec9 = self.dconv9(F.interpolate(dec8,scale_factor=2))\n","\n","        return dec9\n","\n","    def forward(self, x):\n","        dec10_0 = self.forward1(x[:, :3, :, :])\n","        dec10_1 = self.forward1(x[:, 3:, :, :])\n","\n","        dec10 = torch.cat([dec10_0, dec10_1], 1)\n","\n","        return self.res(dec10)\n","\n","\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Linear):\n","                m.weight.data = nn.init.kaiming_normal_(m.weight.data)\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","\n","class SeResNext50_Unet_Double(nn.Module):\n","    def __init__(self, pretrained='imagenet', **kwargs):\n","        super(SeResNext50_Unet_Double, self).__init__()\n","\n","        encoder_filters = [64, 256, 512, 1024, 2048]\n","        decoder_filters = np.asarray([64, 96, 128, 256, 512]) // 2\n","\n","        self.conv6 = ConvRelu(encoder_filters[-1], decoder_filters[-1])\n","        self.conv6_2 = ConvRelu(decoder_filters[-1] + encoder_filters[-2], decoder_filters[-1])\n","        self.conv7 = ConvRelu(decoder_filters[-1], decoder_filters[-2])\n","        self.conv7_2 = ConvRelu(decoder_filters[-2] + encoder_filters[-3], decoder_filters[-2])\n","        self.conv8 = ConvRelu(decoder_filters[-2], decoder_filters[-3])\n","        self.conv8_2 = ConvRelu(decoder_filters[-3] + encoder_filters[-4], decoder_filters[-3])\n","        self.conv9 = ConvRelu(decoder_filters[-3], decoder_filters[-4])\n","        self.conv9_2 = ConvRelu(decoder_filters[-4] + encoder_filters[-5], decoder_filters[-4])\n","        self.conv10 = ConvRelu(decoder_filters[-4], decoder_filters[-5])\n","\n","\n","        self.res = nn.Conv2d(decoder_filters[-5] * 2, 5, 1, stride=1, padding=0)\n","\n","        self._initialize_weights()\n","\n","        encoder = se_resnext50_32x4d(pretrained=pretrained)\n","        #encoder = torchvision.models.resnet50(pretrained=pretrained)\n","\n","        # conv1_new = nn.Conv2d(6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","        # _w = encoder.layer0.conv1.state_dict()\n","        # _w['weight'] = torch.cat([0.5 * _w['weight'], 0.5 * _w['weight']], 1)\n","        # conv1_new.load_state_dict(_w)\n","        self.conv1 = nn.Sequential(encoder.layer0.conv1, encoder.layer0.bn1, encoder.layer0.relu1) #encoder.layer0.conv1\n","        self.conv2 = nn.Sequential(encoder.pool, encoder.layer1)\n","        self.conv3 = encoder.layer2\n","        self.conv4 = encoder.layer3\n","        self.conv5 = encoder.layer4\n","\n","\n","    def forward1(self, x):\n","        batch_size, C, H, W = x.shape\n","\n","        enc1 = self.conv1(x)\n","        enc2 = self.conv2(enc1)\n","        enc3 = self.conv3(enc2)\n","        enc4 = self.conv4(enc3)\n","        enc5 = self.conv5(enc4)\n","\n","        dec6 = self.conv6(F.interpolate(enc5, scale_factor=2))\n","        dec6 = self.conv6_2(torch.cat([dec6, enc4 ], 1))\n","\n","        dec7 = self.conv7(F.interpolate(dec6, scale_factor=2))\n","        dec7 = self.conv7_2(torch.cat([dec7, enc3 ], 1))\n","\n","        dec8 = self.conv8(F.interpolate(dec7, scale_factor=2))\n","        dec8 = self.conv8_2(torch.cat([dec8, enc2 ], 1))\n","\n","        dec9 = self.conv9(F.interpolate(dec8, scale_factor=2))\n","        dec9 = self.conv9_2(torch.cat([dec9,  enc1  ], 1))\n","\n","        dec10 = self.conv10(F.interpolate(dec9, scale_factor=2))\n","\n","        return dec10\n","\n","\n","    def forward(self, x):\n","        dec10_0 = self.forward1(x[:, :3, :, :])\n","        dec10_1 = self.forward1(x[:, 3:, :, :])\n","\n","        dec10 = torch.cat([dec10_0, dec10_1], 1)\n","\n","        return self.res(dec10)\n","\n","\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Linear):\n","                m.weight.data = nn.init.kaiming_normal_(m.weight.data)\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","\n","class SeResNext50_Unet_MultiScale(nn.Module):\n","    def __init__(self, pretrained='imagenet', **kwargs):\n","        super(SeResNext50_Unet_MultiScale, self).__init__()\n","\n","        #encoder_filters = [64, 256, 512, 1024, 2048]\n","        encoder_filters = [128, 256, 512, 1024, 2048]\n","        fuse_filter = 64\n","\n","        self.down12 = DownSample(encoder_filters[0], 2)\n","        self.down13 = DownSample(encoder_filters[0]*2, 2)\n","        self.down23 = DownSample(encoder_filters[1], 2)\n","        self.up21 = UpSample(encoder_filters[1], 2)\n","        self.up31 = UpSample(encoder_filters[2]//2, 2)\n","        self.up32 = UpSample(encoder_filters[2], 2)\n","\n","        # self.convF1 = ConvBNReluNkernel(encoder_filters[0], decoder_filters[0])\n","        # self.convF2 = ConvBNReluNkernel(encoder_filters[1], decoder_filters[1])\n","        # self.convF3 = ConvBNReluNkernel(encoder_filters[2], decoder_filters[2])\n","        self.conv0 = ConvRelu(encoder_filters[0]//2, encoder_filters[0])\n","        self.convF1 = nn.Sequential(ConvRelu(encoder_filters[0], encoder_filters[0]), SCSEModule(encoder_filters[0], reduction=4, concat=True))\n","        self.conv1_1 = ConvRelu(encoder_filters[0]*2, encoder_filters[0])\n","        self.convF2 = nn.Sequential(ConvRelu(encoder_filters[1], encoder_filters[1]), SCSEModule(encoder_filters[1], reduction=8, concat=True))\n","        self.conv2_1 = ConvRelu(encoder_filters[1]*2, encoder_filters[1])\n","        self.convF3 = nn.Sequential(ConvRelu(encoder_filters[2], encoder_filters[2]), SCSEModule(encoder_filters[2], reduction=16, concat=True))\n","        self.conv3_1 = ConvRelu(encoder_filters[2]*2, encoder_filters[2])\n","\n","        self.conv1_2 = ConvRelu(encoder_filters[0] * 2, fuse_filter)\n","        self.conv2_2 = ConvRelu(encoder_filters[1] * 2, fuse_filter)\n","        self.conv3_2 = ConvRelu(encoder_filters[2] * 2, fuse_filter*2)\n","        self.up31_2 = UpSample(fuse_filter*2, 4)   #32\n","        self.up21_2 = UpSample(fuse_filter, 2)   #32\n","\n","        self.conv4 = ConvRelu(fuse_filter * 2, fuse_filter)  # 32+32+64\n","        self.conv4_2 = nn.Conv2d(fuse_filter, fuse_filter, 1, stride=1, padding=0)\n","        self.relu = nn.ReLU(inplace=True)\n","\n","        self.res = nn.Conv2d(fuse_filter*2, 5, 1, stride=1, padding=0)\n","\n","        self._initialize_weights()\n","\n","        encoder = se_resnext50_32x4d(pretrained=pretrained)\n","        #encoder = torchvision.models.resnet50(pretrained=pretrained)\n","        self.conv1 = nn.Sequential(encoder.layer0.conv1, encoder.layer0.bn1, encoder.layer0.relu1) #encoder.layer0.conv1\n","        self.conv2 = nn.Sequential(encoder.pool, encoder.layer1)\n","        self.conv3 = encoder.layer2\n","        #self.conv4 = encoder.layer3\n","\n","\n","    def forward1(self, x):\n","        batch_size, C, H, W = x.shape\n","\n","        enc1 = self.conv1(x)\n","        enc2 = self.conv2(enc1)\n","        enc3 = self.conv3(enc2)\n","\n","        enc1 = self.conv0(enc1)\n","\n","        f12 = self.down12(enc1)\n","        f13 = self.down13(f12)\n","        f23 = self.down23(enc2)\n","        f21 = self.up21(enc2)\n","        f32 = self.up32(enc3)\n","        f31 = self.up31(f32)\n","\n","        fusion1 = self.convF1(enc1+f21+f31)\n","        fusion1 = self.conv1_1(fusion1)\n","        fusion2 = self.convF2(enc2+f12+f32)\n","        fusion2 = self.conv2_1(fusion2)\n","        fusion3 = self.convF3(enc3+f23+f13)\n","        fusion3 = self.conv3_1(fusion3)\n","\n","        dec1 = self.conv1_2(torch.cat([enc1, fusion1], 1))\n","        dec2 = self.conv2_2(torch.cat([enc2, fusion2], 1))\n","        dec3 = self.conv3_2(torch.cat([enc3, fusion3], 1))\n","\n","        dec2 = self.up21_2(dec2)\n","        dec3 = self.up31_2(dec3)\n","        dec4 = self.conv4(torch.cat([dec1, dec2, dec3], 1))\n","        dec4 = self.conv4_2(F.interpolate(dec4, scale_factor=2, mode='bilinear'))\n","        dec4 = self.relu(dec4)\n","\n","        return dec4\n","\n","    def forward(self, x):\n","        dec10_0 = self.forward1(x[:, :3, :, :])\n","        dec10_1 = self.forward1(x[:, 3:, :, :])\n","\n","        dec10 = torch.cat([dec10_0, dec10_1], 1)\n","\n","        return self.res(dec10)\n","\n","\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Linear):\n","                m.weight.data = nn.init.kaiming_normal_(m.weight.data)\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","\n","class SeResNext50_Unet_2SUnet(nn.Module):\n","    def __init__(self, pretrained='imagenet', **kwargs):\n","        super(SeResNext50_Unet_2SUnet, self).__init__()\n","\n","        encoder_filters = [64, 256, 512, 1024, 2048]\n","        decoder_filters = np.asarray([64, 96, 128, 256, 512]) // 2\n","\n","        self.conv6 = ConvRelu(encoder_filters[-1], decoder_filters[-1])\n","        self.conv6_2 = ConvRelu(decoder_filters[-1] + encoder_filters[-2], decoder_filters[-1])\n","        self.conv7 = ConvRelu(decoder_filters[-1], decoder_filters[-2])\n","        self.conv7_2 = ConvRelu(decoder_filters[-2] + encoder_filters[-3] , decoder_filters[-2] )\n","        self.conv8 = ConvRelu(decoder_filters[-2], decoder_filters[-3])\n","        self.conv8_2 = ConvRelu(decoder_filters[-3] + encoder_filters[-4] , decoder_filters[-3])\n","        self.conv9 = ConvRelu(decoder_filters[-3], decoder_filters[-4])\n","        self.conv9_2 = ConvRelu(decoder_filters[-4] + encoder_filters[-5], decoder_filters[-4])\n","        # self.conv9_3 = nn.Sequential(ConvRelu(encoder_filters[-4], encoder_filters[-4]), nn.Sigmoid())\n","        # self.convx9_3 = ConvRelu(encoder_filters[-4], encoder_filters[-4])\n","\n","        self.conv10 = ConvRelu(decoder_filters[-4], decoder_filters[-5])\n","        self.convxx = nn.Sequential(ConvRelu(decoder_filters[-5]*2, decoder_filters[-5]*2),\n","                                    nn.Conv2d(decoder_filters[-5] * 2, decoder_filters[-5], 1, stride=1, padding=0))\n","\n","\n","        self.res = nn.Conv2d(decoder_filters[-5] * 2, 5, 1, stride=1, padding=0)\n","\n","        self._initialize_weights()\n","\n","        encoder = se_resnext50_32x4d(pretrained=pretrained)\n","        #encoder = torchvision.models.resnet50(pretrained=pretrained)\n","        self.conv1 = nn.Sequential(encoder.layer0.conv1, encoder.layer0.bn1, encoder.layer0.relu1) #encoder.layer0.conv1\n","        self.conv2 = nn.Sequential(encoder.pool, encoder.layer1)\n","        self.conv3 = encoder.layer2\n","        self.conv4 = encoder.layer3\n","        self.conv5 = encoder.layer4\n","\n","\n","    def forward1(self, x):\n","        batch_size, C, H, W = x.shape\n","        xx = F.interpolate(x, scale_factor=0.5, mode='bilinear', align_corners=False)\n","\n","        enc1 = self.conv1(x)\n","        enc2 = self.conv2(enc1)\n","        enc3 = self.conv3(enc2)\n","        enc4 = self.conv4(enc3)\n","        enc5 = self.conv5(enc4)\n","\n","        encx1 = self.conv1(xx)   # 64 128 128\n","        encx2 = self.conv2(encx1) # 64\n","        encx3 = self.conv3(encx2) # 32\n","        encx4 = self.conv4(encx3) # 16\n","        encx5 = self.conv5(encx4) # 8\n","\n","        dec6 = self.conv6(F.interpolate(enc5, scale_factor=2))\n","        dec6 = self.conv6_2(torch.cat([dec6, enc4 ], 1))\n","        dec7 = self.conv7(F.interpolate(dec6, scale_factor=2))\n","        dec7 = self.conv7_2(torch.cat([dec7, enc3], 1))\n","        dec8 = self.conv8(F.interpolate(dec7, scale_factor=2))\n","        dec8 = self.conv8_2(torch.cat([dec8, enc2], 1))\n","        dec9 = self.conv9(F.interpolate(dec8, scale_factor=2))\n","        dec9 = self.conv9_2(torch.cat([dec9,  enc1], 1))   #256\n","\n","\n","        decx6 = self.conv6(F.interpolate(encx5, scale_factor=2))\n","        decx6 = self.conv6_2(torch.cat([decx6, encx4 ], 1))\n","        decx7 = self.conv7(F.interpolate(decx6, scale_factor=2))\n","        decx7 = self.conv7_2(torch.cat([decx7, encx3], 1))\n","        decx8 = self.conv8(F.interpolate(decx7, scale_factor=2))\n","        decx8 = self.conv8_2(torch.cat([decx8, encx2], 1))\n","        decx9 = self.conv9(F.interpolate(decx8, scale_factor=2))\n","        decx9 = self.conv9_2(torch.cat([decx9,  encx1], 1))   #128\n","        #decx9 = self.convx9_3(F.interpolate(decx9, scale_factor=4))\n","\n","\n","        dec10 = self.conv10(F.interpolate(dec9, scale_factor=2))\n","        decx10 = self.conv10(F.interpolate(decx9, scale_factor=4))\n","\n","        dec = self.convxx(torch.cat([dec10, decx10], 1))\n","\n","        return dec\n","\n","    def forward(self, x):\n","        dec10_0 = self.forward1(x[:, :3, :, :])\n","        dec10_1 = self.forward1(x[:, 3:, :, :])\n","\n","        dec10 = torch.cat([dec10_0, dec10_1], 1)\n","\n","        return self.res(dec10)\n","\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Linear):\n","                m.weight.data = nn.init.kaiming_normal_(m.weight.data)\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","\n","class SeResNext50_Unet_2Ssum(nn.Module):\n","    def __init__(self, pretrained='imagenet', **kwargs):\n","        super(SeResNext50_Unet_2Ssum, self).__init__()\n","\n","        encoder_filters = [64, 256, 512, 1024, 2048]\n","        decoder_filters = np.asarray([64, 96, 128, 256, 512]) // 2\n","\n","        self.conv6 = ConvRelu(encoder_filters[-1], decoder_filters[-1])\n","        self.conv6_2 = ConvRelu(decoder_filters[-1] + encoder_filters[-2], decoder_filters[-1])\n","        self.conv7 = ConvRelu(decoder_filters[-1], decoder_filters[-2])\n","        self.conv7_2 = ConvRelu(decoder_filters[-2] + encoder_filters[-3] , decoder_filters[-2] )\n","        self.conv8 = ConvRelu(decoder_filters[-2], decoder_filters[-3])\n","        self.conv8_2 = ConvRelu(decoder_filters[-3] + encoder_filters[-4] , decoder_filters[-3])\n","        self.conv9 = ConvRelu(decoder_filters[-3], decoder_filters[-4])\n","        self.conv9_2 = ConvRelu(decoder_filters[-4] + encoder_filters[-5], decoder_filters[-4])\n","\n","        # self.convx9_3 = ConvRelu(encoder_filters[-4], encoder_filters[-4])\n","\n","\n","        self.conv10 = ConvRelu(decoder_filters[-4], decoder_filters[-5])\n","        self.conv10_s = nn.Sequential(ConvRelu(decoder_filters[-5], decoder_filters[-5]),\n","                                      nn.Conv2d(decoder_filters[-5] , 1, 1, stride=1, padding=0),\n","                                      nn.Sigmoid())\n","        # self.convxx = nn.Sequential(ConvRelu(decoder_filters[-5]*2, decoder_filters[-5]*2),\n","        #                             nn.Conv2d(decoder_filters[-5] * 2, decoder_filters[-5], 1, stride=1, padding=0))\n","\n","        self.res = nn.Conv2d(decoder_filters[-5] * 2, 5, 1, stride=1, padding=0)\n","\n","        self._initialize_weights()\n","\n","        encoder = se_resnext50_32x4d(pretrained=pretrained)\n","        #encoder = torchvision.models.resnet50(pretrained=pretrained)\n","        self.conv1 = nn.Sequential(encoder.layer0.conv1, encoder.layer0.bn1, encoder.layer0.relu1) #encoder.layer0.conv1\n","        self.conv2 = nn.Sequential(encoder.pool, encoder.layer1)\n","        self.conv3 = encoder.layer2\n","        self.conv4 = encoder.layer3\n","        self.conv5 = encoder.layer4\n","\n","\n","    def forward1(self, x):\n","        batch_size, C, H, W = x.shape\n","        xx = F.interpolate(x, scale_factor=0.5, mode='bilinear', align_corners=False)\n","\n","        enc1 = self.conv1(x)\n","        enc2 = self.conv2(enc1)\n","        enc3 = self.conv3(enc2)\n","        enc4 = self.conv4(enc3)\n","        enc5 = self.conv5(enc4)\n","\n","        encx1 = self.conv1(xx)   # 64 128 128\n","        encx2 = self.conv2(encx1) # 64\n","        encx3 = self.conv3(encx2) # 32\n","        encx4 = self.conv4(encx3) # 16\n","        encx5 = self.conv5(encx4) # 8\n","\n","        dec6 = self.conv6(F.interpolate(enc5, scale_factor=2))\n","        dec6 = self.conv6_2(torch.cat([dec6, enc4 ], 1))\n","        dec7 = self.conv7(F.interpolate(dec6, scale_factor=2))\n","        dec7 = self.conv7_2(torch.cat([dec7, enc3], 1))\n","        dec8 = self.conv8(F.interpolate(dec7, scale_factor=2))\n","        dec8 = self.conv8_2(torch.cat([dec8, enc2], 1))\n","        dec9 = self.conv9(F.interpolate(dec8, scale_factor=2))\n","        dec9 = self.conv9_2(torch.cat([dec9,  enc1], 1))   #256\n","\n","        decx6 = self.conv6(F.interpolate(encx5, scale_factor=2))\n","        decx6 = self.conv6_2(torch.cat([decx6, encx4 ], 1))\n","        decx7 = self.conv7(F.interpolate(decx6, scale_factor=2))\n","        decx7 = self.conv7_2(torch.cat([decx7, encx3], 1))\n","        decx8 = self.conv8(F.interpolate(decx7, scale_factor=2))\n","        decx8 = self.conv8_2(torch.cat([decx8, encx2], 1))\n","        decx9 = self.conv9(F.interpolate(decx8, scale_factor=2))\n","        decx9 = self.conv9_2(torch.cat([decx9,  encx1], 1))   #128\n","        #decx9 = self.convx9_3(F.interpolate(decx9, scale_factor=4))\n","\n","\n","        dec10 = self.conv10(F.interpolate(dec9, scale_factor=2))\n","        alpha = self.conv10_s(dec10)\n","        decx10 = self.conv10(F.interpolate(decx9, scale_factor=4))\n","\n","        dec = alpha * dec10 + (1-alpha)*decx10\n","\n","        return dec\n","\n","    def forward(self, x):\n","        dec10_0 = self.forward1(x[:, :3, :, :])\n","        dec10_1 = self.forward1(x[:, 3:, :, :])\n","\n","        dec10 = torch.cat([dec10_0, dec10_1], 1)\n","\n","        return self.res(dec10)\n","\n","\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Linear):\n","                m.weight.data = nn.init.kaiming_normal_(m.weight.data)\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()"]},{"cell_type":"markdown","metadata":{"id":"tHCAM2vfRK7e"},"source":["# TrainBDANet"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":176248,"status":"ok","timestamp":1686744848264,"user":{"displayName":"Antonio Santos","userId":"03265893617080544823"},"user_tz":180},"id":"Un2B5Ov0F8f-","outputId":"ead6374c-51ae-4c90-8390-1f06874a5aa5"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 2/2 [02:40\u003c00:00, 80.30s/it]\n","100%|██████████| 1/1 [00:14\u003c00:00, 14.25s/it]\n"]}],"source":["import os\n","os.environ[\"MKL_NUM_THREADS\"] = \"2\"\n","os.environ[\"NUMEXPR_NUM_THREADS\"] = \"2\"\n","os.environ[\"OMP_NUM_THREADS\"] = \"2\"\n","\n","from os import path, makedirs, listdir\n","import sys\n","import numpy as np\n","np.random.seed(1)\n","import random\n","random.seed(1)\n","\n","import torch\n","from torch import nn\n","from torch.backends import cudnn\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","import torch.optim.lr_scheduler as lr_scheduler\n","\n","#from apex import amp\n","\n","import pandas as pd\n","from tqdm import tqdm\n","import timeit\n","import cv2\n","\n","from imgaug import augmenters as iaa\n","\n","from skimage.morphology import square, dilation\n","\n","from sklearn.model_selection import train_test_split\n","\n","from sklearn.metrics import accuracy_score\n","\n","import gc\n","\n","cv2.setNumThreads(0)\n","cv2.ocl.setUseOpenCL(False)\n","\n","train_dirs = ['/content/drive/MyDrive/Modeling Satelities Images Building Damaged/data/tier3','/content/drive/MyDrive/Modeling Satelities Images Building Damaged/data/train']\n","\n","val_dirs = ['/content/drive/MyDrive/Modeling Satelities Images Building Damaged/data/test']\n","\n","models_folder = '/content/drive/MyDrive/Modeling Satelities Images Building Damaged/src/train/weights'\n","\n","loc_folder = 'pred_loc_val'\n","\n","input_shape = (512, 512)\n","\n","\n","all_files = []\n","for d in tqdm(train_dirs):\n","    for f in sorted(listdir(path.join(d, 'images'))):\n","        if '_pre_disaster.png' in f:\n","            post_disaster_file = f.replace('_pre_disaster.png', '_post_disaster.png')\n","            if path.exists(path.join(d, 'images', post_disaster_file)):\n","                all_files.append(path.join(d, 'images', f))\n","\n","all_files2 = []\n","for d in tqdm(val_dirs):\n","    for f in sorted(listdir(path.join(d, 'images'))):\n","        if '_pre_disaster.png' in f:\n","            post_disaster_file = f.replace('_pre_disaster.png', '_post_disaster.png')\n","            if path.exists(path.join(d, 'images', post_disaster_file)):\n","                all_files2.append(path.join(d, 'images', f))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3_V8N6ykQ2g0"},"outputs":[],"source":["def rand_bbox(size, lam):\n","    W = size[0]\n","    H = size[1]\n","    cut_rat = np.sqrt(1. - lam)\n","    cut_w = int(W * cut_rat)\n","    cut_h = int(H * cut_rat)\n","    # if cut_rat \u003e 0.9:\n","    #   cut_w = np.int(W * cut_rat * 0.9)\n","    #   cut_h = np.int(H * cut_rat * 0.9)\n","\n","    # uniform\n","    cx = np.random.randint(W)\n","    cy = np.random.randint(H)\n","\n","    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n","    bby1 = np.clip(cy - cut_h // 2, 0, H)\n","    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n","    bby2 = np.clip(cy + cut_h // 2, 0, H)\n","\n","    return bbx1, bby1, bbx2, bby2\n","\n","class TrainData(Dataset):\n","    def __init__(self, train_idxs, low, high):\n","        super().__init__()\n","        self.train_idxs = train_idxs\n","        self.elastic = iaa.ElasticTransformation(alpha=(0.25, 1.2), sigma=0.2)\n","        self.low =low\n","        self.high = high\n","\n","    def __len__(self):\n","        return len(self.train_idxs)\n","\n","    def __getitem__(self, idx):\n","        _idx = self.train_idxs[idx]\n","\n","        fn = all_files[_idx]\n","\n","        img = cv2.imread(fn, cv2.IMREAD_COLOR)\n","        img2 = cv2.imread(fn.replace('_pre_disaster', '_post_disaster'), cv2.IMREAD_COLOR)\n","        if img is None and img2 is None:\n","          sample = {'img': None, 'msk': None, 'lbl_msk': None, 'fn': None}\n","        elif img is None or img2 is None:\n","          sample = {'img': None, 'msk': None, 'lbl_msk': None, 'fn': None}\n","\n","        msk0 = cv2.imread(fn.replace('/images/', '/targets/').replace('.png', '_target.png'), cv2.IMREAD_UNCHANGED)\n","        lbl_msk1 = cv2.imread(fn.replace('/images/', '/targets/').replace('_pre_disaster', '_post_disaster').replace('.png', '_target.png'), cv2.IMREAD_UNCHANGED)\n","        msk1 = np.zeros_like(lbl_msk1)\n","        msk2 = np.zeros_like(lbl_msk1)\n","        msk3 = np.zeros_like(lbl_msk1)\n","        msk4 = np.zeros_like(lbl_msk1)\n","        msk2[lbl_msk1 == 2] = 255\n","        msk3[lbl_msk1 == 3] = 255\n","        msk4[lbl_msk1 == 4] = 255\n","        msk1[lbl_msk1 == 1] = 255\n","\n","        try:\n","          if random.random() \u003e 0.87:\n","              lam = np.random.beta(2, 1.8)\n","              rand_inx = torch.randint(low=self.low,high=self.high,size=(1,))\n","              ttt = self.train_idxs[rand_inx]\n","              fn_rand = all_files[ttt]\n","              img_random = cv2.imread(fn_rand, cv2.IMREAD_COLOR)\n","              img2_random = cv2.imread(fn_rand.replace('_pre_disaster', '_post_disaster'), cv2.IMREAD_COLOR)\n","              msk0_random = cv2.imread(fn_rand.replace('/images/', '/targets/').replace('.png', '_target.png'), cv2.IMREAD_UNCHANGED)\n","              lbl_msk1_random = cv2.imread(fn_rand.replace('/images/', '/targets/').replace('_pre_disaster', '_post_disaster').replace('.png', '_target.png'), cv2.IMREAD_UNCHANGED)\n","              bbx1, bby1, bbx2, bby2 = rand_bbox((1024, 1024), lam)\n","              img[bbx1:bbx2, bby1:bby2, :] = img_random[bbx1:bbx2, bby1:bby2, :]\n","              img2[bbx1:bbx2, bby1:bby2, :] = img2_random[bbx1:bbx2, bby1:bby2, :]\n","              msk0[bbx1:bbx2, bby1:bby2] = msk0_random[bbx1:bbx2, bby1:bby2]\n","              lbl_msk1[bbx1:bbx2, bby1:bby2] = lbl_msk1_random[bbx1:bbx2, bby1:bby2]\n","              # lbl_msk1[lbl_msk1==1]=70\n","              # lbl_msk1[lbl_msk1==2]=130\n","              # lbl_msk1[lbl_msk1==3]=190\n","              # lbl_msk1[lbl_msk1==4]=255\n","              # cv2.imshow('input_image', lbl_msk1)\n","              # cv2.waitKey(5000)\n","        except:\n","          None\n","\n","        msk2[lbl_msk1 == 2] = 255\n","        msk3[lbl_msk1 == 3] = 255\n","        msk4[lbl_msk1 == 4] = 255\n","        msk1[lbl_msk1 == 1] = 255\n","\n","        try:\n","          if random.random() \u003e 0.5:\n","              img = img[::-1, ...]\n","              img2 = img2[::-1, ...]\n","              msk0 = msk0[::-1, ...]\n","              msk1 = msk1[::-1, ...]\n","              msk2 = msk2[::-1, ...]\n","              msk3 = msk3[::-1, ...]\n","              msk4 = msk4[::-1, ...]\n","        except:\n","          None\n","\n","        try:\n","          if random.random() \u003e 0.05:\n","              rot = random.randrange(4)\n","              if rot \u003e 0:\n","                img = np.rot90(img, k=rot)\n","                img2 = np.rot90(img2, k=rot)\n","                msk0 = np.rot90(msk0, k=rot)\n","                msk1 = np.rot90(msk1, k=rot)\n","                msk2 = np.rot90(msk2, k=rot)\n","                msk3 = np.rot90(msk3, k=rot)\n","                msk4 = np.rot90(msk4, k=rot)\n","        except:\n","          None\n","\n","        try:\n","          if random.random() \u003e 0.8:\n","              shift_pnt = (random.randint(-320, 320), random.randint(-320, 320))\n","              img = shift_image(img, shift_pnt)\n","              img2 = shift_image(img2, shift_pnt)\n","              msk0 = shift_image(msk0, shift_pnt)\n","              msk1 = shift_image(msk1, shift_pnt)\n","              msk2 = shift_image(msk2, shift_pnt)\n","              msk3 = shift_image(msk3, shift_pnt)\n","              msk4 = shift_image(msk4, shift_pnt)\n","        except:\n","          None\n","\n","        try:\n","          if random.random() \u003e 0.2:\n","              rot_pnt =  (img.shape[0] // 2 + random.randint(-320, 320), img.shape[1] // 2 + random.randint(-320, 320))\n","              scale = 0.9 + random.random() * 0.2\n","              angle = random.randint(0, 20) - 10\n","              if (angle != 0) or (scale != 1):\n","                  img = rotate_image(img, angle, scale, rot_pnt)\n","                  img2 = rotate_image(img2, angle, scale, rot_pnt)\n","                  msk0 = rotate_image(msk0, angle, scale, rot_pnt)\n","                  msk1 = rotate_image(msk1, angle, scale, rot_pnt)\n","                  msk2 = rotate_image(msk2, angle, scale, rot_pnt)\n","                  msk3 = rotate_image(msk3, angle, scale, rot_pnt)\n","                  msk4 = rotate_image(msk4, angle, scale, rot_pnt)\n","        except:\n","          None\n","\n","        crop_size = input_shape[0]\n","\n","        try:\n","          if random.random() \u003e 0.1:\n","              crop_size = random.randint(int(input_shape[0] / 1.15), int(input_shape[0] / 0.85))\n","        except:\n","          None\n","\n","        try:\n","          bst_x0 = random.randint(0, img.shape[1] - crop_size)\n","          bst_y0 = random.randint(0, img.shape[0] - crop_size)\n","          bst_sc = -1\n","          try_cnt = random.randint(1, 10)\n","          for i in range(try_cnt):\n","              x0 = random.randint(0, img.shape[1] - crop_size)\n","              y0 = random.randint(0, img.shape[0] - crop_size)\n","              _sc = msk2[y0:y0+crop_size, x0:x0+crop_size].sum() * 5 + msk3[y0:y0+crop_size, x0:x0+crop_size].sum() * 5 + msk4[y0:y0+crop_size, x0:x0+crop_size].sum() * 2 + msk1[y0:y0+crop_size, x0:x0+crop_size].sum()\n","              if _sc \u003e bst_sc:\n","                  bst_sc = _sc\n","                  bst_x0 = x0\n","                  bst_y0 = y0\n","          x0 = bst_x0\n","          y0 = bst_y0\n","          img = img[y0:y0+crop_size, x0:x0+crop_size, :]\n","          img2 = img2[y0:y0+crop_size, x0:x0+crop_size, :]\n","          msk0 = msk0[y0:y0+crop_size, x0:x0+crop_size]\n","          msk1 = msk1[y0:y0+crop_size, x0:x0+crop_size]\n","          msk2 = msk2[y0:y0+crop_size, x0:x0+crop_size]\n","          msk3 = msk3[y0:y0+crop_size, x0:x0+crop_size]\n","          msk4 = msk4[y0:y0+crop_size, x0:x0+crop_size]\n","\n","          if crop_size != input_shape[0]:\n","            img = cv2.resize(img, input_shape, interpolation=cv2.INTER_LINEAR)\n","            img2 = cv2.resize(img2, input_shape, interpolation=cv2.INTER_LINEAR)\n","            msk0 = cv2.resize(msk0, input_shape, interpolation=cv2.INTER_LINEAR)\n","            msk1 = cv2.resize(msk1, input_shape, interpolation=cv2.INTER_LINEAR)\n","            msk2 = cv2.resize(msk2, input_shape, interpolation=cv2.INTER_LINEAR)\n","            msk3 = cv2.resize(msk3, input_shape, interpolation=cv2.INTER_LINEAR)\n","            msk4 = cv2.resize(msk4, input_shape, interpolation=cv2.INTER_LINEAR)\n","        except:\n","          None\n","\n","        try:\n","          if random.random() \u003e 0.96:\n","              img = shift_channels(img, random.randint(-5, 5), random.randint(-5, 5), random.randint(-5, 5))\n","          elif random.random() \u003e 0.96:\n","              img2 = shift_channels(img2, random.randint(-5, 5), random.randint(-5, 5), random.randint(-5, 5))\n","\n","          if random.random() \u003e 0.96:\n","              img = change_hsv(img, random.randint(-5, 5), random.randint(-5, 5), random.randint(-5, 5))\n","          elif random.random() \u003e 0.96:\n","              img2 = change_hsv(img2, random.randint(-5, 5), random.randint(-5, 5), random.randint(-5, 5))\n","        except:\n","          None\n","\n","        try:\n","          if random.random() \u003e 0.9:\n","              if random.random() \u003e 0.96:\n","                  img = clahe(img)\n","              elif random.random() \u003e 0.96:\n","                  img = gauss_noise(img)\n","              elif random.random() \u003e 0.96:\n","                  img = cv2.blur(img, (3, 3))\n","          elif random.random() \u003e 0.9:\n","              if random.random() \u003e 0.96:\n","                  img = saturation(img, 0.9 + random.random() * 0.2)\n","              elif random.random() \u003e 0.96:\n","                  img = brightness(img, 0.9 + random.random() * 0.2)\n","              elif random.random() \u003e 0.96:\n","                  img = contrast(img, 0.9 + random.random() * 0.2)\n","\n","          if random.random() \u003e 0.9:\n","              if random.random() \u003e 0.96:\n","                  img2 = clahe(img2)\n","              elif random.random() \u003e 0.96:\n","                  img2 = gauss_noise(img2)\n","              elif random.random() \u003e 0.96:\n","                  img2 = cv2.blur(img2, (3, 3))\n","          elif random.random() \u003e 0.9:\n","              if random.random() \u003e 0.96:\n","                  img2 = saturation(img2, 0.9 + random.random() * 0.2)\n","              elif random.random() \u003e 0.96:\n","                  img2 = brightness(img2, 0.9 + random.random() * 0.2)\n","              elif random.random() \u003e 0.96:\n","                  img2 = contrast(img2, 0.9 + random.random() * 0.2)\n","        except:\n","          None\n","\n","        try:\n","          if random.random() \u003e 0.96:\n","              el_det = self.elastic.to_deterministic()\n","              img = el_det.augment_image(img)\n","\n","          if random.random() \u003e 0.96:\n","              el_det = self.elastic.to_deterministic()\n","              img2 = el_det.augment_image(img2)\n","        except:\n","          None\n","\n","        msk0 = msk0[..., np.newaxis]\n","        msk1 = msk1[..., np.newaxis]\n","        msk2 = msk2[..., np.newaxis]\n","        msk3 = msk3[..., np.newaxis]\n","        msk4 = msk4[..., np.newaxis]\n","\n","        msk = np.concatenate([msk0, msk1, msk2, msk3, msk4], axis=2)\n","        msk = (msk \u003e 127)\n","\n","        msk[..., 0] = True\n","        msk[..., 1] = dilation(msk[..., 1], square(5))\n","        msk[..., 2] = dilation(msk[..., 2], square(5))\n","        msk[..., 3] = dilation(msk[..., 3], square(5))\n","        msk[..., 4] = dilation(msk[..., 4], square(5))\n","        msk[..., 1][msk[..., 2:].max(axis=2)] = False\n","        msk[..., 3][msk[..., 2]] = False\n","        msk[..., 4][msk[..., 2]] = False\n","        msk[..., 4][msk[..., 3]] = False\n","        msk[..., 0][msk[..., 1:].max(axis=2)] = False\n","        msk = msk * 1\n","\n","        lbl_msk = msk.argmax(axis=2)\n","\n","        img = np.concatenate([img, img2], axis=2)\n","        img = preprocess_inputs(img)\n","\n","        img = torch.from_numpy(img.transpose((2, 0, 1))).float()\n","        msk = torch.from_numpy(msk.transpose((2, 0, 1))).long()\n","\n","        sample = {'img': img, 'msk': msk, 'lbl_msk': lbl_msk, 'fn': fn}\n","        return sample\n","\n","\n","class ValData(Dataset):\n","    def __init__(self, image_idxs):\n","        super().__init__()\n","        self.image_idxs = image_idxs\n","\n","    def __len__(self):\n","        return len(self.image_idxs)\n","\n","    def __getitem__(self, idx):\n","        _idx = self.image_idxs[idx]\n","\n","        fn = all_files2[_idx]\n","\n","        img = cv2.imread(fn, cv2.IMREAD_COLOR)\n","        img2 = cv2.imread(fn.replace('_pre_disaster', '_post_disaster'), cv2.IMREAD_COLOR)\n","        msk_loc = cv2.imread(fn.replace('/images/', '/targets/').replace('.png', '_target.png'), cv2.IMREAD_UNCHANGED)# \u003e (0.3*255)\n","\n","        msk0 = cv2.imread(fn.replace('/images/', '/targets/').replace('.png', '_target.png'), cv2.IMREAD_UNCHANGED)\n","        lbl_msk1 = cv2.imread(fn.replace('/images/', '/targets/').replace('_pre_disaster', '_post_disaster').replace('.png', '_target.png'), cv2.IMREAD_UNCHANGED)\n","        msk1 = np.zeros_like(lbl_msk1)\n","        msk2 = np.zeros_like(lbl_msk1)\n","        msk3 = np.zeros_like(lbl_msk1)\n","        msk4 = np.zeros_like(lbl_msk1)\n","        msk1[lbl_msk1 == 1] = 255\n","        msk2[lbl_msk1 == 2] = 255\n","        msk3[lbl_msk1 == 3] = 255\n","        msk4[lbl_msk1 == 4] = 255\n","\n","        msk0 = msk0[..., np.newaxis]\n","        msk1 = msk1[..., np.newaxis]\n","        msk2 = msk2[..., np.newaxis]\n","        msk3 = msk3[..., np.newaxis]\n","        msk4 = msk4[..., np.newaxis]\n","\n","        msk = np.concatenate([msk0, msk1, msk2, msk3, msk4], axis=2)\n","        msk = (msk \u003e 127)\n","\n","        msk = msk * 1\n","\n","        lbl_msk = msk[..., 1:].argmax(axis=2)\n","\n","        img = np.concatenate([img, img2], axis=2)\n","        img = preprocess_inputs(img)\n","\n","        img = torch.from_numpy(img.transpose((2, 0, 1))).float()\n","        msk = torch.from_numpy(msk.transpose((2, 0, 1))).long()\n","\n","        sample = {'img': img, 'msk': msk, 'lbl_msk': lbl_msk, 'fn': fn, 'msk_loc': msk_loc}\n","        return sample\n","\n","\n","def validate(net, data_loader):\n","    dices0 = []\n","\n","    tp = np.zeros((5,))\n","    fp = np.zeros((5,))\n","    fn = np.zeros((5,))\n","\n","    _thr = 0.3\n","\n","    with torch.no_grad():\n","        for i, sample in enumerate(tqdm(data_loader)):\n","            msks = sample[\"msk\"].numpy()\n","            lbl_msk = sample[\"lbl_msk\"].numpy()\n","            imgs = sample[\"img\"].cuda(non_blocking=True)\n","            msk_loc = sample[\"msk_loc\"].numpy() * 1\n","            out = model(imgs)\n","\n","            msk_pred = msk_loc\n","            msk_damage_pred = torch.softmax(out, dim=1).cpu().numpy()[:, 1:, ...]\n","\n","            for j in range(msks.shape[0]):\n","                tp[4] += np.logical_and(msks[j, 0] \u003e 0, msk_pred[j] \u003e 0).sum()\n","                fn[4] += np.logical_and(msks[j, 0] \u003c 1, msk_pred[j] \u003e 0).sum()\n","                fp[4] += np.logical_and(msks[j, 0] \u003e 0, msk_pred[j] \u003c 1).sum()\n","\n","\n","                targ = lbl_msk[j][msks[j, 0] \u003e 0]\n","                pred = msk_damage_pred[j].argmax(axis=0)\n","                pred = pred * (msk_pred[j] \u003e _thr)\n","                pred = pred[msks[j, 0] \u003e 0]\n","                for c in range(4):\n","                    tp[c] += np.logical_and(pred == c, targ == c).sum()\n","                    fn[c] += np.logical_and(pred != c, targ == c).sum()\n","                    fp[c] += np.logical_and(pred == c, targ != c).sum()\n","\n","    d0 = 2 * tp[4] / (2 * tp[4] + fp[4] + fn[4])\n","\n","    f1_sc = np.zeros((4,))\n","    for c in range(4):\n","        f1_sc[c] = 2 * tp[c] / (2 * tp[c] + fp[c] + fn[c])\n","\n","    f1 = 4 / np.sum(1.0 / (f1_sc + 1e-6))\n","\n","    sc = 0.3 * d0 + 0.7 * f1\n","    print(\"Val Score: {}, Dice: {}, F1: {}, F1_0: {}, F1_1: {}, F1_2: {}, F1_3: {}\".format(sc, d0, f1, f1_sc[0], f1_sc[1], f1_sc[2], f1_sc[3]))\n","    return sc\n","\n","\n","def evaluate_val(data_val, best_score, model, snapshot_name, current_epoch):\n","    model = model.eval()\n","    d = validate(model, data_loader=data_val)\n","\n","    if d \u003e best_score:\n","        torch.save({\n","            'epoch': current_epoch + 1,\n","            'state_dict': model.state_dict(),\n","            'best_score': d,\n","        }, path.join(models_folder, snapshot_name + '_best'))\n","        best_score = d\n","\n","    print(\"score: {}\\tscore_best: {}\".format(d, best_score))\n","    return best_score\n","\n","\n","def train_epoch(current_epoch, seg_loss, ce_loss, seg_seesaw, model, optimizer, scheduler, train_data_loader):\n","    losses = AverageMeter()\n","    losses1 = AverageMeter()\n","\n","    dices = AverageMeter()\n","\n","    iterator = tqdm(train_data_loader)\n","    model.train()\n","    for i, sample in enumerate(iterator):\n","        imgs = sample[\"img\"].cuda(non_blocking=True)\n","        msks = sample[\"msk\"].cuda(non_blocking=True)\n","        lbl_msk = sample[\"lbl_msk\"].cuda(non_blocking=True)\n","\n","        out = model(imgs)\n","\n","        # loss0 = seg_loss(out[:, 0, ...], msks[:, 0, ...])\n","        # loss1 = seg_loss(out[:, 1, ...], msks[:, 1, ...])\n","        # loss2 = seg_loss(out[:, 2, ...], msks[:, 2, ...])\n","        # loss3 = seg_loss(out[:, 3, ...], msks[:, 3, ...])\n","        # loss4 = seg_loss(out[:, 4, ...], msks[:, 4, ...])\n","\n","        loss5 = ce_loss(out, lbl_msk)\n","        #loss5 = seg_seesaw(out, lbl_msk)\n","        loss = loss5\n","        #loss = 0.1 * loss0 + 0.1 * loss1 + 0.3 * loss2 + 0.3 * loss3 + 0.2 * loss4 + loss5 * 2\n","\n","        with torch.no_grad():\n","            _probs = 1 - torch.sigmoid(out[:, 0, ...])\n","            dice_sc = 1 - dice_round(_probs, 1 - msks[:, 0, ...])\n","\n","        losses.update(loss.item(), imgs.size(0))\n","        losses1.update(loss5.item(), imgs.size(0))\n","\n","        dices.update(dice_sc, imgs.size(0))\n","\n","        iterator.set_description(\n","            \"epoch: {}; lr {:.7f}; Loss {loss.val:.4f} ({loss.avg:.4f}); cce_loss {loss1.val:.4f} ({loss1.avg:.4f}); Dice {dice.val:.4f} ({dice.avg:.4f})\".format(\n","                current_epoch, scheduler.get_lr()[-1], loss=losses, loss1=losses1, dice=dices))\n","\n","        optimizer.zero_grad()\n","        # loss.backward()\n","        with amp.scale_loss(loss, optimizer) as scaled_loss:\n","            scaled_loss.backward()\n","        torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), 0.999)\n","        optimizer.step()\n","\n","    scheduler.step()\n","\n","    print(\"epoch: {}; lr {:.7f}; Loss {loss.avg:.4f}; CCE_loss {loss1.avg:.4f}; Dice {dice.avg:.4f}\".format(\n","            current_epoch, scheduler.get_lr()[-1], loss=losses, loss1=losses1, dice=dices))\n","\n","def train_epoch(current_epoch, seg_loss, ce_loss, seg_seesaw, model, optimizer, scheduler, train_data_loader):\n","    losses = AverageMeter()\n","    losses1 = AverageMeter()\n","\n","    dices = AverageMeter()\n","\n","    iterator = tqdm(train_data_loader)\n","    model.train()\n","    for i, sample in enumerate(iterator):\n","        if sample[\"img\"] is None or sample[\"msk\"] is None or sample[\"lbl_msk\"] is None:\n","              continue\n","        imgs = sample[\"img\"].cuda(non_blocking=True)\n","        msks = sample[\"msk\"].cuda(non_blocking=True)\n","        lbl_msk = sample[\"lbl_msk\"].cuda(non_blocking=True)\n","\n","        out = model(imgs)\n","\n","        loss5 = ce_loss(out, lbl_msk)\n","        loss = loss5\n","\n","        with torch.no_grad():\n","            _probs = 1 - torch.sigmoid(out[:, 0, ...])\n","            dice_sc = 1 - dice_round(_probs, 1 - msks[:, 0, ...])\n","\n","        losses.update(loss.item(), imgs.size(0))\n","        losses1.update(loss5.item(), imgs.size(0))\n","\n","        dices.update(dice_sc, imgs.size(0))\n","\n","        iterator.set_description(\n","            \"epoch: {}; lr {:.7f}; Loss {loss.val:.4f} ({loss.avg:.4f}); cce_loss {loss1.val:.4f} ({loss1.avg:.4f}); Dice {dice.val:.4f} ({dice.avg:.4f})\".format(\n","                current_epoch, scheduler.get_lr()[-1], loss=losses, loss1=losses1, dice=dices))\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.999)\n","        optimizer.step()\n","\n","    scheduler.step()\n","\n","    print(\"epoch: {}; lr {:.7f}; Loss {loss.avg:.4f}; CCE_loss {loss1.avg:.4f}; Dice {dice.avg:.4f}\".format(\n","            current_epoch, scheduler.get_lr()[-1], loss=losses, loss1=losses1, dice=dices))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8159259,"status":"ok","timestamp":1686753007511,"user":{"displayName":"Antonio Santos","userId":"03265893617080544823"},"user_tz":180},"id":"AL3hRfYVR6t7","outputId":"fdf07989-d5fe-481c-b767-e111ec045b95"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 9162/9162 [2:02:33\u003c00:00,  1.25it/s]\n","100%|██████████| 906/906 [13:25\u003c00:00,  1.12it/s]\n","100%|██████████| 906/906 [00:00\u003c00:00, 2019149.53it/s]\n","100%|██████████| 9070/9070 [00:00\u003c00:00, 410071.55it/s]\n","100%|██████████| 9070/9070 [00:00\u003c00:00, 420148.40it/s]\n"]}],"source":["# ttt = np.asarray([True, False, True, True])\n","# p1=ttt[0:].max()\n","# p2=ttt[1].max()\n","# ttt2 = np.asarray([True, True, False, False])\n","# p3=ttt2[1].max()\n","# p4=ttt2[2:3].max()\n","t0 = timeit.default_timer()\n","\n","makedirs(models_folder, exist_ok=True)\n","\n","seed = 13\n","#seed=0\n","# vis_dev = sys.argv[2]\n","\n","# os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n","# os.environ[\"CUDA_VISIBLE_DEVICES\"] = vis_dev\n","\n","cudnn.benchmark = True\n","\n","batch_size = 12\n","val_batch_size = 10\n","\n","snapshot_name = 'res50_cls_2Ssum_{}_0'.format(seed)\n","\n","file_classes = []\n","for fn in tqdm(all_files):\n","    fl = np.zeros((4,), dtype=bool)\n","    msk1 = cv2.imread(fn.replace('/images/', '/targets/').replace('_pre_disaster', '_post_disaster').replace('.png', '_target.png'), cv2.IMREAD_UNCHANGED)\n","    for c in range(1, 5):\n","        fl[c-1] = c in msk1\n","    file_classes.append(fl)\n","file_classes = np.asarray(file_classes)\n","\n","file_classes2 = []\n","for fn in tqdm(all_files2):\n","    fl = np.zeros((4,), dtype=bool)\n","    msk1 = cv2.imread(fn.replace('/images/', '/targets/').replace('_pre_disaster', '_post_disaster').replace('.png', '_target.png'), cv2.IMREAD_UNCHANGED)\n","    for c in range(1, 5):\n","        fl[c-1] = c in msk1\n","    file_classes2.append(fl)\n","file_classes2 = np.asarray(file_classes2)\n","\n","train_idxs0, val_idxs = train_test_split(np.arange(len(all_files)), test_size=0.01, random_state=seed)\n","\n","val_idxs0 = np.arange(len(all_files2))\n","\n","val_idxs = []\n","for i in tqdm(val_idxs0):\n","    val_idxs.append(i)\n","\n","np.random.seed(seed + 1234)\n","random.seed(seed + 1234)\n","\n","train_idxs = []\n","for i in tqdm(train_idxs0):\n","    train_idxs.append(i)\n","    if file_classes[i, 1:].max():\n","        train_idxs.append(i)\n","    # if file_classes[i, 2].max():\n","    #     train_idxs.append(i)\n","low1 = len(train_idxs)\n","for i in tqdm(train_idxs0):\n","    if file_classes[i, 1:3].max():\n","        train_idxs.append(i)\n","# for i in train_idxs0:\n","#     if file_classes[i, 1].max():\n","#         train_idxs.append(i)\n","high1 = len(train_idxs)\n","\n","train_idxs = np.asarray(train_idxs)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1686753007511,"user":{"displayName":"Antonio Santos","userId":"03265893617080544823"},"user_tz":180},"id":"ZxguzzcmqDBX","outputId":"1479cd60-2312-4a07-9ab2-435a85bf9925"},"outputs":[{"name":"stdout","output_type":"stream","text":["steps_per_epoch 1227 validation_steps 90\n"]}],"source":["steps_per_epoch = len(train_idxs) // batch_size\n","validation_steps = len(val_idxs) // val_batch_size\n","\n","print('steps_per_epoch', steps_per_epoch, 'validation_steps', validation_steps)\n","\n","data_train = TrainData(train_idxs, low1, high1)\n","val_train = ValData(val_idxs)\n","\n","train_data_loader = DataLoader(data_train, batch_size=batch_size, num_workers=6, shuffle=True, pin_memory=False, drop_last=True)\n","val_data_loader = DataLoader(val_train, batch_size=val_batch_size, num_workers=6, shuffle=False, pin_memory=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"iae4EwCfz-Q7"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading: \"http://data.lip6.fr/cadene/pretrainedmodels/se_resnext50_32x4d-a260b3a4.pth\" to /root/.cache/torch/hub/checkpoints/se_resnext50_32x4d-a260b3a4.pth\n","100%|██████████| 105M/105M [05:10\u003c00:00, 356kB/s]\n","  0%|          | 0/1227 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","epoch: 0; lr 0.0002020; Loss 7.3427 (7.3427); cce_loss 7.3427 (7.3427); Dice 0.1464 (0.1464):   0%|          | 0/1227 [00:58\u003c?, ?it/s]\u003cipython-input-6-b49c52c0b773\u003e:70: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1485.)\n","  exp_avg.mul_(beta1).add_(1 - beta1, grad)\n","epoch: 0; lr 0.0002020; Loss 0.0828 (0.1656); cce_loss 0.0828 (0.1656); Dice 0.0865 (0.1925): 100%|██████████| 1227/1227 [1:41:49\u003c00:00,  4.98s/it]\n"]},{"name":"stdout","output_type":"stream","text":["epoch: 0; lr 0.0002020; Loss 0.1656; CCE_loss 0.1656; Dice 0.1925\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 91/91 [09:48\u003c00:00,  6.47s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Val Score: 0.47813919673207655, Dice: 1.0, F1: 0.2544845667601094, F1_0: 0.9258317648623338, F1_1: 0.0849962801567158, F1_2: 0.6133427760891194, F1_3: 0.8048620066195342\n","score: 0.47813919673207655\tscore_best: 0.47813919673207655\n"]},{"name":"stderr","output_type":"stream","text":["epoch: 1; lr 0.0002020; Loss 0.0558 (0.1052); cce_loss 0.0558 (0.1052); Dice 0.1957 (0.1925):  17%|█▋        | 212/1227 [03:07\u003c14:32,  1.16it/s]"]}],"source":["#model = SeResNext50_Unet_Double().cuda()\n","import ssl\n","ssl._create_default_https_context = ssl._create_unverified_context\n","model = SeResNext50_Unet_2Ssum().cuda()\n","\n","params = model.parameters()\n","\n","optimizer = AdamW(params, lr=0.000202, weight_decay=1e-6)     #0.002\n","\n","#model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\")\n","#model = nn.DataParallel(model).cuda()\n","\n","scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[5, 13, 19, 23, 28, 47, 50, 60, 70, 90, 110, 130, 150, 170, 180, 190], gamma=0.5)\n","#scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[5, 11, 15, 23,  29, 33, 47, 50, 60, 70, 90, 110, 130, 150, 170, 180, 190], gamma=0.5)\n","\n","#snap_to_load = 'res50_cls_cutmixCE1_{}_0_best'.format(seed)\n","#print(\"=\u003e loading checkpoint '{}'\".format(snap_to_load))\n","#checkpoint = torch.load(path.join(models_folder, snap_to_load), map_location='cpu')\n","#loaded_dict = checkpoint['state_dict']\n","#sd = model.state_dict()\n","#for k in model.state_dict():\n","#    if k in loaded_dict and sd[k].size() == loaded_dict[k].size():\n","#        sd[k] = loaded_dict[k]\n","#loaded_dict = sd\n","#model.load_state_dict(loaded_dict)\n","#print(\"loaded checkpoint '{}' (epoch {}, best_score {})\"\n","#        .format(snap_to_load, checkpoint['epoch'], checkpoint['best_score']))\n","#del loaded_dict\n","#del sd\n","#del checkpoint\n","gc.collect()\n","torch.cuda.empty_cache()\n","\n","model = nn.DataParallel(model).cuda()\n","\n","seg_loss = ComboLoss({'dice': 0.5, 'focal': 2.0}, per_image=False).cuda()\n","#wei = [2., 2., 3., 3., 2.]\n","#wei = torch.tensor(wei)\n","ce_loss = nn.CrossEntropyLoss().cuda()\n","seg_lossSeesaw = None#SeesawLoss2().cuda()\n","\n","best_score = 0\n","torch.cuda.empty_cache()\n","for epoch in range(25):\n","    train_epoch(epoch, seg_loss, ce_loss, seg_lossSeesaw, model, optimizer, scheduler, train_data_loader)\n","    if epoch % 2 == 0 and epoch \u003c= 20:\n","        torch.cuda.empty_cache()\n","        best_score = evaluate_val(val_data_loader, best_score, model, snapshot_name, epoch)\n","    if epoch \u003e 20:\n","        torch.cuda.empty_cache()\n","        best_score = evaluate_val(val_data_loader, best_score, model, snapshot_name, epoch)\n","\n","torch.save(model.state_dict(), '/content/drive/MyDrive/Modeling Satelities Images Building Damaged/models/modelBDANet_test_train_3.pth')\n","\n","elapsed = timeit.default_timer() - t0\n","print('Time: {:.3f} min'.format(elapsed / 60))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":11377775,"status":"error","timestamp":1686721294535,"user":{"displayName":"Antonio Santos","userId":"03265893617080544823"},"user_tz":180},"id":"_Cb3XWt7GGj5","outputId":"7f3b86c0-2d92-4313-ebce-6f7c3ba6e391"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading: \"http://data.lip6.fr/cadene/pretrainedmodels/se_resnext50_32x4d-a260b3a4.pth\" to /root/.cache/torch/hub/checkpoints/se_resnext50_32x4d-a260b3a4.pth\n","100%|██████████| 105M/105M [05:10\u003c00:00, 356kB/s]\n","  0%|          | 0/1227 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","epoch: 0; lr 0.0002020; Loss 2.1333 (2.1333); cce_loss 2.1333 (2.1333); Dice 0.0925 (0.0925):   0%|          | 0/1227 [00:19\u003c?, ?it/s]\u003cipython-input-6-b49c52c0b773\u003e:70: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1485.)\n","  exp_avg.mul_(beta1).add_(1 - beta1, grad)\n","epoch: 0; lr 0.0002020; Loss 0.1426 (0.1498); cce_loss 0.1426 (0.1498); Dice 0.6682 (0.4174): 100%|██████████| 1227/1227 [55:01\u003c00:00,  2.69s/it]\n"]},{"name":"stdout","output_type":"stream","text":["epoch: 0; lr 0.0002020; Loss 0.1498; CCE_loss 0.1498; Dice 0.4174\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 91/91 [04:48\u003c00:00,  3.17s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Val Score: 0.48824514356388415, Dice: 1.0, F1: 0.26892163366269173, F1_0: 0.9125034739466232, F1_1: 0.09451986616088655, F1_2: 0.5097077185690015, F1_3: 0.8085650767789438\n","score: 0.48824514356388415\tscore_best: 0.48824514356388415\n"]},{"name":"stderr","output_type":"stream","text":["epoch: 1; lr 0.0002020; Loss 0.0974 (0.1143); cce_loss 0.0974 (0.1143); Dice 0.6073 (0.5445): 100%|██████████| 1227/1227 [17:06\u003c00:00,  1.20it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch: 1; lr 0.0002020; Loss 0.1143; CCE_loss 0.1143; Dice 0.5445\n"]},{"name":"stderr","output_type":"stream","text":["epoch: 2; lr 0.0002020; Loss 0.0968 (0.1016); cce_loss 0.0968 (0.1016); Dice 0.7424 (0.5637): 100%|██████████| 1227/1227 [12:11\u003c00:00,  1.68it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch: 2; lr 0.0002020; Loss 0.1016; CCE_loss 0.1016; Dice 0.5637\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 91/91 [03:13\u003c00:00,  2.13s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Val Score: 0.7812806748282082, Dice: 1.0, F1: 0.6875438211831547, F1_0: 0.9432108393236317, F1_1: 0.4631216420714571, F1_2: 0.703677394438535, F1_3: 0.8494400194127507\n","score: 0.7812806748282082\tscore_best: 0.7812806748282082\n"]},{"name":"stderr","output_type":"stream","text":["epoch: 3; lr 0.0002020; Loss 0.0635 (0.0988); cce_loss 0.0635 (0.0988); Dice 0.5720 (0.5721): 100%|██████████| 1227/1227 [22:09\u003c00:00,  1.08s/it]\n"]},{"name":"stdout","output_type":"stream","text":["epoch: 3; lr 0.0002020; Loss 0.0988; CCE_loss 0.0988; Dice 0.5721\n"]},{"name":"stderr","output_type":"stream","text":["epoch: 4; lr 0.0002020; Loss 0.1814 (0.0945); cce_loss 0.1814 (0.0945); Dice 0.5860 (0.5904): 100%|██████████| 1227/1227 [12:13\u003c00:00,  1.67it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch: 4; lr 0.0000505; Loss 0.0945; CCE_loss 0.0945; Dice 0.5904\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 91/91 [04:14\u003c00:00,  2.80s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Val Score: 0.8208444996780484, Dice: 1.0, F1: 0.7440635709686406, F1_0: 0.9511289124047113, F1_1: 0.559590709813279, F1_2: 0.7230982563299516, F1_3: 0.8661369713965267\n","score: 0.8208444996780484\tscore_best: 0.8208444996780484\n"]},{"name":"stderr","output_type":"stream","text":["epoch: 5; lr 0.0000505; Loss 0.0300 (0.0865); cce_loss 0.0300 (0.0865); Dice 0.3798 (0.5828): 100%|██████████| 1227/1227 [20:07\u003c00:00,  1.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch: 5; lr 0.0001010; Loss 0.0865; CCE_loss 0.0865; Dice 0.5828\n"]},{"name":"stderr","output_type":"stream","text":["epoch: 6; lr 0.0001010; Loss 0.1203 (0.0856); cce_loss 0.1203 (0.0856); Dice 0.6722 (0.5997): 100%|██████████| 1227/1227 [12:18\u003c00:00,  1.66it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch: 6; lr 0.0001010; Loss 0.0856; CCE_loss 0.0856; Dice 0.5997\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 91/91 [04:06\u003c00:00,  2.71s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Val Score: 0.8118244251555651, Dice: 1.0, F1: 0.7311777502222359, F1_0: 0.948998804004121, F1_1: 0.5302398019471878, F1_2: 0.7372120524573619, F1_3: 0.8514328084394733\n","score: 0.8118244251555651\tscore_best: 0.8208444996780484\n"]},{"name":"stderr","output_type":"stream","text":["epoch: 7; lr 0.0001010; Loss 0.1019 (0.0826); cce_loss 0.1019 (0.0826); Dice 0.6702 (0.6018):  92%|█████████▏| 1125/1227 [16:46\u003c01:31,  1.12it/s]\n"]},{"ename":"error","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-16-2d1fe5acd761\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 44\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 45\u001b[0;31m     \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseg_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mce_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseg_lossSeesaw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m\u003c=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m\u003cipython-input-13-f5574f4de1a9\u003e\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(current_epoch, seg_loss, ce_loss, seg_seesaw, model, optimizer, scheduler, train_data_loader)\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0miterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 444\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"img\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"msk\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lbl_msk\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m               \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 1178\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 633\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1343\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1344\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 1345\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 1371\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1372\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 644\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31merror\u001b[0m: Caught error in DataLoader worker process 3.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in \u003clistcomp\u003e\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"\u003cipython-input-13-f5574f4de1a9\u003e\", line 173, in __getitem__\n    img2 = cv2.resize(img2, input_shape, interpolation=cv2.INTER_LINEAR)\ncv2.error: OpenCV(4.7.0) /io/opencv/modules/imgproc/src/resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\n"]}],"source":["#model = SeResNext50_Unet_Double().cuda()\n","import ssl\n","ssl._create_default_https_context = ssl._create_unverified_context\n","model = SeResNext50_Unet_2Ssum().cuda()\n","\n","params = model.parameters()\n","\n","optimizer = AdamW(params, lr=0.000202, weight_decay=1e-6)     #0.002\n","\n","#model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\")\n","#model = nn.DataParallel(model).cuda()\n","\n","scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[5, 13, 19, 23, 28, 47, 50, 60, 70, 90, 110, 130, 150, 170, 180, 190], gamma=0.5)\n","#scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[5, 11, 15, 23,  29, 33, 47, 50, 60, 70, 90, 110, 130, 150, 170, 180, 190], gamma=0.5)\n","\n","#snap_to_load = 'res50_cls_cutmixCE1_{}_0_best'.format(seed)\n","#print(\"=\u003e loading checkpoint '{}'\".format(snap_to_load))\n","#checkpoint = torch.load(path.join(models_folder, snap_to_load), map_location='cpu')\n","#loaded_dict = checkpoint['state_dict']\n","#sd = model.state_dict()\n","#for k in model.state_dict():\n","#    if k in loaded_dict and sd[k].size() == loaded_dict[k].size():\n","#        sd[k] = loaded_dict[k]\n","#loaded_dict = sd\n","#model.load_state_dict(loaded_dict)\n","#print(\"loaded checkpoint '{}' (epoch {}, best_score {})\"\n","#        .format(snap_to_load, checkpoint['epoch'], checkpoint['best_score']))\n","#del loaded_dict\n","#del sd\n","#del checkpoint\n","gc.collect()\n","torch.cuda.empty_cache()\n","\n","model = nn.DataParallel(model).cuda()\n","\n","seg_loss = ComboLoss({'dice': 0.5, 'focal': 2.0}, per_image=False).cuda()\n","#wei = [2., 2., 3., 3., 2.]\n","#wei = torch.tensor(wei)\n","ce_loss = nn.CrossEntropyLoss().cuda()\n","seg_lossSeesaw = None#SeesawLoss2().cuda()\n","\n","best_score = 0\n","torch.cuda.empty_cache()\n","for epoch in range(25):\n","    train_epoch(epoch, seg_loss, ce_loss, seg_lossSeesaw, model, optimizer, scheduler, train_data_loader)\n","    if epoch % 2 == 0 and epoch \u003c= 20:\n","        torch.cuda.empty_cache()\n","        best_score = evaluate_val(val_data_loader, best_score, model, snapshot_name, epoch)\n","    if epoch \u003e 20:\n","        torch.cuda.empty_cache()\n","        best_score = evaluate_val(val_data_loader, best_score, model, snapshot_name, epoch)\n","\n","torch.save(model.state_dict(), '/content/drive/MyDrive/Modeling Satelities Images Building Damaged/models/modelBDANet_test_train_3.pth')\n","\n","elapsed = timeit.default_timer() - t0\n","print('Time: {:.3f} min'.format(elapsed / 60))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GHGryCXssKzG"},"outputs":[],"source":["#torch.cuda.empty_cache()\n","#del model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pRg_hj2MH2e7"},"outputs":[],"source":["#model.load_state_dict(torch.load('/content/drive/MyDrive/Modeling Satelities Images Building Damaged/models/modelBDANet_test_train_3.pth'))"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPxLKs259+ubQIxhJkKvGeS","collapsed_sections":["TlRP-duNXnpK","yUSNtuVeTUwl","pTW3yt84TQMf","N5xl5qEyTN3v","FXa807PbTjxn","Ifa7HjK2FVf3","Jbp9HIBOoO4H"],"machine_shape":"hm","name":"","toc_visible":true,"version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}