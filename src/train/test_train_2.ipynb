{"cells":[{"cell_type":"markdown","metadata":{"id":"xZ0IEwYcRzAl"},"source":["# Requirements"]},{"cell_type":"markdown","metadata":{"id":"TlRP-duNXnpK"},"source":["## Iniciation"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26221,"status":"ok","timestamp":1685488138549,"user":{"displayName":"Antonio Santos","userId":"03265893617080544823"},"user_tz":180},"id":"iCeN-zCbXqfV","outputId":"1149b95e-cc9b-4a97-a82e-7c3b2991700b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip uninstall torch torchvision torchaudio -y\n","!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uOyfTgUDztSD","executionInfo":{"status":"ok","timestamp":1685488245835,"user_tz":180,"elapsed":107288,"user":{"displayName":"Antonio Santos","userId":"03265893617080544823"}},"outputId":"c888213b-84a8-4774-a04c-ffdb741782ad"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: torch 2.0.1+cu118\n","Uninstalling torch-2.0.1+cu118:\n","  Successfully uninstalled torch-2.0.1+cu118\n","Found existing installation: torchvision 0.15.2+cu118\n","Uninstalling torchvision-0.15.2+cu118:\n","  Successfully uninstalled torchvision-0.15.2+cu118\n","Found existing installation: torchaudio 2.0.2+cu118\n","Uninstalling torchaudio-2.0.2+cu118:\n","  Successfully uninstalled torchaudio-2.0.2+cu118\n","Looking in indexes: https://download.pytorch.org/whl/cu118, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torch\n","  Downloading https://download.pytorch.org/whl/cu118/torch-2.0.1%2Bcu118-cp310-cp310-linux_x86_64.whl (2267.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m765.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchvision\n","  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.15.2%2Bcu118-cp310-cp310-linux_x86_64.whl (6.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m113.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchaudio\n","  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.0.2%2Bcu118-cp310-cp310-linux_x86_64.whl (4.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.5)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (8.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Installing collected packages: torch, torchvision, torchaudio\n","Successfully installed torch-2.0.1+cu118 torchaudio-2.0.2+cu118 torchvision-0.15.2+cu118\n"]}]},{"cell_type":"code","source":["!nvcc --version"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dSxd1Sjk6_2a","executionInfo":{"status":"ok","timestamp":1685488245835,"user_tz":180,"elapsed":5,"user":{"displayName":"Antonio Santos","userId":"03265893617080544823"}},"outputId":"124a8e57-663c-4106-a713-6df0caa7d3da"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2022 NVIDIA Corporation\n","Built on Wed_Sep_21_10:33:58_PDT_2022\n","Cuda compilation tools, release 11.8, V11.8.89\n","Build cuda_11.8.r11.8/compiler.31833905_0\n"]}]},{"cell_type":"code","source":["import torch\n","print(torch.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K0WhAIMi0KX1","executionInfo":{"status":"ok","timestamp":1685488248102,"user_tz":180,"elapsed":2270,"user":{"displayName":"Antonio Santos","userId":"03265893617080544823"}},"outputId":"e62dac4e-61eb-4c7b-e51c-d035b23bdf05"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["2.0.1+cu118\n"]}]},{"cell_type":"code","source":["!pip freeze"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ejMJGR8w0nmM","executionInfo":{"status":"ok","timestamp":1685488248854,"user_tz":180,"elapsed":755,"user":{"displayName":"Antonio Santos","userId":"03265893617080544823"}},"outputId":"56346eae-8af1-4bdf-e025-71a646e64ee4"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["absl-py==1.4.0\n","alabaster==0.7.13\n","albumentations==1.2.1\n","altair==4.2.2\n","anyio==3.6.2\n","appdirs==1.4.4\n","argon2-cffi==21.3.0\n","argon2-cffi-bindings==21.2.0\n","array-record==0.2.0\n","arviz==0.15.1\n","astropy==5.2.2\n","astunparse==1.6.3\n","attrs==23.1.0\n","audioread==3.0.0\n","autograd==1.5\n","Babel==2.12.1\n","backcall==0.2.0\n","beautifulsoup4==4.11.2\n","bleach==6.0.0\n","blis==0.7.9\n","blosc2==2.0.0\n","bokeh==2.4.3\n","branca==0.6.0\n","build==0.10.0\n","CacheControl==0.12.11\n","cached-property==1.5.2\n","cachetools==5.3.0\n","catalogue==2.0.8\n","certifi==2022.12.7\n","cffi==1.15.1\n","chardet==4.0.0\n","charset-normalizer==2.0.12\n","chex==0.1.7\n","click==8.1.3\n","cloudpickle==2.2.1\n","cmake==3.25.2\n","cmdstanpy==1.1.0\n","colorcet==3.0.1\n","colorlover==0.3.0\n","community==1.0.0b1\n","confection==0.0.4\n","cons==0.4.5\n","contextlib2==0.6.0.post1\n","contourpy==1.0.7\n","convertdate==2.4.0\n","cryptography==40.0.2\n","cufflinks==0.17.3\n","cupy-cuda11x==11.0.0\n","cvxopt==1.3.0\n","cvxpy==1.3.1\n","cycler==0.11.0\n","cymem==2.0.7\n","Cython==0.29.34\n","dask==2022.12.1\n","datascience==0.17.6\n","db-dtypes==1.1.1\n","dbus-python==1.2.16\n","debugpy==1.6.6\n","decorator==4.4.2\n","defusedxml==0.7.1\n","distributed==2022.12.1\n","dlib==19.24.1\n","dm-tree==0.1.8\n","docutils==0.16\n","dopamine-rl==4.0.6\n","duckdb==0.7.1\n","earthengine-api==0.1.350\n","easydict==1.10\n","ecos==2.0.12\n","editdistance==0.6.2\n","en-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl#sha256=0964370218b7e1672a30ac50d72cdc6b16f7c867496f1d60925691188f4d2510\n","entrypoints==0.4\n","ephem==4.1.4\n","et-xmlfile==1.1.0\n","etils==1.2.0\n","etuples==0.3.8\n","exceptiongroup==1.1.1\n","fastai==2.7.12\n","fastcore==1.5.29\n","fastdownload==0.0.7\n","fastjsonschema==2.16.3\n","fastprogress==1.0.3\n","fastrlock==0.8.1\n","filelock==3.12.0\n","firebase-admin==5.3.0\n","Flask==2.2.4\n","flatbuffers==23.3.3\n","flax==0.6.9\n","folium==0.14.0\n","fonttools==4.39.3\n","frozendict==2.3.7\n","fsspec==2023.4.0\n","future==0.18.3\n","gast==0.4.0\n","GDAL==3.3.2\n","gdown==4.6.6\n","gensim==4.3.1\n","geographiclib==2.0\n","geopy==2.3.0\n","gin-config==0.5.0\n","glob2==0.7\n","google==2.0.3\n","google-api-core==2.11.0\n","google-api-python-client==2.84.0\n","google-auth==2.17.3\n","google-auth-httplib2==0.1.0\n","google-auth-oauthlib==1.0.0\n","google-cloud-bigquery==3.9.0\n","google-cloud-bigquery-storage==2.19.1\n","google-cloud-core==2.3.2\n","google-cloud-datastore==2.15.1\n","google-cloud-firestore==2.11.0\n","google-cloud-language==2.9.1\n","google-cloud-storage==2.8.0\n","google-cloud-translate==3.11.1\n","google-colab @ file:///colabtools/dist/google-colab-1.0.0.tar.gz#sha256=5a00caf6ecf46f65407da5680ef137489f93189d1a1181701867e186ff906102\n","google-crc32c==1.5.0\n","google-pasta==0.2.0\n","google-resumable-media==2.5.0\n","googleapis-common-protos==1.59.0\n","googledrivedownloader==0.4\n","graphviz==0.20.1\n","greenlet==2.0.2\n","grpcio==1.54.0\n","grpcio-status==1.48.2\n","gspread==3.4.2\n","gspread-dataframe==3.0.8\n","gym==0.25.2\n","gym-notices==0.0.8\n","h5netcdf==1.1.0\n","h5py==3.8.0\n","holidays==0.25\n","holoviews==1.15.4\n","html5lib==1.1\n","httpimport==1.3.0\n","httplib2==0.21.0\n","humanize==4.6.0\n","hyperopt==0.2.7\n","idna==3.4\n","imageio==2.25.1\n","imageio-ffmpeg==0.4.8\n","imagesize==1.4.1\n","imbalanced-learn==0.10.1\n","imgaug==0.4.0\n","importlib-resources==5.12.0\n","imutils==0.5.4\n","inflect==6.0.4\n","iniconfig==2.0.0\n","intel-openmp==2023.1.0\n","ipykernel==5.5.6\n","ipython==7.34.0\n","ipython-genutils==0.2.0\n","ipython-sql==0.4.1\n","ipywidgets==7.7.1\n","itsdangerous==2.1.2\n","jax==0.4.10\n","jaxlib @ https://storage.googleapis.com/jax-releases/cuda11/jaxlib-0.4.10+cuda11.cudnn86-cp310-cp310-manylinux2014_x86_64.whl#sha256=fe53205ef12727c80ed5ac2d4506d6732c0c3db69ede4565a7d4df98e609af84\n","jieba==0.42.1\n","Jinja2==3.1.2\n","joblib==1.2.0\n","jsonpickle==3.0.1\n","jsonschema==4.3.3\n","jupyter-client==6.1.12\n","jupyter-console==6.1.0\n","jupyter-server==1.24.0\n","jupyter_core==5.3.0\n","jupyterlab-pygments==0.2.2\n","jupyterlab-widgets==3.0.7\n","kaggle==1.5.13\n","keras==2.12.0\n","kiwisolver==1.4.4\n","korean-lunar-calendar==0.3.1\n","langcodes==3.3.0\n","lazy_loader==0.2\n","libclang==16.0.0\n","librosa==0.10.0.post2\n","lightgbm==3.3.5\n","lit==16.0.5\n","llvmlite==0.39.1\n","locket==1.0.0\n","logical-unification==0.4.5\n","LunarCalendar==0.0.9\n","lxml==4.9.2\n","Markdown==3.4.3\n","markdown-it-py==2.2.0\n","MarkupSafe==2.1.2\n","matplotlib==3.7.1\n","matplotlib-inline==0.1.6\n","matplotlib-venn==0.11.9\n","mdurl==0.1.2\n","miniKanren==1.0.3\n","missingno==0.5.2\n","mistune==0.8.4\n","mizani==0.8.1\n","mkl==2019.0\n","ml-dtypes==0.1.0\n","mlxtend==0.14.0\n","more-itertools==9.1.0\n","moviepy==1.0.3\n","mpmath==1.3.0\n","msgpack==1.0.5\n","multipledispatch==0.6.0\n","multitasking==0.0.11\n","murmurhash==1.0.9\n","music21==8.1.0\n","natsort==8.3.1\n","nbclient==0.7.4\n","nbconvert==6.5.4\n","nbformat==5.8.0\n","nest-asyncio==1.5.6\n","networkx==3.1\n","nibabel==3.0.2\n","nltk==3.8.1\n","notebook==6.4.8\n","numba==0.56.4\n","numexpr==2.8.4\n","numpy==1.22.4\n","oauth2client==4.1.3\n","oauthlib==3.2.2\n","opencv-contrib-python==4.7.0.72\n","opencv-python==4.7.0.72\n","opencv-python-headless==4.7.0.72\n","openpyxl==3.0.10\n","opt-einsum==3.3.0\n","optax==0.1.5\n","orbax-checkpoint==0.2.1\n","osqp==0.6.2.post8\n","packaging==23.1\n","palettable==3.3.3\n","pandas==1.5.3\n","pandas-datareader==0.10.0\n","pandas-gbq==0.17.9\n","pandocfilters==1.5.0\n","panel==0.14.4\n","param==1.13.0\n","parso==0.8.3\n","partd==1.4.0\n","pathlib==1.0.1\n","pathy==0.10.1\n","patsy==0.5.3\n","pexpect==4.8.0\n","pickleshare==0.7.5\n","Pillow==8.4.0\n","pip-tools==6.13.0\n","platformdirs==3.3.0\n","plotly==5.13.1\n","plotnine==0.10.1\n","pluggy==1.0.0\n","polars==0.17.3\n","pooch==1.6.0\n","portpicker==1.3.9\n","prefetch-generator==1.0.3\n","preshed==3.0.8\n","prettytable==0.7.2\n","proglog==0.1.10\n","progressbar2==4.2.0\n","prometheus-client==0.16.0\n","promise==2.3\n","prompt-toolkit==3.0.38\n","prophet==1.1.3\n","proto-plus==1.22.2\n","protobuf==3.20.3\n","psutil==5.9.5\n","psycopg2==2.9.6\n","ptyprocess==0.7.0\n","py-cpuinfo==9.0.0\n","py4j==0.10.9.7\n","pyarrow==9.0.0\n","pyasn1==0.5.0\n","pyasn1-modules==0.3.0\n","pycocotools==2.0.6\n","pycparser==2.21\n","pyct==0.5.0\n","pydantic==1.10.7\n","pydata-google-auth==1.7.0\n","pydot==1.4.2\n","pydot-ng==2.0.0\n","pydotplus==2.0.2\n","PyDrive==1.3.1\n","pyerfa==2.0.0.3\n","pygame==2.3.0\n","Pygments==2.14.0\n","PyGObject==3.36.0\n","pymc==5.1.2\n","PyMeeus==0.5.12\n","pymystem3==0.2.0\n","PyOpenGL==3.1.6\n","pyparsing==3.0.9\n","pyproject_hooks==1.0.0\n","pyrsistent==0.19.3\n","PySocks==1.7.1\n","pytensor==2.10.1\n","pytest==7.2.2\n","python-apt==0.0.0\n","python-dateutil==2.8.2\n","python-louvain==0.16\n","python-slugify==8.0.1\n","python-utils==3.5.2\n","pytz==2022.7.1\n","pytz-deprecation-shim==0.1.0.post0\n","pyviz-comms==2.2.1\n","PyWavelets==1.4.1\n","PyYAML==6.0\n","pyzmq==23.2.1\n","qdldl==0.1.7\n","qudida==0.0.4\n","regex==2022.10.31\n","requests==2.27.1\n","requests-oauthlib==1.3.1\n","requests-unixsocket==0.2.0\n","requirements-parser==0.5.0\n","rich==13.3.4\n","rpy2==3.5.5\n","rsa==4.9\n","scikit-image==0.19.3\n","scikit-learn==1.2.2\n","scipy==1.10.1\n","scs==3.2.3\n","seaborn==0.12.2\n","Send2Trash==1.8.0\n","shapely==2.0.1\n","six==1.16.0\n","sklearn-pandas==2.2.0\n","smart-open==6.3.0\n","sniffio==1.3.0\n","snowballstemmer==2.2.0\n","sortedcontainers==2.4.0\n","soundfile==0.12.1\n","soupsieve==2.4.1\n","soxr==0.3.5\n","spacy==3.5.2\n","spacy-legacy==3.0.12\n","spacy-loggers==1.0.4\n","Sphinx==3.5.4\n","sphinxcontrib-applehelp==1.0.4\n","sphinxcontrib-devhelp==1.0.2\n","sphinxcontrib-htmlhelp==2.0.1\n","sphinxcontrib-jsmath==1.0.1\n","sphinxcontrib-qthelp==1.0.3\n","sphinxcontrib-serializinghtml==1.1.5\n","SQLAlchemy==2.0.10\n","sqlparse==0.4.4\n","srsly==2.4.6\n","statsmodels==0.13.5\n","sympy==1.11.1\n","tables==3.8.0\n","tabulate==0.8.10\n","tblib==1.7.0\n","tenacity==8.2.2\n","tensorboard==2.12.2\n","tensorboard-data-server==0.7.0\n","tensorboard-plugin-wit==1.8.1\n","tensorflow==2.12.0\n","tensorflow-datasets==4.9.2\n","tensorflow-estimator==2.12.0\n","tensorflow-gcs-config==2.12.0\n","tensorflow-hub==0.13.0\n","tensorflow-io-gcs-filesystem==0.32.0\n","tensorflow-metadata==1.13.1\n","tensorflow-probability==0.20.1\n","tensorstore==0.1.36\n","termcolor==2.3.0\n","terminado==0.17.1\n","text-unidecode==1.3\n","textblob==0.17.1\n","tf-slim==1.1.0\n","thinc==8.1.9\n","threadpoolctl==3.1.0\n","tifffile==2023.4.12\n","tinycss2==1.2.1\n","toml==0.10.2\n","tomli==2.0.1\n","toolz==0.12.0\n","torch==2.0.1+cu118\n","torchaudio==2.0.2+cu118\n","torchdata==0.6.1\n","torchsummary==1.5.1\n","torchtext==0.15.2\n","torchvision==0.15.2+cu118\n","tornado==6.3.1\n","tqdm==4.65.0\n","traitlets==5.7.1\n","triton==2.0.0\n","tweepy==4.13.0\n","typer==0.7.0\n","types-setuptools==67.8.0.0\n","typing_extensions==4.5.0\n","tzdata==2023.3\n","tzlocal==4.3\n","uritemplate==4.1.1\n","urllib3==1.26.15\n","vega-datasets==0.9.0\n","wasabi==1.1.1\n","wcwidth==0.2.6\n","webcolors==1.13\n","webencodings==0.5.1\n","websocket-client==1.5.1\n","Werkzeug==2.3.0\n","widgetsnbextension==3.6.4\n","wordcloud==1.8.2.2\n","wrapt==1.14.1\n","xarray==2022.12.0\n","xarray-einstats==0.5.1\n","xgboost==1.7.5\n","xlrd==2.0.1\n","yellowbrick==1.5\n","yfinance==0.2.18\n","zict==3.0.0\n","zipp==3.15.0\n"]}]},{"cell_type":"markdown","metadata":{"id":"5rmjtBX5T9_W"},"source":["## Installs"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jf7QXKrsT_Oe","executionInfo":{"status":"ok","timestamp":1685456547827,"user_tz":180,"elapsed":1481062,"user":{"displayName":"Antonio Santos","userId":"03265893617080544823"}},"outputId":"d7a31314-1d6b-48be-8701-c759e96a4c71"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'apex'...\n","remote: Enumerating objects: 11070, done.\u001b[K\n","remote: Counting objects: 100% (196/196), done.\u001b[K\n","remote: Compressing objects: 100% (118/118), done.\u001b[K\n","remote: Total 11070 (delta 109), reused 148 (delta 77), pack-reused 10874\u001b[K\n","Receiving objects: 100% (11070/11070), 15.34 MiB | 16.64 MiB/s, done.\n","Resolving deltas: 100% (7652/7652), done.\n","/content/apex\n","Using pip 23.1.2 from /usr/local/lib/python3.10/dist-packages/pip (python 3.10)\n","\u001b[33mDEPRECATION: --build-option and --global-option are deprecated. pip 23.3 will enforce this behaviour change. A possible replacement is to use --config-settings. Discussion can be found at https://github.com/pypa/pip/issues/11859\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Implying --no-binary=:all: due to the presence of --build-option / --global-option.\u001b[0m\u001b[33m\n","\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Processing /content/apex\n","  Running command python setup.py egg_info\n","\n","\n","  torch.__version__  = 2.0.1+cu118\n","\n","\n","  running egg_info\n","  creating /tmp/pip-pip-egg-info-p8zu6s3y/apex.egg-info\n","  writing /tmp/pip-pip-egg-info-p8zu6s3y/apex.egg-info/PKG-INFO\n","  writing dependency_links to /tmp/pip-pip-egg-info-p8zu6s3y/apex.egg-info/dependency_links.txt\n","  writing requirements to /tmp/pip-pip-egg-info-p8zu6s3y/apex.egg-info/requires.txt\n","  writing top-level names to /tmp/pip-pip-egg-info-p8zu6s3y/apex.egg-info/top_level.txt\n","  writing manifest file '/tmp/pip-pip-egg-info-p8zu6s3y/apex.egg-info/SOURCES.txt'\n","  reading manifest file '/tmp/pip-pip-egg-info-p8zu6s3y/apex.egg-info/SOURCES.txt'\n","  adding license file 'LICENSE'\n","  writing manifest file '/tmp/pip-pip-egg-info-p8zu6s3y/apex.egg-info/SOURCES.txt'\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: packaging>20.6 in /usr/local/lib/python3.10/dist-packages (from apex==0.1) (23.1)\n","Building wheels for collected packages: apex\n","  Running command python setup.py bdist_wheel\n","\n","\n","  torch.__version__  = 2.0.1+cu118\n","\n","\n","\n","  Compiling cuda extensions with\n","  nvcc: NVIDIA (R) Cuda compiler driver\n","  Copyright (c) 2005-2022 NVIDIA Corporation\n","  Built on Wed_Sep_21_10:33:58_PDT_2022\n","  Cuda compilation tools, release 11.8, V11.8.89\n","  Build cuda_11.8.r11.8/compiler.31833905_0\n","  from /usr/local/cuda/bin\n","\n","  running bdist_wheel\n","  /usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:476: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n","    warnings.warn(msg.format('we could not find ninja.'))\n","  running build\n","  running build_py\n","  creating build\n","  creating build/lib.linux-x86_64-cpython-310\n","  creating build/lib.linux-x86_64-cpython-310/apex\n","  copying apex/_autocast_utils.py -> build/lib.linux-x86_64-cpython-310/apex\n","  copying apex/__init__.py -> build/lib.linux-x86_64-cpython-310/apex\n","  creating build/lib.linux-x86_64-cpython-310/apex/amp\n","  copying apex/amp/_initialize.py -> build/lib.linux-x86_64-cpython-310/apex/amp\n","  copying apex/amp/_process_optimizer.py -> build/lib.linux-x86_64-cpython-310/apex/amp\n","  copying apex/amp/rnn_compat.py -> build/lib.linux-x86_64-cpython-310/apex/amp\n","  copying apex/amp/compat.py -> build/lib.linux-x86_64-cpython-310/apex/amp\n","  copying apex/amp/wrap.py -> build/lib.linux-x86_64-cpython-310/apex/amp\n","  copying apex/amp/amp.py -> build/lib.linux-x86_64-cpython-310/apex/amp\n","  copying apex/amp/handle.py -> build/lib.linux-x86_64-cpython-310/apex/amp\n","  copying apex/amp/__version__.py -> build/lib.linux-x86_64-cpython-310/apex/amp\n","  copying apex/amp/utils.py -> build/lib.linux-x86_64-cpython-310/apex/amp\n","  copying apex/amp/_amp_state.py -> build/lib.linux-x86_64-cpython-310/apex/amp\n","  copying apex/amp/opt.py -> build/lib.linux-x86_64-cpython-310/apex/amp\n","  copying apex/amp/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/amp\n","  copying apex/amp/frontend.py -> build/lib.linux-x86_64-cpython-310/apex/amp\n","  copying apex/amp/scaler.py -> build/lib.linux-x86_64-cpython-310/apex/amp\n","  creating build/lib.linux-x86_64-cpython-310/apex/contrib\n","  copying apex/contrib/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib\n","  creating build/lib.linux-x86_64-cpython-310/apex/normalization\n","  copying apex/normalization/fused_layer_norm.py -> build/lib.linux-x86_64-cpython-310/apex/normalization\n","  copying apex/normalization/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/normalization\n","  creating build/lib.linux-x86_64-cpython-310/apex/multi_tensor_apply\n","  copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib.linux-x86_64-cpython-310/apex/multi_tensor_apply\n","  copying apex/multi_tensor_apply/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/multi_tensor_apply\n","  creating build/lib.linux-x86_64-cpython-310/apex/transformer\n","  copying apex/transformer/_ucc_util.py -> build/lib.linux-x86_64-cpython-310/apex/transformer\n","  copying apex/transformer/utils.py -> build/lib.linux-x86_64-cpython-310/apex/transformer\n","  copying apex/transformer/parallel_state.py -> build/lib.linux-x86_64-cpython-310/apex/transformer\n","  copying apex/transformer/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/transformer\n","  copying apex/transformer/microbatches.py -> build/lib.linux-x86_64-cpython-310/apex/transformer\n","  copying apex/transformer/log_util.py -> build/lib.linux-x86_64-cpython-310/apex/transformer\n","  copying apex/transformer/enums.py -> build/lib.linux-x86_64-cpython-310/apex/transformer\n","  creating build/lib.linux-x86_64-cpython-310/apex/mlp\n","  copying apex/mlp/mlp.py -> build/lib.linux-x86_64-cpython-310/apex/mlp\n","  copying apex/mlp/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/mlp\n","  creating build/lib.linux-x86_64-cpython-310/apex/parallel\n","  copying apex/parallel/sync_batchnorm.py -> build/lib.linux-x86_64-cpython-310/apex/parallel\n","  copying apex/parallel/multiproc.py -> build/lib.linux-x86_64-cpython-310/apex/parallel\n","  copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib.linux-x86_64-cpython-310/apex/parallel\n","  copying apex/parallel/optimized_sync_batchnorm.py -> build/lib.linux-x86_64-cpython-310/apex/parallel\n","  copying apex/parallel/sync_batchnorm_kernel.py -> build/lib.linux-x86_64-cpython-310/apex/parallel\n","  copying apex/parallel/distributed.py -> build/lib.linux-x86_64-cpython-310/apex/parallel\n","  copying apex/parallel/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/parallel\n","  copying apex/parallel/LARC.py -> build/lib.linux-x86_64-cpython-310/apex/parallel\n","  creating build/lib.linux-x86_64-cpython-310/apex/fp16_utils\n","  copying apex/fp16_utils/loss_scaler.py -> build/lib.linux-x86_64-cpython-310/apex/fp16_utils\n","  copying apex/fp16_utils/fp16util.py -> build/lib.linux-x86_64-cpython-310/apex/fp16_utils\n","  copying apex/fp16_utils/fp16_optimizer.py -> build/lib.linux-x86_64-cpython-310/apex/fp16_utils\n","  copying apex/fp16_utils/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/fp16_utils\n","  creating build/lib.linux-x86_64-cpython-310/apex/RNN\n","  copying apex/RNN/RNNBackend.py -> build/lib.linux-x86_64-cpython-310/apex/RNN\n","  copying apex/RNN/models.py -> build/lib.linux-x86_64-cpython-310/apex/RNN\n","  copying apex/RNN/cells.py -> build/lib.linux-x86_64-cpython-310/apex/RNN\n","  copying apex/RNN/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/RNN\n","  creating build/lib.linux-x86_64-cpython-310/apex/optimizers\n","  copying apex/optimizers/fused_adam.py -> build/lib.linux-x86_64-cpython-310/apex/optimizers\n","  copying apex/optimizers/fused_lamb.py -> build/lib.linux-x86_64-cpython-310/apex/optimizers\n","  copying apex/optimizers/fused_novograd.py -> build/lib.linux-x86_64-cpython-310/apex/optimizers\n","  copying apex/optimizers/fused_mixed_precision_lamb.py -> build/lib.linux-x86_64-cpython-310/apex/optimizers\n","  copying apex/optimizers/fused_adagrad.py -> build/lib.linux-x86_64-cpython-310/apex/optimizers\n","  copying apex/optimizers/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/optimizers\n","  copying apex/optimizers/fused_sgd.py -> build/lib.linux-x86_64-cpython-310/apex/optimizers\n","  creating build/lib.linux-x86_64-cpython-310/apex/fused_dense\n","  copying apex/fused_dense/fused_dense.py -> build/lib.linux-x86_64-cpython-310/apex/fused_dense\n","  copying apex/fused_dense/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/fused_dense\n","  creating build/lib.linux-x86_64-cpython-310/apex/amp/lists\n","  copying apex/amp/lists/torch_overrides.py -> build/lib.linux-x86_64-cpython-310/apex/amp/lists\n","  copying apex/amp/lists/tensor_overrides.py -> build/lib.linux-x86_64-cpython-310/apex/amp/lists\n","  copying apex/amp/lists/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/amp/lists\n","  copying apex/amp/lists/functional_overrides.py -> build/lib.linux-x86_64-cpython-310/apex/amp/lists\n","  creating build/lib.linux-x86_64-cpython-310/apex/contrib/xentropy\n","  copying apex/contrib/xentropy/softmax_xentropy.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/xentropy\n","  copying apex/contrib/xentropy/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/xentropy\n","  creating build/lib.linux-x86_64-cpython-310/apex/contrib/multihead_attn\n","  copying apex/contrib/multihead_attn/self_multihead_attn.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/multihead_attn\n","  copying apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/multihead_attn\n","  copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/multihead_attn\n","  copying apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/multihead_attn\n","  copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/multihead_attn\n","  copying apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/multihead_attn\n","  copying apex/contrib/multihead_attn/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/multihead_attn\n","  copying apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/multihead_attn\n","  copying apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/multihead_attn\n","  copying apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/multihead_attn\n","  creating build/lib.linux-x86_64-cpython-310/apex/contrib/peer_memory\n","  copying apex/contrib/peer_memory/peer_memory.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/peer_memory\n","  copying apex/contrib/peer_memory/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/peer_memory\n","  copying apex/contrib/peer_memory/peer_halo_exchanger_1d.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/peer_memory\n","  creating build/lib.linux-x86_64-cpython-310/apex/contrib/fmha\n","  copying apex/contrib/fmha/fmha.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/fmha\n","  copying apex/contrib/fmha/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/fmha\n","  creating build/lib.linux-x86_64-cpython-310/apex/contrib/groupbn\n","  copying apex/contrib/groupbn/batch_norm.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/groupbn\n","  copying apex/contrib/groupbn/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/groupbn\n","  creating build/lib.linux-x86_64-cpython-310/apex/contrib/sparsity\n","  copying apex/contrib/sparsity/sparse_masklib.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/sparsity\n","  copying apex/contrib/sparsity/permutation_lib.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/sparsity\n","  copying apex/contrib/sparsity/asp.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/sparsity\n","  copying apex/contrib/sparsity/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/sparsity\n","  creating build/lib.linux-x86_64-cpython-310/apex/contrib/test\n","  copying apex/contrib/test/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test\n","  creating build/lib.linux-x86_64-cpython-310/apex/contrib/bottleneck\n","  copying apex/contrib/bottleneck/halo_exchangers.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/bottleneck\n","  copying apex/contrib/bottleneck/bottleneck.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/bottleneck\n","  copying apex/contrib/bottleneck/test.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/bottleneck\n","  copying apex/contrib/bottleneck/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/bottleneck\n","  creating build/lib.linux-x86_64-cpython-310/apex/contrib/index_mul_2d\n","  copying apex/contrib/index_mul_2d/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/index_mul_2d\n","  copying apex/contrib/index_mul_2d/index_mul_2d.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/index_mul_2d\n","  creating build/lib.linux-x86_64-cpython-310/apex/contrib/layer_norm\n","  copying apex/contrib/layer_norm/layer_norm.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/layer_norm\n","  copying apex/contrib/layer_norm/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/layer_norm\n","  creating build/lib.linux-x86_64-cpython-310/apex/contrib/clip_grad\n","  copying apex/contrib/clip_grad/clip_grad.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/clip_grad\n","  copying apex/contrib/clip_grad/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/clip_grad\n","  creating build/lib.linux-x86_64-cpython-310/apex/contrib/optimizers\n","  copying apex/contrib/optimizers/distributed_fused_adam.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/optimizers\n","  copying apex/contrib/optimizers/distributed_fused_lamb.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/optimizers\n","  copying apex/contrib/optimizers/fused_adam.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/optimizers\n","  copying apex/contrib/optimizers/fused_lamb.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/optimizers\n","  copying apex/contrib/optimizers/fp16_optimizer.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/optimizers\n","  copying apex/contrib/optimizers/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/optimizers\n","  copying apex/contrib/optimizers/fused_sgd.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/optimizers\n","  creating build/lib.linux-x86_64-cpython-310/apex/contrib/conv_bias_relu\n","  copying apex/contrib/conv_bias_relu/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/conv_bias_relu\n","  copying apex/contrib/conv_bias_relu/conv_bias_relu.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/conv_bias_relu\n","  creating build/lib.linux-x86_64-cpython-310/apex/contrib/cudnn_gbn\n","  copying apex/contrib/cudnn_gbn/batch_norm.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/cudnn_gbn\n","  copying apex/contrib/cudnn_gbn/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/cudnn_gbn\n","  creating build/lib.linux-x86_64-cpython-310/apex/contrib/focal_loss\n","  copying apex/contrib/focal_loss/focal_loss.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/focal_loss\n","  copying apex/contrib/focal_loss/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/focal_loss\n","  creating build/lib.linux-x86_64-cpython-310/apex/contrib/transducer\n","  copying apex/contrib/transducer/_transducer_ref.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/transducer\n","  copying apex/contrib/transducer/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/transducer\n","  copying apex/contrib/transducer/transducer.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/transducer\n","  creating build/lib.linux-x86_64-cpython-310/apex/contrib/sparsity/permutation_search_kernels\n","  copying apex/contrib/sparsity/permutation_search_kernels/exhaustive_search.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/sparsity/permutation_search_kernels\n","  copying apex/contrib/sparsity/permutation_search_kernels/channel_swap.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/sparsity/permutation_search_kernels\n","  copying apex/contrib/sparsity/permutation_search_kernels/permutation_utilities.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/sparsity/permutation_search_kernels\n","  copying apex/contrib/sparsity/permutation_search_kernels/call_permutation_search_kernels.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/sparsity/permutation_search_kernels\n","  copying apex/contrib/sparsity/permutation_search_kernels/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/sparsity/permutation_search_kernels\n","  creating build/lib.linux-x86_64-cpython-310/apex/contrib/test/xentropy\n","  copying apex/contrib/test/xentropy/test_label_smoothing.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/xentropy\n","  copying apex/contrib/test/xentropy/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/xentropy\n","  creating build/lib.linux-x86_64-cpython-310/apex/contrib/test/multihead_attn\n","  copying apex/contrib/test/multihead_attn/test_fast_self_multihead_attn_bias.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/multihead_attn\n","  copying apex/contrib/test/multihead_attn/test_self_multihead_attn_norm_add.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/multihead_attn\n","  copying apex/contrib/test/multihead_attn/test_mha_fused_softmax.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/multihead_attn\n","  copying apex/contrib/test/multihead_attn/test_self_multihead_attn.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/multihead_attn\n","  copying apex/contrib/test/multihead_attn/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/multihead_attn\n","  copying apex/contrib/test/multihead_attn/test_encdec_multihead_attn_norm_add.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/multihead_attn\n","  copying apex/contrib/test/multihead_attn/test_encdec_multihead_attn.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/multihead_attn\n","  creating build/lib.linux-x86_64-cpython-310/apex/contrib/test/peer_memory\n","  copying apex/contrib/test/peer_memory/test_peer_halo_exchange_module.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/peer_memory\n","  copying apex/contrib/test/peer_memory/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/peer_memory\n","  creating build/lib.linux-x86_64-cpython-310/apex/contrib/test/fmha\n","  copying apex/contrib/test/fmha/test_fmha.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/fmha\n","  copying apex/contrib/test/fmha/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/fmha\n","  creating build/lib.linux-x86_64-cpython-310/apex/contrib/test/bottleneck\n","  copying apex/contrib/test/bottleneck/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/bottleneck\n","  copying apex/contrib/test/bottleneck/test_bottleneck_module.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/bottleneck\n","  creating build/lib.linux-x86_64-cpython-310/apex/contrib/test/index_mul_2d\n","  copying apex/contrib/test/index_mul_2d/test_index_mul_2d.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/index_mul_2d\n","  copying apex/contrib/test/index_mul_2d/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/index_mul_2d\n","  creating build/lib.linux-x86_64-cpython-310/apex/contrib/test/layer_norm\n","  copying apex/contrib/test/layer_norm/test_fast_layer_norm.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/layer_norm\n","  copying apex/contrib/test/layer_norm/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/layer_norm\n","  creating build/lib.linux-x86_64-cpython-310/apex/contrib/test/clip_grad\n","  copying apex/contrib/test/clip_grad/test_clip_grad.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/clip_grad\n","  copying apex/contrib/test/clip_grad/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/clip_grad\n","  creating build/lib.linux-x86_64-cpython-310/apex/contrib/test/optimizers\n","  copying apex/contrib/test/optimizers/test_distributed_fused_lamb.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/optimizers\n","  copying apex/contrib/test/optimizers/test_dist_adam.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/optimizers\n","  copying apex/contrib/test/optimizers/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/optimizers\n","  creating build/lib.linux-x86_64-cpython-310/apex/contrib/test/conv_bias_relu\n","  copying apex/contrib/test/conv_bias_relu/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/conv_bias_relu\n","  copying apex/contrib/test/conv_bias_relu/test_conv_bias_relu.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/conv_bias_relu\n","  creating build/lib.linux-x86_64-cpython-310/apex/contrib/test/cudnn_gbn\n","  copying apex/contrib/test/cudnn_gbn/test_cudnn_gbn_with_two_gpus.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/cudnn_gbn\n","  copying apex/contrib/test/cudnn_gbn/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/cudnn_gbn\n","  creating build/lib.linux-x86_64-cpython-310/apex/contrib/test/focal_loss\n","  copying apex/contrib/test/focal_loss/test_focal_loss.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/focal_loss\n","  copying apex/contrib/test/focal_loss/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/focal_loss\n","  creating build/lib.linux-x86_64-cpython-310/apex/contrib/test/transducer\n","  copying apex/contrib/test/transducer/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/transducer\n","  copying apex/contrib/test/transducer/test_transducer_loss.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/transducer\n","  copying apex/contrib/test/transducer/test_transducer_joint.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/transducer\n","  creating build/lib.linux-x86_64-cpython-310/apex/transformer/pipeline_parallel\n","  copying apex/transformer/pipeline_parallel/p2p_communication.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/pipeline_parallel\n","  copying apex/transformer/pipeline_parallel/utils.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/pipeline_parallel\n","  copying apex/transformer/pipeline_parallel/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/pipeline_parallel\n","  copying apex/transformer/pipeline_parallel/_timers.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/pipeline_parallel\n","  creating build/lib.linux-x86_64-cpython-310/apex/transformer/tensor_parallel\n","  copying apex/transformer/tensor_parallel/random.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/tensor_parallel\n","  copying apex/transformer/tensor_parallel/mappings.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/tensor_parallel\n","  copying apex/transformer/tensor_parallel/cross_entropy.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/tensor_parallel\n","  copying apex/transformer/tensor_parallel/utils.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/tensor_parallel\n","  copying apex/transformer/tensor_parallel/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/tensor_parallel\n","  copying apex/transformer/tensor_parallel/data.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/tensor_parallel\n","  copying apex/transformer/tensor_parallel/memory.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/tensor_parallel\n","  copying apex/transformer/tensor_parallel/layers.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/tensor_parallel\n","  creating build/lib.linux-x86_64-cpython-310/apex/transformer/amp\n","  copying apex/transformer/amp/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/amp\n","  copying apex/transformer/amp/grad_scaler.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/amp\n","  creating build/lib.linux-x86_64-cpython-310/apex/transformer/functional\n","  copying apex/transformer/functional/fused_softmax.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/functional\n","  copying apex/transformer/functional/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/functional\n","  creating build/lib.linux-x86_64-cpython-310/apex/transformer/_data\n","  copying apex/transformer/_data/_batchsampler.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/_data\n","  copying apex/transformer/_data/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/_data\n","  creating build/lib.linux-x86_64-cpython-310/apex/transformer/layers\n","  copying apex/transformer/layers/layer_norm.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/layers\n","  copying apex/transformer/layers/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/layers\n","  creating build/lib.linux-x86_64-cpython-310/apex/transformer/testing\n","  copying apex/transformer/testing/standalone_bert.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/testing\n","  copying apex/transformer/testing/arguments.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/testing\n","  copying apex/transformer/testing/standalone_transformer_lm.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/testing\n","  copying apex/transformer/testing/standalone_gpt.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/testing\n","  copying apex/transformer/testing/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/testing\n","  copying apex/transformer/testing/commons.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/testing\n","  copying apex/transformer/testing/global_vars.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/testing\n","  copying apex/transformer/testing/distributed_test_base.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/testing\n","  creating build/lib.linux-x86_64-cpython-310/apex/transformer/pipeline_parallel/schedules\n","  copying apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_without_interleaving.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/pipeline_parallel/schedules\n","  copying apex/transformer/pipeline_parallel/schedules/common.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/pipeline_parallel/schedules\n","  copying apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_with_interleaving.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/pipeline_parallel/schedules\n","  copying apex/transformer/pipeline_parallel/schedules/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/pipeline_parallel/schedules\n","  copying apex/transformer/pipeline_parallel/schedules/fwd_bwd_no_pipelining.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/pipeline_parallel/schedules\n","  running build_ext\n","  /usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:398: UserWarning: There are no x86_64-linux-gnu-g++ version bounds defined for CUDA version 11.8\n","    warnings.warn(f'There are no {compiler_name} version bounds defined for CUDA version {cuda_str_version}')\n","  building 'apex_C' extension\n","  creating build/temp.linux-x86_64-cpython-310\n","  creating build/temp.linux-x86_64-cpython-310/csrc\n","  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/include/python3.10 -c csrc/flatten_unflatten.cpp -o build/temp.linux-x86_64-cpython-310/csrc/flatten_unflatten.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=apex_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n","  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-310/csrc/flatten_unflatten.o -L/usr/local/lib/python3.10/dist-packages/torch/lib -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-cpython-310/apex_C.cpython-310-x86_64-linux-gnu.so\n","  building 'amp_C' extension\n","  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/amp_C_frontend.cpp -o build/temp.linux-x86_64-cpython-310/csrc/amp_C_frontend.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n","  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/multi_tensor_adagrad.cu -o build/temp.linux-x86_64-cpython-310/csrc/multi_tensor_adagrad.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n","            detected during:\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n","  (61): here\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\n","\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n","            detected during:\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n","  (61): here\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\n","\n","  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/multi_tensor_adam.cu -o build/temp.linux-x86_64-cpython-310/csrc/multi_tensor_adam.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n","            detected during:\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n","  (61): here\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\n","\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n","            detected during:\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n","  (61): here\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\n","\n","  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/multi_tensor_axpby_kernel.cu -o build/temp.linux-x86_64-cpython-310/csrc/multi_tensor_axpby_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n","            detected during:\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n","  (61): here\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\n","\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n","            detected during:\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n","  (61): here\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\n","\n","  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/multi_tensor_l2norm_kernel.cu -o build/temp.linux-x86_64-cpython-310/csrc/multi_tensor_l2norm_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n","            detected during:\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n","  (61): here\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\n","\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n","            detected during:\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n","  (61): here\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\n","\n","  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/multi_tensor_l2norm_kernel_mp.cu -o build/temp.linux-x86_64-cpython-310/csrc/multi_tensor_l2norm_kernel_mp.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n","            detected during:\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n","  (61): here\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\n","\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n","            detected during:\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n","  (61): here\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\n","\n","  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/multi_tensor_l2norm_scale_kernel.cu -o build/temp.linux-x86_64-cpython-310/csrc/multi_tensor_l2norm_scale_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n","            detected during:\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n","  (61): here\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\n","\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n","            detected during:\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n","  (61): here\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\n","\n","  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/multi_tensor_lamb.cu -o build/temp.linux-x86_64-cpython-310/csrc/multi_tensor_lamb.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n","            detected during:\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n","  (61): here\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\n","\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n","            detected during:\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n","  (61): here\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\n","\n","  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/multi_tensor_lamb_mp.cu -o build/temp.linux-x86_64-cpython-310/csrc/multi_tensor_lamb_mp.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n","            detected during:\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n","  (61): here\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\n","\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n","            detected during:\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n","  (61): here\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\n","\n","  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/multi_tensor_lamb_stage_1.cu -o build/temp.linux-x86_64-cpython-310/csrc/multi_tensor_lamb_stage_1.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n","            detected during:\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n","  (61): here\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\n","\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n","            detected during:\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n","  (61): here\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\n","\n","  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/multi_tensor_lamb_stage_2.cu -o build/temp.linux-x86_64-cpython-310/csrc/multi_tensor_lamb_stage_2.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n","            detected during:\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n","  (61): here\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\n","\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n","            detected during:\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n","  (61): here\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\n","\n","  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/multi_tensor_novograd.cu -o build/temp.linux-x86_64-cpython-310/csrc/multi_tensor_novograd.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n","            detected during:\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n","  (61): here\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\n","\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n","            detected during:\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n","  (61): here\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\n","\n","  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/multi_tensor_scale_kernel.cu -o build/temp.linux-x86_64-cpython-310/csrc/multi_tensor_scale_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n","            detected during:\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n","  (61): here\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\n","\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n","            detected during:\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n","  (61): here\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\n","\n","  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/multi_tensor_sgd_kernel.cu -o build/temp.linux-x86_64-cpython-310/csrc/multi_tensor_sgd_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n","            detected during:\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n","  (61): here\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\n","\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n","            detected during:\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n","  (61): here\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\n","\n","  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-310/csrc/amp_C_frontend.o build/temp.linux-x86_64-cpython-310/csrc/multi_tensor_adagrad.o build/temp.linux-x86_64-cpython-310/csrc/multi_tensor_adam.o build/temp.linux-x86_64-cpython-310/csrc/multi_tensor_axpby_kernel.o build/temp.linux-x86_64-cpython-310/csrc/multi_tensor_l2norm_kernel.o build/temp.linux-x86_64-cpython-310/csrc/multi_tensor_l2norm_kernel_mp.o build/temp.linux-x86_64-cpython-310/csrc/multi_tensor_l2norm_scale_kernel.o build/temp.linux-x86_64-cpython-310/csrc/multi_tensor_lamb.o build/temp.linux-x86_64-cpython-310/csrc/multi_tensor_lamb_mp.o build/temp.linux-x86_64-cpython-310/csrc/multi_tensor_lamb_stage_1.o build/temp.linux-x86_64-cpython-310/csrc/multi_tensor_lamb_stage_2.o build/temp.linux-x86_64-cpython-310/csrc/multi_tensor_novograd.o build/temp.linux-x86_64-cpython-310/csrc/multi_tensor_scale_kernel.o build/temp.linux-x86_64-cpython-310/csrc/multi_tensor_sgd_kernel.o -L/usr/local/lib/python3.10/dist-packages/torch/lib -L/usr/local/cuda/lib64 -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-310/amp_C.cpython-310-x86_64-linux-gnu.so\n","  building 'syncbn' extension\n","  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/syncbn.cpp -o build/temp.linux-x86_64-cpython-310/csrc/syncbn.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n","  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/welford.cu -o build/temp.linux-x86_64-cpython-310/csrc/welford.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n","            detected during:\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n","  (61): here\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\n","\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n","            detected during:\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n","  (61): here\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\n","\n","  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-310/csrc/syncbn.o build/temp.linux-x86_64-cpython-310/csrc/welford.o -L/usr/local/lib/python3.10/dist-packages/torch/lib -L/usr/local/cuda/lib64 -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-310/syncbn.cpython-310-x86_64-linux-gnu.so\n","  building 'fused_layer_norm_cuda' extension\n","  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/layer_norm_cuda.cpp -o build/temp.linux-x86_64-cpython-310/csrc/layer_norm_cuda.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n","  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/layer_norm_cuda_kernel.cu -o build/temp.linux-x86_64-cpython-310/csrc/layer_norm_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -maxrregcount=50 -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n","            detected during:\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n","  (61): here\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\n","\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n","            detected during:\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n","  (61): here\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\n","\n","  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-310/csrc/layer_norm_cuda.o build/temp.linux-x86_64-cpython-310/csrc/layer_norm_cuda_kernel.o -L/usr/local/lib/python3.10/dist-packages/torch/lib -L/usr/local/cuda/lib64 -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-310/fused_layer_norm_cuda.cpython-310-x86_64-linux-gnu.so\n","  building 'mlp_cuda' extension\n","  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/mlp.cpp -o build/temp.linux-x86_64-cpython-310/csrc/mlp.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n","  csrc/mlp.cpp: In function ‘std::vector<at::Tensor> mlp_forward(int, int, std::vector<at::Tensor>)’:\n","  csrc/mlp.cpp:57:21: warning: comparison of integer expressions of different signedness: ‘int’ and ‘long unsigned int’ [-Wsign-compare]\n","     57 |   for (int i = 0; i < num_layers; i++) {\n","        |                   ~~^~~~~~~~~~~~\n","  csrc/mlp.cpp:64:77: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     64 |   auto out = at::empty({batch_size, output_features.back()}, inputs[0].type());\n","        |                                                                             ^\n","  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n","                   from csrc/mlp.cpp:1:\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here\n","    222 |   DeprecatedTypeProperties & type() const {\n","        |                              ^~~~\n","  csrc/mlp.cpp:65:86: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     65 |   auto reserved_space = at::empty({static_cast<long>(reserved_size)}, inputs[0].type());\n","        |                                                                                      ^\n","  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n","                   from csrc/mlp.cpp:1:\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here\n","    222 |   DeprecatedTypeProperties & type() const {\n","        |                              ^~~~\n","  csrc/mlp.cpp:67:59: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     67 |   auto lt_workspace = at::empty({1 << 22}, inputs[0].type());\n","        |                                                           ^\n","  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n","                   from csrc/mlp.cpp:1:\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here\n","    222 |   DeprecatedTypeProperties & type() const {\n","        |                              ^~~~\n","  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/ATen.h:11,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n","                   from csrc/mlp.cpp:1:\n","  csrc/mlp.cpp: In lambda function:\n","  csrc/mlp.cpp:69:54: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     69 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n","        |                                                      ^\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:228:28: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    228 |     const auto& the_type = TYPE;                                            \\\n","        |                            ^~~~\n","  csrc/mlp.cpp:69:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","     69 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n","                   from csrc/mlp.cpp:1:\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here\n","    222 |   DeprecatedTypeProperties & type() const {\n","        |                              ^~~~\n","  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/ATen.h:11,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n","                   from csrc/mlp.cpp:1:\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:231:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n","    231 |     at::ScalarType _st = ::detail::scalar_type(the_type);                   \\\n","        |                                                        ^\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:258:3: note: in expansion of macro ‘AT_DISPATCH_SWITCH’\n","    258 |   AT_DISPATCH_SWITCH(                                        \\\n","        |   ^~~~~~~~~~~~~~~~~~\n","  csrc/mlp.cpp:69:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","     69 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:122:23: note: declared here\n","    122 | inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n","        |                       ^~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:231:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n","    231 |     at::ScalarType _st = ::detail::scalar_type(the_type);                   \\\n","        |                                                        ^\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:258:3: note: in expansion of macro ‘AT_DISPATCH_SWITCH’\n","    258 |   AT_DISPATCH_SWITCH(                                        \\\n","        |   ^~~~~~~~~~~~~~~~~~\n","  csrc/mlp.cpp:69:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","     69 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:122:23: note: declared here\n","    122 | inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n","        |                       ^~~~~~~~~~~\n","  csrc/mlp.cpp: In lambda function:\n","  csrc/mlp.cpp:72:23: warning: comparison of integer expressions of different signedness: ‘int’ and ‘long unsigned int’ [-Wsign-compare]\n","     72 |     for (int i = 0; i < num_layers; i++) {\n","        |                     ~~^~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    234 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:253:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    253 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:259:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n","    259 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n","        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/mlp.cpp:69:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","     69 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/mlp.cpp:78:10: warning: unused variable ‘result’ [-Wunused-variable]\n","     78 |     auto result = mlp_fp<scalar_t>(\n","        |          ^~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    234 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:253:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    253 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:259:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n","    259 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n","        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/mlp.cpp:69:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","     69 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/mlp.cpp: In lambda function:\n","  csrc/mlp.cpp:72:23: warning: comparison of integer expressions of different signedness: ‘int’ and ‘long unsigned int’ [-Wsign-compare]\n","     72 |     for (int i = 0; i < num_layers; i++) {\n","        |                     ~~^~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    234 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:254:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    254 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)  \\\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:259:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n","    259 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n","        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/mlp.cpp:69:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","     69 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/mlp.cpp:78:10: warning: unused variable ‘result’ [-Wunused-variable]\n","     78 |     auto result = mlp_fp<scalar_t>(\n","        |          ^~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    234 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:254:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    254 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)  \\\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:259:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n","    259 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n","        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/mlp.cpp:69:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","     69 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/mlp.cpp: In lambda function:\n","  csrc/mlp.cpp:72:23: warning: comparison of integer expressions of different signedness: ‘int’ and ‘long unsigned int’ [-Wsign-compare]\n","     72 |     for (int i = 0; i < num_layers; i++) {\n","        |                     ~~^~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    234 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:255:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    255 |   AT_DISPATCH_CASE(at::ScalarType::Half, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:259:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n","    259 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n","        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/mlp.cpp:69:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","     69 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/mlp.cpp:78:10: warning: unused variable ‘result’ [-Wunused-variable]\n","     78 |     auto result = mlp_fp<scalar_t>(\n","        |          ^~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    234 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:255:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    255 |   AT_DISPATCH_CASE(at::ScalarType::Half, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:259:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n","    259 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n","        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/mlp.cpp:69:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","     69 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/mlp.cpp: In function ‘std::vector<at::Tensor> mlp_backward(int, int, at::Tensor, std::vector<at::Tensor>, std::vector<at::Tensor>)’:\n","  csrc/mlp.cpp:115:21: warning: comparison of integer expressions of different signedness: ‘int’ and ‘long unsigned int’ [-Wsign-compare]\n","    115 |   for (int i = 0; i < num_layers; i++) {\n","        |                   ~~^~~~~~~~~~~~\n","  csrc/mlp.cpp:120:21: warning: comparison of integer expressions of different signedness: ‘int’ and ‘std::vector<at::Tensor>::size_type’ {aka ‘long unsigned int’} [-Wsign-compare]\n","    120 |   for (int i = 0; i < inputs.size(); i++) {\n","        |                   ~~^~~~~~~~~~~~~~~\n","  csrc/mlp.cpp:121:67: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","    121 |     outputs.push_back(at::empty(inputs[i].sizes(), inputs[i].type()));  // clone for testing now\n","        |                                                                   ^\n","  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n","                   from csrc/mlp.cpp:1:\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here\n","    222 |   DeprecatedTypeProperties & type() const {\n","        |                              ^~~~\n","  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/ATen.h:11,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n","                   from csrc/mlp.cpp:1:\n","  csrc/mlp.cpp: In lambda function:\n","  csrc/mlp.cpp:124:54: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","        |                                                      ^\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:228:28: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    228 |     const auto& the_type = TYPE;                                            \\\n","        |                            ^~~~\n","  csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n","                   from csrc/mlp.cpp:1:\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here\n","    222 |   DeprecatedTypeProperties & type() const {\n","        |                              ^~~~\n","  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/ATen.h:11,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n","                   from csrc/mlp.cpp:1:\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:231:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n","    231 |     at::ScalarType _st = ::detail::scalar_type(the_type);                   \\\n","        |                                                        ^\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:258:3: note: in expansion of macro ‘AT_DISPATCH_SWITCH’\n","    258 |   AT_DISPATCH_SWITCH(                                        \\\n","        |   ^~~~~~~~~~~~~~~~~~\n","  csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:122:23: note: declared here\n","    122 | inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n","        |                       ^~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:231:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n","    231 |     at::ScalarType _st = ::detail::scalar_type(the_type);                   \\\n","        |                                                        ^\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:258:3: note: in expansion of macro ‘AT_DISPATCH_SWITCH’\n","    258 |   AT_DISPATCH_SWITCH(                                        \\\n","        |   ^~~~~~~~~~~~~~~~~~\n","  csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:122:23: note: declared here\n","    122 | inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n","        |                       ^~~~~~~~~~~\n","  csrc/mlp.cpp: In lambda function:\n","  csrc/mlp.cpp:126:23: warning: comparison of integer expressions of different signedness: ‘int’ and ‘long unsigned int’ [-Wsign-compare]\n","    126 |     for (int i = 0; i < num_layers; i++) {\n","        |                     ~~^~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    234 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:253:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    253 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:259:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n","    259 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n","        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/mlp.cpp:130:23: warning: comparison of integer expressions of different signedness: ‘int’ and ‘std::vector<at::Tensor>::size_type’ {aka ‘long unsigned int’} [-Wsign-compare]\n","    130 |     for (int i = 0; i < inputs.size(); i++) {\n","        |                     ~~^~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    234 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:253:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    253 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:259:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n","    259 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n","        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/mlp.cpp:138:99: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","    138 |     auto work_space = at::empty({static_cast<long>(work_size / sizeof(scalar_t))}, inputs[0].type());\n","        |                                                                                                   ^\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    234 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:253:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    253 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:259:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n","    259 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n","        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n","                   from csrc/mlp.cpp:1:\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here\n","    222 |   DeprecatedTypeProperties & type() const {\n","        |                              ^~~~\n","  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/ATen.h:11,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n","                   from csrc/mlp.cpp:1:\n","  csrc/mlp.cpp:140:10: warning: unused variable ‘result’ [-Wunused-variable]\n","    140 |     auto result = mlp_bp<scalar_t>(\n","        |          ^~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    234 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:253:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    253 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:259:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n","    259 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n","        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/mlp.cpp: In lambda function:\n","  csrc/mlp.cpp:126:23: warning: comparison of integer expressions of different signedness: ‘int’ and ‘long unsigned int’ [-Wsign-compare]\n","    126 |     for (int i = 0; i < num_layers; i++) {\n","        |                     ~~^~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    234 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:254:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    254 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)  \\\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:259:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n","    259 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n","        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/mlp.cpp:130:23: warning: comparison of integer expressions of different signedness: ‘int’ and ‘std::vector<at::Tensor>::size_type’ {aka ‘long unsigned int’} [-Wsign-compare]\n","    130 |     for (int i = 0; i < inputs.size(); i++) {\n","        |                     ~~^~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    234 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:254:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    254 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)  \\\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:259:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n","    259 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n","        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/mlp.cpp:138:99: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","    138 |     auto work_space = at::empty({static_cast<long>(work_size / sizeof(scalar_t))}, inputs[0].type());\n","        |                                                                                                   ^\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    234 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:254:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    254 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)  \\\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:259:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n","    259 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n","        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n","                   from csrc/mlp.cpp:1:\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here\n","    222 |   DeprecatedTypeProperties & type() const {\n","        |                              ^~~~\n","  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/ATen.h:11,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n","                   from csrc/mlp.cpp:1:\n","  csrc/mlp.cpp:140:10: warning: unused variable ‘result’ [-Wunused-variable]\n","    140 |     auto result = mlp_bp<scalar_t>(\n","        |          ^~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    234 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:254:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    254 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)  \\\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:259:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n","    259 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n","        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/mlp.cpp: In lambda function:\n","  csrc/mlp.cpp:126:23: warning: comparison of integer expressions of different signedness: ‘int’ and ‘long unsigned int’ [-Wsign-compare]\n","    126 |     for (int i = 0; i < num_layers; i++) {\n","        |                     ~~^~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    234 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:255:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    255 |   AT_DISPATCH_CASE(at::ScalarType::Half, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:259:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n","    259 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n","        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/mlp.cpp:130:23: warning: comparison of integer expressions of different signedness: ‘int’ and ‘std::vector<at::Tensor>::size_type’ {aka ‘long unsigned int’} [-Wsign-compare]\n","    130 |     for (int i = 0; i < inputs.size(); i++) {\n","        |                     ~~^~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    234 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:255:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    255 |   AT_DISPATCH_CASE(at::ScalarType::Half, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:259:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n","    259 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n","        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/mlp.cpp:138:99: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","    138 |     auto work_space = at::empty({static_cast<long>(work_size / sizeof(scalar_t))}, inputs[0].type());\n","        |                                                                                                   ^\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    234 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:255:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    255 |   AT_DISPATCH_CASE(at::ScalarType::Half, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:259:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n","    259 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n","        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n","                   from csrc/mlp.cpp:1:\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here\n","    222 |   DeprecatedTypeProperties & type() const {\n","        |                              ^~~~\n","  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/ATen.h:11,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n","                   from csrc/mlp.cpp:1:\n","  csrc/mlp.cpp:140:10: warning: unused variable ‘result’ [-Wunused-variable]\n","    140 |     auto result = mlp_bp<scalar_t>(\n","        |          ^~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    234 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:255:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    255 |   AT_DISPATCH_CASE(at::ScalarType::Half, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:259:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n","    259 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n","        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/mlp_cuda.cu -o build/temp.linux-x86_64-cpython-310/csrc/mlp_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n","            detected during:\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n","  (61): here\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\n","\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n","            detected during:\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n","  (61): here\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\n","\n","  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-310/csrc/mlp.o build/temp.linux-x86_64-cpython-310/csrc/mlp_cuda.o -L/usr/local/lib/python3.10/dist-packages/torch/lib -L/usr/local/cuda/lib64 -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-310/mlp_cuda.cpython-310-x86_64-linux-gnu.so\n","  building 'fused_dense_cuda' extension\n","  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/fused_dense.cpp -o build/temp.linux-x86_64-cpython-310/csrc/fused_dense.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=fused_dense_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n","  csrc/fused_dense.cpp: In function ‘at::Tensor linear_bias_forward(at::Tensor, at::Tensor, at::Tensor)’:\n","  csrc/fused_dense.cpp:30:63: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     30 |   auto out = at::empty({batch_size, out_features}, input.type());\n","        |                                                               ^\n","  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n","                   from csrc/fused_dense.cpp:1:\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here\n","    222 |   DeprecatedTypeProperties & type() const {\n","        |                              ^~~~\n","  csrc/fused_dense.cpp:33:55: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     33 |   auto lt_workspace = at::empty({1 << 22}, input.type());\n","        |                                                       ^\n","  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n","                   from csrc/fused_dense.cpp:1:\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here\n","    222 |   DeprecatedTypeProperties & type() const {\n","        |                              ^~~~\n","  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/ATen.h:11,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n","                   from csrc/fused_dense.cpp:1:\n","  csrc/fused_dense.cpp: In lambda function:\n","  csrc/fused_dense.cpp:35:94: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     35 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.type(), \"linear_bias_forward\", [&] {\n","        |                                                                                              ^\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:228:28: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    228 |     const auto& the_type = TYPE;                                            \\\n","        |                            ^~~~\n","  csrc/fused_dense.cpp:35:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n","     35 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.type(), \"linear_bias_forward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n","                   from csrc/fused_dense.cpp:1:\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here\n","    222 |   DeprecatedTypeProperties & type() const {\n","        |                              ^~~~\n","  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/ATen.h:11,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n","                   from csrc/fused_dense.cpp:1:\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:231:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n","    231 |     at::ScalarType _st = ::detail::scalar_type(the_type);                   \\\n","        |                                                        ^\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:278:3: note: in expansion of macro ‘AT_DISPATCH_SWITCH’\n","    278 |   AT_DISPATCH_SWITCH(                          \\\n","        |   ^~~~~~~~~~~~~~~~~~\n","  csrc/fused_dense.cpp:35:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n","     35 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.type(), \"linear_bias_forward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:122:23: note: declared here\n","    122 | inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n","        |                       ^~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:231:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n","    231 |     at::ScalarType _st = ::detail::scalar_type(the_type);                   \\\n","        |                                                        ^\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:278:3: note: in expansion of macro ‘AT_DISPATCH_SWITCH’\n","    278 |   AT_DISPATCH_SWITCH(                          \\\n","        |   ^~~~~~~~~~~~~~~~~~\n","  csrc/fused_dense.cpp:35:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n","     35 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.type(), \"linear_bias_forward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:122:23: note: declared here\n","    122 | inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n","        |                       ^~~~~~~~~~~\n","  csrc/fused_dense.cpp: In lambda function:\n","  csrc/fused_dense.cpp:37:15: warning: unused variable ‘b_ptr’ [-Wunused-variable]\n","     37 |     scalar_t* b_ptr = bias.data_ptr<scalar_t>();\n","        |               ^~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    234 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:246:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    246 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:272:3: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES’\n","    272 |   AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \\\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n","    281 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n","        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/fused_dense.cpp:35:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n","     35 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.type(), \"linear_bias_forward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/fused_dense.cpp:38:10: warning: unused variable ‘result’ [-Wunused-variable]\n","     38 |     auto result = linear_bias_forward_cuda<scalar_t>(\n","        |          ^~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    234 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:246:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    246 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:272:3: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES’\n","    272 |   AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \\\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n","    281 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n","        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/fused_dense.cpp:35:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n","     35 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.type(), \"linear_bias_forward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/fused_dense.cpp: In lambda function:\n","  csrc/fused_dense.cpp:37:15: warning: unused variable ‘b_ptr’ [-Wunused-variable]\n","     37 |     scalar_t* b_ptr = bias.data_ptr<scalar_t>();\n","        |               ^~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    234 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:247:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    247 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:272:3: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES’\n","    272 |   AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \\\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n","    281 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n","        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/fused_dense.cpp:35:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n","     35 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.type(), \"linear_bias_forward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/fused_dense.cpp:38:10: warning: unused variable ‘result’ [-Wunused-variable]\n","     38 |     auto result = linear_bias_forward_cuda<scalar_t>(\n","        |          ^~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    234 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:247:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    247 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:272:3: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES’\n","    272 |   AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \\\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n","    281 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n","        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/fused_dense.cpp:35:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n","     35 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.type(), \"linear_bias_forward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/fused_dense.cpp: In lambda function:\n","  csrc/fused_dense.cpp:37:15: warning: unused variable ‘b_ptr’ [-Wunused-variable]\n","     37 |     scalar_t* b_ptr = bias.data_ptr<scalar_t>();\n","        |               ^~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    234 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:273:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    273 |   AT_DISPATCH_CASE(SCALARTYPE1, __VA_ARGS__)                                \\\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n","    281 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n","        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/fused_dense.cpp:35:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n","     35 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.type(), \"linear_bias_forward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/fused_dense.cpp:38:10: warning: unused variable ‘result’ [-Wunused-variable]\n","     38 |     auto result = linear_bias_forward_cuda<scalar_t>(\n","        |          ^~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    234 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:273:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    273 |   AT_DISPATCH_CASE(SCALARTYPE1, __VA_ARGS__)                                \\\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n","    281 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n","        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/fused_dense.cpp:35:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n","     35 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.type(), \"linear_bias_forward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/fused_dense.cpp: In lambda function:\n","  csrc/fused_dense.cpp:37:15: warning: unused variable ‘b_ptr’ [-Wunused-variable]\n","     37 |     scalar_t* b_ptr = bias.data_ptr<scalar_t>();\n","        |               ^~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    234 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:274:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    274 |   AT_DISPATCH_CASE(SCALARTYPE2, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n","    281 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n","        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/fused_dense.cpp:35:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n","     35 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.type(), \"linear_bias_forward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/fused_dense.cpp:38:10: warning: unused variable ‘result’ [-Wunused-variable]\n","     38 |     auto result = linear_bias_forward_cuda<scalar_t>(\n","        |          ^~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    234 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:274:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    274 |   AT_DISPATCH_CASE(SCALARTYPE2, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n","    281 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n","        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/fused_dense.cpp:35:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n","     35 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.type(), \"linear_bias_forward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/fused_dense.cpp: In function ‘std::vector<at::Tensor> linear_bias_backward(at::Tensor, at::Tensor, at::Tensor)’:\n","  csrc/fused_dense.cpp:64:69: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     64 |   auto d_weight = at::empty({out_features, in_features}, input.type());\n","        |                                                                     ^\n","  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n","                   from csrc/fused_dense.cpp:1:\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here\n","    222 |   DeprecatedTypeProperties & type() const {\n","        |                              ^~~~\n","  csrc/fused_dense.cpp:68:54: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     68 |   auto d_bias = at::empty({out_features}, input.type());\n","        |                                                      ^\n","  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n","                   from csrc/fused_dense.cpp:1:\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here\n","    222 |   DeprecatedTypeProperties & type() const {\n","        |                              ^~~~\n","  csrc/fused_dense.cpp:70:66: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     70 |   auto d_input = at::empty({batch_size, in_features}, input.type());\n","        |                                                                  ^\n","  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n","                   from csrc/fused_dense.cpp:1:\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here\n","    222 |   DeprecatedTypeProperties & type() const {\n","        |                              ^~~~\n","  csrc/fused_dense.cpp:73:55: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     73 |   auto lt_workspace = at::empty({1 << 22}, input.type());\n","        |                                                       ^\n","  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n","                   from csrc/fused_dense.cpp:1:\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here\n","    222 |   DeprecatedTypeProperties & type() const {\n","        |                              ^~~~\n","  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/ATen.h:11,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n","                   from csrc/fused_dense.cpp:1:\n","  csrc/fused_dense.cpp: In lambda function:\n","  csrc/fused_dense.cpp:75:94: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     75 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.type(), \"linear_bias_backward\", [&] {\n","        |                                                                                              ^\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:228:28: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    228 |     const auto& the_type = TYPE;                                            \\\n","        |                            ^~~~\n","  csrc/fused_dense.cpp:75:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n","     75 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.type(), \"linear_bias_backward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n","                   from csrc/fused_dense.cpp:1:\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here\n","    222 |   DeprecatedTypeProperties & type() const {\n","        |                              ^~~~\n","  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/ATen.h:11,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n","                   from csrc/fused_dense.cpp:1:\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:231:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n","    231 |     at::ScalarType _st = ::detail::scalar_type(the_type);                   \\\n","        |                                                        ^\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:278:3: note: in expansion of macro ‘AT_DISPATCH_SWITCH’\n","    278 |   AT_DISPATCH_SWITCH(                          \\\n","        |   ^~~~~~~~~~~~~~~~~~\n","  csrc/fused_dense.cpp:75:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n","     75 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.type(), \"linear_bias_backward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:122:23: note: declared here\n","    122 | inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n","        |                       ^~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:231:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n","    231 |     at::ScalarType _st = ::detail::scalar_type(the_type);                   \\\n","        |                                                        ^\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:278:3: note: in expansion of macro ‘AT_DISPATCH_SWITCH’\n","    278 |   AT_DISPATCH_SWITCH(                          \\\n","        |   ^~~~~~~~~~~~~~~~~~\n","  csrc/fused_dense.cpp:75:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n","     75 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.type(), \"linear_bias_backward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:122:23: note: declared here\n","    122 | inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n","        |                       ^~~~~~~~~~~\n","  csrc/fused_dense.cpp: In lambda function:\n","  csrc/fused_dense.cpp:77:15: warning: unused variable ‘d_b_ptr’ [-Wunused-variable]\n","     77 |     scalar_t* d_b_ptr = d_bias.data_ptr<scalar_t>();\n","        |               ^~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    234 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:246:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    246 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:272:3: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES’\n","    272 |   AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \\\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n","    281 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n","        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/fused_dense.cpp:75:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n","     75 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.type(), \"linear_bias_backward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/fused_dense.cpp:78:10: warning: unused variable ‘result’ [-Wunused-variable]\n","     78 |     auto result = linear_bias_backward_cuda<scalar_t>(\n","        |          ^~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    234 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:246:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    246 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:272:3: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES’\n","    272 |   AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \\\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n","    281 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n","        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/fused_dense.cpp:75:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n","     75 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.type(), \"linear_bias_backward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/fused_dense.cpp: In lambda function:\n","  csrc/fused_dense.cpp:77:15: warning: unused variable ‘d_b_ptr’ [-Wunused-variable]\n","     77 |     scalar_t* d_b_ptr = d_bias.data_ptr<scalar_t>();\n","        |               ^~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    234 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:247:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    247 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:272:3: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES’\n","    272 |   AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \\\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n","    281 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n","        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/fused_dense.cpp:75:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n","     75 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.type(), \"linear_bias_backward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/fused_dense.cpp:78:10: warning: unused variable ‘result’ [-Wunused-variable]\n","     78 |     auto result = linear_bias_backward_cuda<scalar_t>(\n","        |          ^~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    234 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:247:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    247 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:272:3: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES’\n","    272 |   AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \\\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n","    281 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n","        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/fused_dense.cpp:75:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n","     75 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.type(), \"linear_bias_backward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/fused_dense.cpp: In lambda function:\n","  csrc/fused_dense.cpp:77:15: warning: unused variable ‘d_b_ptr’ [-Wunused-variable]\n","     77 |     scalar_t* d_b_ptr = d_bias.data_ptr<scalar_t>();\n","        |               ^~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    234 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:273:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    273 |   AT_DISPATCH_CASE(SCALARTYPE1, __VA_ARGS__)                                \\\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n","    281 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n","        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/fused_dense.cpp:75:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n","     75 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.type(), \"linear_bias_backward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/fused_dense.cpp:78:10: warning: unused variable ‘result’ [-Wunused-variable]\n","     78 |     auto result = linear_bias_backward_cuda<scalar_t>(\n","        |          ^~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    234 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:273:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    273 |   AT_DISPATCH_CASE(SCALARTYPE1, __VA_ARGS__)                                \\\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n","    281 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n","        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/fused_dense.cpp:75:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n","     75 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.type(), \"linear_bias_backward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/fused_dense.cpp: In lambda function:\n","  csrc/fused_dense.cpp:77:15: warning: unused variable ‘d_b_ptr’ [-Wunused-variable]\n","     77 |     scalar_t* d_b_ptr = d_bias.data_ptr<scalar_t>();\n","        |               ^~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    234 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:274:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    274 |   AT_DISPATCH_CASE(SCALARTYPE2, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n","    281 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n","        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/fused_dense.cpp:75:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n","     75 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.type(), \"linear_bias_backward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/fused_dense.cpp:78:10: warning: unused variable ‘result’ [-Wunused-variable]\n","     78 |     auto result = linear_bias_backward_cuda<scalar_t>(\n","        |          ^~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    234 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:274:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    274 |   AT_DISPATCH_CASE(SCALARTYPE2, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n","    281 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n","        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/fused_dense.cpp:75:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n","     75 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.type(), \"linear_bias_backward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/fused_dense.cpp: In function ‘std::vector<at::Tensor> linear_gelu_linear_forward(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor)’:\n","  csrc/fused_dense.cpp:106:70: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","    106 |   auto output1 = at::empty({batch_size, hidden_features}, input.type());\n","        |                                                                      ^\n","  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n","                   from csrc/fused_dense.cpp:1:\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here\n","    222 |   DeprecatedTypeProperties & type() const {\n","        |                              ^~~~\n","  csrc/fused_dense.cpp:107:70: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","    107 |   auto gelu_in = at::empty({batch_size, hidden_features}, input.type());\n","        |                                                                      ^\n","  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n","                   from csrc/fused_dense.cpp:1:\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here\n","    222 |   DeprecatedTypeProperties & type() const {\n","        |                              ^~~~\n","  csrc/fused_dense.cpp:108:67: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","    108 |   auto output2 = at::empty({batch_size, out_features}, input.type());\n","        |                                                                   ^\n","  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n","                   from csrc/fused_dense.cpp:1:\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here\n","    222 |   DeprecatedTypeProperties & type() const {\n","        |                              ^~~~\n","  csrc/fused_dense.cpp:111:55: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","    111 |   auto lt_workspace = at::empty({1 << 22}, input.type());\n","        |                                                       ^\n","  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n","                   from csrc/fused_dense.cpp:1:\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here\n","    222 |   DeprecatedTypeProperties & type() const {\n","        |                              ^~~~\n","  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/ATen.h:11,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n","                   from csrc/fused_dense.cpp:1:\n","  csrc/fused_dense.cpp: In lambda function:\n","  csrc/fused_dense.cpp:113:94: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","    113 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.type(), \"linear_gelu_linear_forward\", [&] {\n","        |                                                                                              ^\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:228:28: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    228 |     const auto& the_type = TYPE;                                            \\\n","        |                            ^~~~\n","  csrc/fused_dense.cpp:113:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n","    113 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.type(), \"linear_gelu_linear_forward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n","                   from csrc/fused_dense.cpp:1:\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here\n","    222 |   DeprecatedTypeProperties & type() const {\n","        |                              ^~~~\n","  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/ATen.h:11,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n","                   from csrc/fused_dense.cpp:1:\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:231:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n","    231 |     at::ScalarType _st = ::detail::scalar_type(the_type);                   \\\n","        |                                                        ^\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:278:3: note: in expansion of macro ‘AT_DISPATCH_SWITCH’\n","    278 |   AT_DISPATCH_SWITCH(                          \\\n","        |   ^~~~~~~~~~~~~~~~~~\n","  csrc/fused_dense.cpp:113:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n","    113 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.type(), \"linear_gelu_linear_forward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:122:23: note: declared here\n","    122 | inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n","        |                       ^~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:231:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n","    231 |     at::ScalarType _st = ::detail::scalar_type(the_type);                   \\\n","        |                                                        ^\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:278:3: note: in expansion of macro ‘AT_DISPATCH_SWITCH’\n","    278 |   AT_DISPATCH_SWITCH(                          \\\n","        |   ^~~~~~~~~~~~~~~~~~\n","  csrc/fused_dense.cpp:113:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n","    113 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.type(), \"linear_gelu_linear_forward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:122:23: note: declared here\n","    122 | inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n","        |                       ^~~~~~~~~~~\n","  csrc/fused_dense.cpp: In lambda function:\n","  csrc/fused_dense.cpp:118:10: warning: unused variable ‘result’ [-Wunused-variable]\n","    118 |     auto result = linear_gelu_linear_forward_cuda<scalar_t>(\n","        |          ^~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    234 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:246:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    246 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:272:3: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES’\n","    272 |   AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \\\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n","    281 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n","        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/fused_dense.cpp:113:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n","    113 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.type(), \"linear_gelu_linear_forward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/fused_dense.cpp: In lambda function:\n","  csrc/fused_dense.cpp:118:10: warning: unused variable ‘result’ [-Wunused-variable]\n","    118 |     auto result = linear_gelu_linear_forward_cuda<scalar_t>(\n","        |          ^~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    234 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:247:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    247 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:272:3: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES’\n","    272 |   AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \\\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n","    281 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n","        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/fused_dense.cpp:113:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n","    113 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.type(), \"linear_gelu_linear_forward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/fused_dense.cpp: In lambda function:\n","  csrc/fused_dense.cpp:118:10: warning: unused variable ‘result’ [-Wunused-variable]\n","    118 |     auto result = linear_gelu_linear_forward_cuda<scalar_t>(\n","        |          ^~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    234 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:273:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    273 |   AT_DISPATCH_CASE(SCALARTYPE1, __VA_ARGS__)                                \\\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n","    281 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n","        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/fused_dense.cpp:113:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n","    113 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.type(), \"linear_gelu_linear_forward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/fused_dense.cpp: In lambda function:\n","  csrc/fused_dense.cpp:118:10: warning: unused variable ‘result’ [-Wunused-variable]\n","    118 |     auto result = linear_gelu_linear_forward_cuda<scalar_t>(\n","        |          ^~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    234 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:274:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    274 |   AT_DISPATCH_CASE(SCALARTYPE2, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n","    281 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n","        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/fused_dense.cpp:113:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n","    113 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.type(), \"linear_gelu_linear_forward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/fused_dense.cpp: In function ‘std::vector<at::Tensor> linear_gelu_linear_backward(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor)’:\n","  csrc/fused_dense.cpp:149:73: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","    149 |   auto d_weight1 = at::empty({hidden_features, in_features}, input.type());\n","        |                                                                         ^\n","  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n","                   from csrc/fused_dense.cpp:1:\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here\n","    222 |   DeprecatedTypeProperties & type() const {\n","        |                              ^~~~\n","  csrc/fused_dense.cpp:150:74: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","    150 |   auto d_weight2 = at::empty({out_features, hidden_features}, input.type());\n","        |                                                                          ^\n","  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n","                   from csrc/fused_dense.cpp:1:\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here\n","    222 |   DeprecatedTypeProperties & type() const {\n","        |                              ^~~~\n","  csrc/fused_dense.cpp:151:58: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","    151 |   auto d_bias1 = at::empty({hidden_features}, input.type());\n","        |                                                          ^\n","  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n","                   from csrc/fused_dense.cpp:1:\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here\n","    222 |   DeprecatedTypeProperties & type() const {\n","        |                              ^~~~\n","  csrc/fused_dense.cpp:152:55: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","    152 |   auto d_bias2 = at::empty({out_features}, input.type());\n","        |                                                       ^\n","  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n","                   from csrc/fused_dense.cpp:1:\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here\n","    222 |   DeprecatedTypeProperties & type() const {\n","        |                              ^~~~\n","  csrc/fused_dense.cpp:153:66: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","    153 |   auto d_input = at::empty({batch_size, in_features}, input.type());\n","        |                                                                  ^\n","  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n","                   from csrc/fused_dense.cpp:1:\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here\n","    222 |   DeprecatedTypeProperties & type() const {\n","        |                              ^~~~\n","  csrc/fused_dense.cpp:154:72: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","    154 |   auto d_output1 = at::empty({batch_size, hidden_features}, input.type());\n","        |                                                                        ^\n","  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n","                   from csrc/fused_dense.cpp:1:\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here\n","    222 |   DeprecatedTypeProperties & type() const {\n","        |                              ^~~~\n","  csrc/fused_dense.cpp:157:55: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","    157 |   auto lt_workspace = at::empty({1 << 22}, input.type());\n","        |                                                       ^\n","  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n","                   from csrc/fused_dense.cpp:1:\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here\n","    222 |   DeprecatedTypeProperties & type() const {\n","        |                              ^~~~\n","  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/ATen.h:11,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n","                   from csrc/fused_dense.cpp:1:\n","  csrc/fused_dense.cpp: In lambda function:\n","  csrc/fused_dense.cpp:159:94: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","    159 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.type(), \"linear_bias_backward\", [&] {\n","        |                                                                                              ^\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:228:28: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    228 |     const auto& the_type = TYPE;                                            \\\n","        |                            ^~~~\n","  csrc/fused_dense.cpp:159:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n","    159 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.type(), \"linear_bias_backward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n","                   from csrc/fused_dense.cpp:1:\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here\n","    222 |   DeprecatedTypeProperties & type() const {\n","        |                              ^~~~\n","  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/ATen.h:11,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n","                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n","                   from csrc/fused_dense.cpp:1:\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:231:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n","    231 |     at::ScalarType _st = ::detail::scalar_type(the_type);                   \\\n","        |                                                        ^\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:278:3: note: in expansion of macro ‘AT_DISPATCH_SWITCH’\n","    278 |   AT_DISPATCH_SWITCH(                          \\\n","        |   ^~~~~~~~~~~~~~~~~~\n","  csrc/fused_dense.cpp:159:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n","    159 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.type(), \"linear_bias_backward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:122:23: note: declared here\n","    122 | inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n","        |                       ^~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:231:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n","    231 |     at::ScalarType _st = ::detail::scalar_type(the_type);                   \\\n","        |                                                        ^\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:278:3: note: in expansion of macro ‘AT_DISPATCH_SWITCH’\n","    278 |   AT_DISPATCH_SWITCH(                          \\\n","        |   ^~~~~~~~~~~~~~~~~~\n","  csrc/fused_dense.cpp:159:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n","    159 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.type(), \"linear_bias_backward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:122:23: note: declared here\n","    122 | inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n","        |                       ^~~~~~~~~~~\n","  csrc/fused_dense.cpp: In lambda function:\n","  csrc/fused_dense.cpp:163:10: warning: unused variable ‘result’ [-Wunused-variable]\n","    163 |     auto result = linear_gelu_linear_backward_cuda<scalar_t>(\n","        |          ^~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    234 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:246:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    246 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:272:3: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES’\n","    272 |   AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \\\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n","    281 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n","        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/fused_dense.cpp:159:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n","    159 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.type(), \"linear_bias_backward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/fused_dense.cpp: In lambda function:\n","  csrc/fused_dense.cpp:163:10: warning: unused variable ‘result’ [-Wunused-variable]\n","    163 |     auto result = linear_gelu_linear_backward_cuda<scalar_t>(\n","        |          ^~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    234 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:247:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    247 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:272:3: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES’\n","    272 |   AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \\\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n","    281 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n","        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/fused_dense.cpp:159:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n","    159 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.type(), \"linear_bias_backward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/fused_dense.cpp: In lambda function:\n","  csrc/fused_dense.cpp:163:10: warning: unused variable ‘result’ [-Wunused-variable]\n","    163 |     auto result = linear_gelu_linear_backward_cuda<scalar_t>(\n","        |          ^~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    234 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:273:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    273 |   AT_DISPATCH_CASE(SCALARTYPE1, __VA_ARGS__)                                \\\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n","    281 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n","        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/fused_dense.cpp:159:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n","    159 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.type(), \"linear_bias_backward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/fused_dense.cpp: In lambda function:\n","  csrc/fused_dense.cpp:163:10: warning: unused variable ‘result’ [-Wunused-variable]\n","    163 |     auto result = linear_gelu_linear_backward_cuda<scalar_t>(\n","        |          ^~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    234 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:274:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    274 |   AT_DISPATCH_CASE(SCALARTYPE2, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n","    281 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n","        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  csrc/fused_dense.cpp:159:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n","    159 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.type(), \"linear_bias_backward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/fused_dense_cuda.cu -o build/temp.linux-x86_64-cpython-310/csrc/fused_dense_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=fused_dense_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n","            detected during:\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n","  (61): here\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\n","\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n","            detected during:\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n","  (61): here\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\n","\n","  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-310/csrc/fused_dense.o build/temp.linux-x86_64-cpython-310/csrc/fused_dense_cuda.o -L/usr/local/lib/python3.10/dist-packages/torch/lib -L/usr/local/cuda/lib64 -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-310/fused_dense_cuda.cpython-310-x86_64-linux-gnu.so\n","  building 'scaled_upper_triang_masked_softmax_cuda' extension\n","  creating build/temp.linux-x86_64-cpython-310/csrc/megatron\n","  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/content/apex/csrc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/megatron/scaled_upper_triang_masked_softmax.cpp -o build/temp.linux-x86_64-cpython-310/csrc/megatron/scaled_upper_triang_masked_softmax.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=scaled_upper_triang_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n","  /usr/local/cuda/bin/nvcc -I/content/apex/csrc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/megatron/scaled_upper_triang_masked_softmax_cuda.cu -o build/temp.linux-x86_64-cpython-310/csrc/megatron/scaled_upper_triang_masked_softmax_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=scaled_upper_triang_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n","            detected during:\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n","  (61): here\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\n","\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n","            detected during:\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n","  (61): here\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\n","\n","  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-310/csrc/megatron/scaled_upper_triang_masked_softmax.o build/temp.linux-x86_64-cpython-310/csrc/megatron/scaled_upper_triang_masked_softmax_cuda.o -L/usr/local/lib/python3.10/dist-packages/torch/lib -L/usr/local/cuda/lib64 -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-310/scaled_upper_triang_masked_softmax_cuda.cpython-310-x86_64-linux-gnu.so\n","  building 'generic_scaled_masked_softmax_cuda' extension\n","  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/content/apex/csrc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/megatron/generic_scaled_masked_softmax.cpp -o build/temp.linux-x86_64-cpython-310/csrc/megatron/generic_scaled_masked_softmax.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=generic_scaled_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n","  /usr/local/cuda/bin/nvcc -I/content/apex/csrc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/megatron/generic_scaled_masked_softmax_cuda.cu -o build/temp.linux-x86_64-cpython-310/csrc/megatron/generic_scaled_masked_softmax_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=generic_scaled_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n","            detected during:\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n","  (61): here\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\n","\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n","            detected during:\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n","  (61): here\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\n","\n","  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-310/csrc/megatron/generic_scaled_masked_softmax.o build/temp.linux-x86_64-cpython-310/csrc/megatron/generic_scaled_masked_softmax_cuda.o -L/usr/local/lib/python3.10/dist-packages/torch/lib -L/usr/local/cuda/lib64 -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-310/generic_scaled_masked_softmax_cuda.cpython-310-x86_64-linux-gnu.so\n","  building 'scaled_masked_softmax_cuda' extension\n","  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/content/apex/csrc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/megatron/scaled_masked_softmax.cpp -o build/temp.linux-x86_64-cpython-310/csrc/megatron/scaled_masked_softmax.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=scaled_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n","  /usr/local/cuda/bin/nvcc -I/content/apex/csrc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/megatron/scaled_masked_softmax_cuda.cu -o build/temp.linux-x86_64-cpython-310/csrc/megatron/scaled_masked_softmax_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=scaled_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n","            detected during:\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n","  (61): here\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\n","\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n","            detected during:\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n","  (61): here\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\n","\n","  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-310/csrc/megatron/scaled_masked_softmax.o build/temp.linux-x86_64-cpython-310/csrc/megatron/scaled_masked_softmax_cuda.o -L/usr/local/lib/python3.10/dist-packages/torch/lib -L/usr/local/cuda/lib64 -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-310/scaled_masked_softmax_cuda.cpython-310-x86_64-linux-gnu.so\n","  building 'scaled_softmax_cuda' extension\n","  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/content/apex/csrc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/megatron/scaled_softmax.cpp -o build/temp.linux-x86_64-cpython-310/csrc/megatron/scaled_softmax.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=scaled_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n","  /usr/local/cuda/bin/nvcc -I/content/apex/csrc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/megatron/scaled_softmax_cuda.cu -o build/temp.linux-x86_64-cpython-310/csrc/megatron/scaled_softmax_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=scaled_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n","            detected during:\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n","  (61): here\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\n","\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n","            detected during:\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n","  (61): here\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\n","\n","  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-310/csrc/megatron/scaled_softmax.o build/temp.linux-x86_64-cpython-310/csrc/megatron/scaled_softmax_cuda.o -L/usr/local/lib/python3.10/dist-packages/torch/lib -L/usr/local/cuda/lib64 -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-310/scaled_softmax_cuda.cpython-310-x86_64-linux-gnu.so\n","  building 'fused_weight_gradient_mlp_cuda' extension\n","  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/content/apex/csrc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/megatron/fused_weight_gradient_dense.cpp -o build/temp.linux-x86_64-cpython-310/csrc/megatron/fused_weight_gradient_dense.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=fused_weight_gradient_mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n","  /usr/local/cuda/bin/nvcc -I/content/apex/csrc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/megatron/fused_weight_gradient_dense_16bit_prec_cuda.cu -o build/temp.linux-x86_64-cpython-310/csrc/megatron/fused_weight_gradient_dense_16bit_prec_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_90,code=sm_90 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=fused_weight_gradient_mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n","            detected during:\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n","  (61): here\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\n","\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n","            detected during:\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n","  (61): here\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\n","\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n","            detected during:\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n","  (61): here\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\n","\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n","            detected during:\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n","  (61): here\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\n","\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n","            detected during:\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n","  (61): here\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\n","\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n","            detected during:\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n","  (61): here\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\n","\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n","            detected during:\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n","  (61): here\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\n","\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n","            detected during:\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n","  (61): here\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\n","\n","  /usr/local/cuda/bin/nvcc -I/content/apex/csrc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/megatron/fused_weight_gradient_dense_cuda.cu -o build/temp.linux-x86_64-cpython-310/csrc/megatron/fused_weight_gradient_dense_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_90,code=sm_90 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=fused_weight_gradient_mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n","            detected during:\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n","  (61): here\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\n","\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n","            detected during:\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n","  (61): here\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\n","\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n","            detected during:\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n","  (61): here\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\n","\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n","            detected during:\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n","  (61): here\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\n","\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n","            detected during:\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n","  (61): here\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\n","\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n","            detected during:\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n","  (61): here\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\n","\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n","            detected during:\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n","  (61): here\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\n","\n","  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n","            detected during:\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n","  (61): here\n","              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n","  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\n","\n","  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-310/csrc/megatron/fused_weight_gradient_dense.o build/temp.linux-x86_64-cpython-310/csrc/megatron/fused_weight_gradient_dense_16bit_prec_cuda.o build/temp.linux-x86_64-cpython-310/csrc/megatron/fused_weight_gradient_dense_cuda.o -L/usr/local/lib/python3.10/dist-packages/torch/lib -L/usr/local/cuda/lib64 -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-310/fused_weight_gradient_mlp_cuda.cpython-310-x86_64-linux-gnu.so\n","  /usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n","  !!\n","\n","          ********************************************************************************\n","          Please avoid running ``setup.py`` directly.\n","          Instead, use pypa/build, pypa/installer, pypa/build or\n","          other standards-based tools.\n","\n","          See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n","          ********************************************************************************\n","\n","  !!\n","    self.initialize_options()\n","  installing to build/bdist.linux-x86_64/wheel\n","  running install\n","  running install_lib\n","  creating build/bdist.linux-x86_64\n","  creating build/bdist.linux-x86_64/wheel\n","  copying build/lib.linux-x86_64-cpython-310/fused_layer_norm_cuda.cpython-310-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel\n","  copying build/lib.linux-x86_64-cpython-310/scaled_upper_triang_masked_softmax_cuda.cpython-310-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel\n","  copying build/lib.linux-x86_64-cpython-310/scaled_masked_softmax_cuda.cpython-310-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel\n","  creating build/bdist.linux-x86_64/wheel/apex\n","  creating build/bdist.linux-x86_64/wheel/apex/amp\n","  copying build/lib.linux-x86_64-cpython-310/apex/amp/_initialize.py -> build/bdist.linux-x86_64/wheel/apex/amp\n","  copying build/lib.linux-x86_64-cpython-310/apex/amp/_process_optimizer.py -> build/bdist.linux-x86_64/wheel/apex/amp\n","  copying build/lib.linux-x86_64-cpython-310/apex/amp/rnn_compat.py -> build/bdist.linux-x86_64/wheel/apex/amp\n","  copying build/lib.linux-x86_64-cpython-310/apex/amp/compat.py -> build/bdist.linux-x86_64/wheel/apex/amp\n","  creating build/bdist.linux-x86_64/wheel/apex/amp/lists\n","  copying build/lib.linux-x86_64-cpython-310/apex/amp/lists/torch_overrides.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n","  copying build/lib.linux-x86_64-cpython-310/apex/amp/lists/tensor_overrides.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n","  copying build/lib.linux-x86_64-cpython-310/apex/amp/lists/__init__.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n","  copying build/lib.linux-x86_64-cpython-310/apex/amp/lists/functional_overrides.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n","  copying build/lib.linux-x86_64-cpython-310/apex/amp/wrap.py -> build/bdist.linux-x86_64/wheel/apex/amp\n","  copying build/lib.linux-x86_64-cpython-310/apex/amp/amp.py -> build/bdist.linux-x86_64/wheel/apex/amp\n","  copying build/lib.linux-x86_64-cpython-310/apex/amp/handle.py -> build/bdist.linux-x86_64/wheel/apex/amp\n","  copying build/lib.linux-x86_64-cpython-310/apex/amp/__version__.py -> build/bdist.linux-x86_64/wheel/apex/amp\n","  copying build/lib.linux-x86_64-cpython-310/apex/amp/utils.py -> build/bdist.linux-x86_64/wheel/apex/amp\n","  copying build/lib.linux-x86_64-cpython-310/apex/amp/_amp_state.py -> build/bdist.linux-x86_64/wheel/apex/amp\n","  copying build/lib.linux-x86_64-cpython-310/apex/amp/opt.py -> build/bdist.linux-x86_64/wheel/apex/amp\n","  copying build/lib.linux-x86_64-cpython-310/apex/amp/__init__.py -> build/bdist.linux-x86_64/wheel/apex/amp\n","  copying build/lib.linux-x86_64-cpython-310/apex/amp/frontend.py -> build/bdist.linux-x86_64/wheel/apex/amp\n","  copying build/lib.linux-x86_64-cpython-310/apex/amp/scaler.py -> build/bdist.linux-x86_64/wheel/apex/amp\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/xentropy\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/xentropy/softmax_xentropy.py -> build/bdist.linux-x86_64/wheel/apex/contrib/xentropy\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/xentropy/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/xentropy\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/multihead_attn/self_multihead_attn.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/multihead_attn/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/peer_memory\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/peer_memory/peer_memory.py -> build/bdist.linux-x86_64/wheel/apex/contrib/peer_memory\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/peer_memory/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/peer_memory\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/peer_memory/peer_halo_exchanger_1d.py -> build/bdist.linux-x86_64/wheel/apex/contrib/peer_memory\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/fmha\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/fmha/fmha.py -> build/bdist.linux-x86_64/wheel/apex/contrib/fmha\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/fmha/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/fmha\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/groupbn\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/groupbn/batch_norm.py -> build/bdist.linux-x86_64/wheel/apex/contrib/groupbn\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/groupbn/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/groupbn\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/sparsity/sparse_masklib.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/sparsity/permutation_lib.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/sparsity/permutation_search_kernels\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/sparsity/permutation_search_kernels/exhaustive_search.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity/permutation_search_kernels\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/sparsity/permutation_search_kernels/channel_swap.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity/permutation_search_kernels\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/sparsity/permutation_search_kernels/permutation_utilities.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity/permutation_search_kernels\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/sparsity/permutation_search_kernels/call_permutation_search_kernels.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity/permutation_search_kernels\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/sparsity/permutation_search_kernels/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity/permutation_search_kernels\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/sparsity/asp.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/sparsity/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/test\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/xentropy\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/xentropy/test_label_smoothing.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/xentropy\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/xentropy/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/xentropy\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/multihead_attn\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/multihead_attn/test_fast_self_multihead_attn_bias.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/multihead_attn\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/multihead_attn/test_self_multihead_attn_norm_add.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/multihead_attn\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/multihead_attn/test_mha_fused_softmax.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/multihead_attn\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/multihead_attn/test_self_multihead_attn.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/multihead_attn\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/multihead_attn/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/multihead_attn\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/multihead_attn/test_encdec_multihead_attn_norm_add.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/multihead_attn\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/multihead_attn/test_encdec_multihead_attn.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/multihead_attn\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/peer_memory\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/peer_memory/test_peer_halo_exchange_module.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/peer_memory\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/peer_memory/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/peer_memory\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/fmha\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/fmha/test_fmha.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/fmha\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/fmha/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/fmha\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/bottleneck\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/bottleneck/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/bottleneck\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/bottleneck/test_bottleneck_module.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/bottleneck\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/index_mul_2d\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/index_mul_2d/test_index_mul_2d.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/index_mul_2d\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/index_mul_2d/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/index_mul_2d\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/layer_norm\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/layer_norm/test_fast_layer_norm.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/layer_norm\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/layer_norm/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/layer_norm\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/clip_grad\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/clip_grad/test_clip_grad.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/clip_grad\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/clip_grad/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/clip_grad\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/optimizers\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/optimizers/test_distributed_fused_lamb.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/optimizers\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/optimizers/test_dist_adam.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/optimizers\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/optimizers/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/optimizers\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/conv_bias_relu\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/conv_bias_relu/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/conv_bias_relu\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/conv_bias_relu/test_conv_bias_relu.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/conv_bias_relu\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/cudnn_gbn\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/cudnn_gbn/test_cudnn_gbn_with_two_gpus.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/cudnn_gbn\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/cudnn_gbn/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/cudnn_gbn\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/focal_loss\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/focal_loss/test_focal_loss.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/focal_loss\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/focal_loss/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/focal_loss\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/transducer\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/transducer/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/transducer\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/transducer/test_transducer_loss.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/transducer\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/transducer/test_transducer_joint.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/transducer\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/bottleneck/halo_exchangers.py -> build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/bottleneck/bottleneck.py -> build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/bottleneck/test.py -> build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/bottleneck/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/index_mul_2d\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/index_mul_2d/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/index_mul_2d\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/index_mul_2d/index_mul_2d.py -> build/bdist.linux-x86_64/wheel/apex/contrib/index_mul_2d\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/layer_norm\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/layer_norm/layer_norm.py -> build/bdist.linux-x86_64/wheel/apex/contrib/layer_norm\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/layer_norm/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/layer_norm\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/clip_grad\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/clip_grad/clip_grad.py -> build/bdist.linux-x86_64/wheel/apex/contrib/clip_grad\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/clip_grad/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/clip_grad\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/optimizers/distributed_fused_adam.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/optimizers/distributed_fused_lamb.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/optimizers/fused_adam.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/optimizers/fused_lamb.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/optimizers/fp16_optimizer.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/optimizers/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/optimizers/fused_sgd.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/conv_bias_relu\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/conv_bias_relu/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/conv_bias_relu\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/conv_bias_relu/conv_bias_relu.py -> build/bdist.linux-x86_64/wheel/apex/contrib/conv_bias_relu\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/cudnn_gbn\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/cudnn_gbn/batch_norm.py -> build/bdist.linux-x86_64/wheel/apex/contrib/cudnn_gbn\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/cudnn_gbn/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/cudnn_gbn\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/focal_loss\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/focal_loss/focal_loss.py -> build/bdist.linux-x86_64/wheel/apex/contrib/focal_loss\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/focal_loss/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/focal_loss\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/transducer\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/transducer/_transducer_ref.py -> build/bdist.linux-x86_64/wheel/apex/contrib/transducer\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/transducer/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/transducer\n","  copying build/lib.linux-x86_64-cpython-310/apex/contrib/transducer/transducer.py -> build/bdist.linux-x86_64/wheel/apex/contrib/transducer\n","  creating build/bdist.linux-x86_64/wheel/apex/normalization\n","  copying build/lib.linux-x86_64-cpython-310/apex/normalization/fused_layer_norm.py -> build/bdist.linux-x86_64/wheel/apex/normalization\n","  copying build/lib.linux-x86_64-cpython-310/apex/normalization/__init__.py -> build/bdist.linux-x86_64/wheel/apex/normalization\n","  copying build/lib.linux-x86_64-cpython-310/apex/_autocast_utils.py -> build/bdist.linux-x86_64/wheel/apex\n","  creating build/bdist.linux-x86_64/wheel/apex/multi_tensor_apply\n","  copying build/lib.linux-x86_64-cpython-310/apex/multi_tensor_apply/multi_tensor_apply.py -> build/bdist.linux-x86_64/wheel/apex/multi_tensor_apply\n","  copying build/lib.linux-x86_64-cpython-310/apex/multi_tensor_apply/__init__.py -> build/bdist.linux-x86_64/wheel/apex/multi_tensor_apply\n","  creating build/bdist.linux-x86_64/wheel/apex/transformer\n","  creating build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel\n","  copying build/lib.linux-x86_64-cpython-310/apex/transformer/pipeline_parallel/p2p_communication.py -> build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel\n","  creating build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel/schedules\n","  copying build/lib.linux-x86_64-cpython-310/apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_without_interleaving.py -> build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel/schedules\n","  copying build/lib.linux-x86_64-cpython-310/apex/transformer/pipeline_parallel/schedules/common.py -> build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel/schedules\n","  copying build/lib.linux-x86_64-cpython-310/apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_with_interleaving.py -> build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel/schedules\n","  copying build/lib.linux-x86_64-cpython-310/apex/transformer/pipeline_parallel/schedules/__init__.py -> build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel/schedules\n","  copying build/lib.linux-x86_64-cpython-310/apex/transformer/pipeline_parallel/schedules/fwd_bwd_no_pipelining.py -> build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel/schedules\n","  copying build/lib.linux-x86_64-cpython-310/apex/transformer/pipeline_parallel/utils.py -> build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel\n","  copying build/lib.linux-x86_64-cpython-310/apex/transformer/pipeline_parallel/__init__.py -> build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel\n","  copying build/lib.linux-x86_64-cpython-310/apex/transformer/pipeline_parallel/_timers.py -> build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel\n","  creating build/bdist.linux-x86_64/wheel/apex/transformer/tensor_parallel\n","  copying build/lib.linux-x86_64-cpython-310/apex/transformer/tensor_parallel/random.py -> build/bdist.linux-x86_64/wheel/apex/transformer/tensor_parallel\n","  copying build/lib.linux-x86_64-cpython-310/apex/transformer/tensor_parallel/mappings.py -> build/bdist.linux-x86_64/wheel/apex/transformer/tensor_parallel\n","  copying build/lib.linux-x86_64-cpython-310/apex/transformer/tensor_parallel/cross_entropy.py -> build/bdist.linux-x86_64/wheel/apex/transformer/tensor_parallel\n","  copying build/lib.linux-x86_64-cpython-310/apex/transformer/tensor_parallel/utils.py -> build/bdist.linux-x86_64/wheel/apex/transformer/tensor_parallel\n","  copying build/lib.linux-x86_64-cpython-310/apex/transformer/tensor_parallel/__init__.py -> build/bdist.linux-x86_64/wheel/apex/transformer/tensor_parallel\n","  copying build/lib.linux-x86_64-cpython-310/apex/transformer/tensor_parallel/data.py -> build/bdist.linux-x86_64/wheel/apex/transformer/tensor_parallel\n","  copying build/lib.linux-x86_64-cpython-310/apex/transformer/tensor_parallel/memory.py -> build/bdist.linux-x86_64/wheel/apex/transformer/tensor_parallel\n","  copying build/lib.linux-x86_64-cpython-310/apex/transformer/tensor_parallel/layers.py -> build/bdist.linux-x86_64/wheel/apex/transformer/tensor_parallel\n","  creating build/bdist.linux-x86_64/wheel/apex/transformer/amp\n","  copying build/lib.linux-x86_64-cpython-310/apex/transformer/amp/__init__.py -> build/bdist.linux-x86_64/wheel/apex/transformer/amp\n","  copying build/lib.linux-x86_64-cpython-310/apex/transformer/amp/grad_scaler.py -> build/bdist.linux-x86_64/wheel/apex/transformer/amp\n","  copying build/lib.linux-x86_64-cpython-310/apex/transformer/_ucc_util.py -> build/bdist.linux-x86_64/wheel/apex/transformer\n","  creating build/bdist.linux-x86_64/wheel/apex/transformer/functional\n","  copying build/lib.linux-x86_64-cpython-310/apex/transformer/functional/fused_softmax.py -> build/bdist.linux-x86_64/wheel/apex/transformer/functional\n","  copying build/lib.linux-x86_64-cpython-310/apex/transformer/functional/__init__.py -> build/bdist.linux-x86_64/wheel/apex/transformer/functional\n","  creating build/bdist.linux-x86_64/wheel/apex/transformer/_data\n","  copying build/lib.linux-x86_64-cpython-310/apex/transformer/_data/_batchsampler.py -> build/bdist.linux-x86_64/wheel/apex/transformer/_data\n","  copying build/lib.linux-x86_64-cpython-310/apex/transformer/_data/__init__.py -> build/bdist.linux-x86_64/wheel/apex/transformer/_data\n","  creating build/bdist.linux-x86_64/wheel/apex/transformer/layers\n","  copying build/lib.linux-x86_64-cpython-310/apex/transformer/layers/layer_norm.py -> build/bdist.linux-x86_64/wheel/apex/transformer/layers\n","  copying build/lib.linux-x86_64-cpython-310/apex/transformer/layers/__init__.py -> build/bdist.linux-x86_64/wheel/apex/transformer/layers\n","  copying build/lib.linux-x86_64-cpython-310/apex/transformer/utils.py -> build/bdist.linux-x86_64/wheel/apex/transformer\n","  copying build/lib.linux-x86_64-cpython-310/apex/transformer/parallel_state.py -> build/bdist.linux-x86_64/wheel/apex/transformer\n","  creating build/bdist.linux-x86_64/wheel/apex/transformer/testing\n","  copying build/lib.linux-x86_64-cpython-310/apex/transformer/testing/standalone_bert.py -> build/bdist.linux-x86_64/wheel/apex/transformer/testing\n","  copying build/lib.linux-x86_64-cpython-310/apex/transformer/testing/arguments.py -> build/bdist.linux-x86_64/wheel/apex/transformer/testing\n","  copying build/lib.linux-x86_64-cpython-310/apex/transformer/testing/standalone_transformer_lm.py -> build/bdist.linux-x86_64/wheel/apex/transformer/testing\n","  copying build/lib.linux-x86_64-cpython-310/apex/transformer/testing/standalone_gpt.py -> build/bdist.linux-x86_64/wheel/apex/transformer/testing\n","  copying build/lib.linux-x86_64-cpython-310/apex/transformer/testing/__init__.py -> build/bdist.linux-x86_64/wheel/apex/transformer/testing\n","  copying build/lib.linux-x86_64-cpython-310/apex/transformer/testing/commons.py -> build/bdist.linux-x86_64/wheel/apex/transformer/testing\n","  copying build/lib.linux-x86_64-cpython-310/apex/transformer/testing/global_vars.py -> build/bdist.linux-x86_64/wheel/apex/transformer/testing\n","  copying build/lib.linux-x86_64-cpython-310/apex/transformer/testing/distributed_test_base.py -> build/bdist.linux-x86_64/wheel/apex/transformer/testing\n","  copying build/lib.linux-x86_64-cpython-310/apex/transformer/__init__.py -> build/bdist.linux-x86_64/wheel/apex/transformer\n","  copying build/lib.linux-x86_64-cpython-310/apex/transformer/microbatches.py -> build/bdist.linux-x86_64/wheel/apex/transformer\n","  copying build/lib.linux-x86_64-cpython-310/apex/transformer/log_util.py -> build/bdist.linux-x86_64/wheel/apex/transformer\n","  copying build/lib.linux-x86_64-cpython-310/apex/transformer/enums.py -> build/bdist.linux-x86_64/wheel/apex/transformer\n","  creating build/bdist.linux-x86_64/wheel/apex/mlp\n","  copying build/lib.linux-x86_64-cpython-310/apex/mlp/mlp.py -> build/bdist.linux-x86_64/wheel/apex/mlp\n","  copying build/lib.linux-x86_64-cpython-310/apex/mlp/__init__.py -> build/bdist.linux-x86_64/wheel/apex/mlp\n","  creating build/bdist.linux-x86_64/wheel/apex/parallel\n","  copying build/lib.linux-x86_64-cpython-310/apex/parallel/sync_batchnorm.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n","  copying build/lib.linux-x86_64-cpython-310/apex/parallel/multiproc.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n","  copying build/lib.linux-x86_64-cpython-310/apex/parallel/optimized_sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n","  copying build/lib.linux-x86_64-cpython-310/apex/parallel/optimized_sync_batchnorm.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n","  copying build/lib.linux-x86_64-cpython-310/apex/parallel/sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n","  copying build/lib.linux-x86_64-cpython-310/apex/parallel/distributed.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n","  copying build/lib.linux-x86_64-cpython-310/apex/parallel/__init__.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n","  copying build/lib.linux-x86_64-cpython-310/apex/parallel/LARC.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n","  creating build/bdist.linux-x86_64/wheel/apex/fp16_utils\n","  copying build/lib.linux-x86_64-cpython-310/apex/fp16_utils/loss_scaler.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n","  copying build/lib.linux-x86_64-cpython-310/apex/fp16_utils/fp16util.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n","  copying build/lib.linux-x86_64-cpython-310/apex/fp16_utils/fp16_optimizer.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n","  copying build/lib.linux-x86_64-cpython-310/apex/fp16_utils/__init__.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n","  creating build/bdist.linux-x86_64/wheel/apex/RNN\n","  copying build/lib.linux-x86_64-cpython-310/apex/RNN/RNNBackend.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n","  copying build/lib.linux-x86_64-cpython-310/apex/RNN/models.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n","  copying build/lib.linux-x86_64-cpython-310/apex/RNN/cells.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n","  copying build/lib.linux-x86_64-cpython-310/apex/RNN/__init__.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n","  creating build/bdist.linux-x86_64/wheel/apex/optimizers\n","  copying build/lib.linux-x86_64-cpython-310/apex/optimizers/fused_adam.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n","  copying build/lib.linux-x86_64-cpython-310/apex/optimizers/fused_lamb.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n","  copying build/lib.linux-x86_64-cpython-310/apex/optimizers/fused_novograd.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n","  copying build/lib.linux-x86_64-cpython-310/apex/optimizers/fused_mixed_precision_lamb.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n","  copying build/lib.linux-x86_64-cpython-310/apex/optimizers/fused_adagrad.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n","  copying build/lib.linux-x86_64-cpython-310/apex/optimizers/__init__.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n","  copying build/lib.linux-x86_64-cpython-310/apex/optimizers/fused_sgd.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n","  copying build/lib.linux-x86_64-cpython-310/apex/__init__.py -> build/bdist.linux-x86_64/wheel/apex\n","  creating build/bdist.linux-x86_64/wheel/apex/fused_dense\n","  copying build/lib.linux-x86_64-cpython-310/apex/fused_dense/fused_dense.py -> build/bdist.linux-x86_64/wheel/apex/fused_dense\n","  copying build/lib.linux-x86_64-cpython-310/apex/fused_dense/__init__.py -> build/bdist.linux-x86_64/wheel/apex/fused_dense\n","  copying build/lib.linux-x86_64-cpython-310/mlp_cuda.cpython-310-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel\n","  copying build/lib.linux-x86_64-cpython-310/fused_dense_cuda.cpython-310-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel\n","  copying build/lib.linux-x86_64-cpython-310/generic_scaled_masked_softmax_cuda.cpython-310-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel\n","  copying build/lib.linux-x86_64-cpython-310/fused_weight_gradient_mlp_cuda.cpython-310-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel\n","  copying build/lib.linux-x86_64-cpython-310/syncbn.cpython-310-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel\n","  copying build/lib.linux-x86_64-cpython-310/scaled_softmax_cuda.cpython-310-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel\n","  copying build/lib.linux-x86_64-cpython-310/amp_C.cpython-310-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel\n","  copying build/lib.linux-x86_64-cpython-310/apex_C.cpython-310-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel\n","  running install_egg_info\n","  running egg_info\n","  creating apex.egg-info\n","  writing apex.egg-info/PKG-INFO\n","  writing dependency_links to apex.egg-info/dependency_links.txt\n","  writing requirements to apex.egg-info/requires.txt\n","  writing top-level names to apex.egg-info/top_level.txt\n","  writing manifest file 'apex.egg-info/SOURCES.txt'\n","  reading manifest file 'apex.egg-info/SOURCES.txt'\n","  adding license file 'LICENSE'\n","  writing manifest file 'apex.egg-info/SOURCES.txt'\n","  Copying apex.egg-info to build/bdist.linux-x86_64/wheel/apex-0.1-py3.10.egg-info\n","  running install_scripts\n","  creating build/bdist.linux-x86_64/wheel/apex-0.1.dist-info/WHEEL\n","  creating '/tmp/pip-wheel-a2i_momp/apex-0.1-cp310-cp310-linux_x86_64.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n","  adding 'amp_C.cpython-310-x86_64-linux-gnu.so'\n","  adding 'apex_C.cpython-310-x86_64-linux-gnu.so'\n","  adding 'fused_dense_cuda.cpython-310-x86_64-linux-gnu.so'\n","  adding 'fused_layer_norm_cuda.cpython-310-x86_64-linux-gnu.so'\n","  adding 'fused_weight_gradient_mlp_cuda.cpython-310-x86_64-linux-gnu.so'\n","  adding 'generic_scaled_masked_softmax_cuda.cpython-310-x86_64-linux-gnu.so'\n","  adding 'mlp_cuda.cpython-310-x86_64-linux-gnu.so'\n","  adding 'scaled_masked_softmax_cuda.cpython-310-x86_64-linux-gnu.so'\n","  adding 'scaled_softmax_cuda.cpython-310-x86_64-linux-gnu.so'\n","  adding 'scaled_upper_triang_masked_softmax_cuda.cpython-310-x86_64-linux-gnu.so'\n","  adding 'syncbn.cpython-310-x86_64-linux-gnu.so'\n","  adding 'apex/__init__.py'\n","  adding 'apex/_autocast_utils.py'\n","  adding 'apex/RNN/RNNBackend.py'\n","  adding 'apex/RNN/__init__.py'\n","  adding 'apex/RNN/cells.py'\n","  adding 'apex/RNN/models.py'\n","  adding 'apex/amp/__init__.py'\n","  adding 'apex/amp/__version__.py'\n","  adding 'apex/amp/_amp_state.py'\n","  adding 'apex/amp/_initialize.py'\n","  adding 'apex/amp/_process_optimizer.py'\n","  adding 'apex/amp/amp.py'\n","  adding 'apex/amp/compat.py'\n","  adding 'apex/amp/frontend.py'\n","  adding 'apex/amp/handle.py'\n","  adding 'apex/amp/opt.py'\n","  adding 'apex/amp/rnn_compat.py'\n","  adding 'apex/amp/scaler.py'\n","  adding 'apex/amp/utils.py'\n","  adding 'apex/amp/wrap.py'\n","  adding 'apex/amp/lists/__init__.py'\n","  adding 'apex/amp/lists/functional_overrides.py'\n","  adding 'apex/amp/lists/tensor_overrides.py'\n","  adding 'apex/amp/lists/torch_overrides.py'\n","  adding 'apex/contrib/__init__.py'\n","  adding 'apex/contrib/bottleneck/__init__.py'\n","  adding 'apex/contrib/bottleneck/bottleneck.py'\n","  adding 'apex/contrib/bottleneck/halo_exchangers.py'\n","  adding 'apex/contrib/bottleneck/test.py'\n","  adding 'apex/contrib/clip_grad/__init__.py'\n","  adding 'apex/contrib/clip_grad/clip_grad.py'\n","  adding 'apex/contrib/conv_bias_relu/__init__.py'\n","  adding 'apex/contrib/conv_bias_relu/conv_bias_relu.py'\n","  adding 'apex/contrib/cudnn_gbn/__init__.py'\n","  adding 'apex/contrib/cudnn_gbn/batch_norm.py'\n","  adding 'apex/contrib/fmha/__init__.py'\n","  adding 'apex/contrib/fmha/fmha.py'\n","  adding 'apex/contrib/focal_loss/__init__.py'\n","  adding 'apex/contrib/focal_loss/focal_loss.py'\n","  adding 'apex/contrib/groupbn/__init__.py'\n","  adding 'apex/contrib/groupbn/batch_norm.py'\n","  adding 'apex/contrib/index_mul_2d/__init__.py'\n","  adding 'apex/contrib/index_mul_2d/index_mul_2d.py'\n","  adding 'apex/contrib/layer_norm/__init__.py'\n","  adding 'apex/contrib/layer_norm/layer_norm.py'\n","  adding 'apex/contrib/multihead_attn/__init__.py'\n","  adding 'apex/contrib/multihead_attn/encdec_multihead_attn.py'\n","  adding 'apex/contrib/multihead_attn/encdec_multihead_attn_func.py'\n","  adding 'apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py'\n","  adding 'apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py'\n","  adding 'apex/contrib/multihead_attn/fast_self_multihead_attn_func.py'\n","  adding 'apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py'\n","  adding 'apex/contrib/multihead_attn/mask_softmax_dropout_func.py'\n","  adding 'apex/contrib/multihead_attn/self_multihead_attn.py'\n","  adding 'apex/contrib/multihead_attn/self_multihead_attn_func.py'\n","  adding 'apex/contrib/optimizers/__init__.py'\n","  adding 'apex/contrib/optimizers/distributed_fused_adam.py'\n","  adding 'apex/contrib/optimizers/distributed_fused_lamb.py'\n","  adding 'apex/contrib/optimizers/fp16_optimizer.py'\n","  adding 'apex/contrib/optimizers/fused_adam.py'\n","  adding 'apex/contrib/optimizers/fused_lamb.py'\n","  adding 'apex/contrib/optimizers/fused_sgd.py'\n","  adding 'apex/contrib/peer_memory/__init__.py'\n","  adding 'apex/contrib/peer_memory/peer_halo_exchanger_1d.py'\n","  adding 'apex/contrib/peer_memory/peer_memory.py'\n","  adding 'apex/contrib/sparsity/__init__.py'\n","  adding 'apex/contrib/sparsity/asp.py'\n","  adding 'apex/contrib/sparsity/permutation_lib.py'\n","  adding 'apex/contrib/sparsity/sparse_masklib.py'\n","  adding 'apex/contrib/sparsity/permutation_search_kernels/__init__.py'\n","  adding 'apex/contrib/sparsity/permutation_search_kernels/call_permutation_search_kernels.py'\n","  adding 'apex/contrib/sparsity/permutation_search_kernels/channel_swap.py'\n","  adding 'apex/contrib/sparsity/permutation_search_kernels/exhaustive_search.py'\n","  adding 'apex/contrib/sparsity/permutation_search_kernels/permutation_utilities.py'\n","  adding 'apex/contrib/test/__init__.py'\n","  adding 'apex/contrib/test/bottleneck/__init__.py'\n","  adding 'apex/contrib/test/bottleneck/test_bottleneck_module.py'\n","  adding 'apex/contrib/test/clip_grad/__init__.py'\n","  adding 'apex/contrib/test/clip_grad/test_clip_grad.py'\n","  adding 'apex/contrib/test/conv_bias_relu/__init__.py'\n","  adding 'apex/contrib/test/conv_bias_relu/test_conv_bias_relu.py'\n","  adding 'apex/contrib/test/cudnn_gbn/__init__.py'\n","  adding 'apex/contrib/test/cudnn_gbn/test_cudnn_gbn_with_two_gpus.py'\n","  adding 'apex/contrib/test/fmha/__init__.py'\n","  adding 'apex/contrib/test/fmha/test_fmha.py'\n","  adding 'apex/contrib/test/focal_loss/__init__.py'\n","  adding 'apex/contrib/test/focal_loss/test_focal_loss.py'\n","  adding 'apex/contrib/test/index_mul_2d/__init__.py'\n","  adding 'apex/contrib/test/index_mul_2d/test_index_mul_2d.py'\n","  adding 'apex/contrib/test/layer_norm/__init__.py'\n","  adding 'apex/contrib/test/layer_norm/test_fast_layer_norm.py'\n","  adding 'apex/contrib/test/multihead_attn/__init__.py'\n","  adding 'apex/contrib/test/multihead_attn/test_encdec_multihead_attn.py'\n","  adding 'apex/contrib/test/multihead_attn/test_encdec_multihead_attn_norm_add.py'\n","  adding 'apex/contrib/test/multihead_attn/test_fast_self_multihead_attn_bias.py'\n","  adding 'apex/contrib/test/multihead_attn/test_mha_fused_softmax.py'\n","  adding 'apex/contrib/test/multihead_attn/test_self_multihead_attn.py'\n","  adding 'apex/contrib/test/multihead_attn/test_self_multihead_attn_norm_add.py'\n","  adding 'apex/contrib/test/optimizers/__init__.py'\n","  adding 'apex/contrib/test/optimizers/test_dist_adam.py'\n","  adding 'apex/contrib/test/optimizers/test_distributed_fused_lamb.py'\n","  adding 'apex/contrib/test/peer_memory/__init__.py'\n","  adding 'apex/contrib/test/peer_memory/test_peer_halo_exchange_module.py'\n","  adding 'apex/contrib/test/transducer/__init__.py'\n","  adding 'apex/contrib/test/transducer/test_transducer_joint.py'\n","  adding 'apex/contrib/test/transducer/test_transducer_loss.py'\n","  adding 'apex/contrib/test/xentropy/__init__.py'\n","  adding 'apex/contrib/test/xentropy/test_label_smoothing.py'\n","  adding 'apex/contrib/transducer/__init__.py'\n","  adding 'apex/contrib/transducer/_transducer_ref.py'\n","  adding 'apex/contrib/transducer/transducer.py'\n","  adding 'apex/contrib/xentropy/__init__.py'\n","  adding 'apex/contrib/xentropy/softmax_xentropy.py'\n","  adding 'apex/fp16_utils/__init__.py'\n","  adding 'apex/fp16_utils/fp16_optimizer.py'\n","  adding 'apex/fp16_utils/fp16util.py'\n","  adding 'apex/fp16_utils/loss_scaler.py'\n","  adding 'apex/fused_dense/__init__.py'\n","  adding 'apex/fused_dense/fused_dense.py'\n","  adding 'apex/mlp/__init__.py'\n","  adding 'apex/mlp/mlp.py'\n","  adding 'apex/multi_tensor_apply/__init__.py'\n","  adding 'apex/multi_tensor_apply/multi_tensor_apply.py'\n","  adding 'apex/normalization/__init__.py'\n","  adding 'apex/normalization/fused_layer_norm.py'\n","  adding 'apex/optimizers/__init__.py'\n","  adding 'apex/optimizers/fused_adagrad.py'\n","  adding 'apex/optimizers/fused_adam.py'\n","  adding 'apex/optimizers/fused_lamb.py'\n","  adding 'apex/optimizers/fused_mixed_precision_lamb.py'\n","  adding 'apex/optimizers/fused_novograd.py'\n","  adding 'apex/optimizers/fused_sgd.py'\n","  adding 'apex/parallel/LARC.py'\n","  adding 'apex/parallel/__init__.py'\n","  adding 'apex/parallel/distributed.py'\n","  adding 'apex/parallel/multiproc.py'\n","  adding 'apex/parallel/optimized_sync_batchnorm.py'\n","  adding 'apex/parallel/optimized_sync_batchnorm_kernel.py'\n","  adding 'apex/parallel/sync_batchnorm.py'\n","  adding 'apex/parallel/sync_batchnorm_kernel.py'\n","  adding 'apex/transformer/__init__.py'\n","  adding 'apex/transformer/_ucc_util.py'\n","  adding 'apex/transformer/enums.py'\n","  adding 'apex/transformer/log_util.py'\n","  adding 'apex/transformer/microbatches.py'\n","  adding 'apex/transformer/parallel_state.py'\n","  adding 'apex/transformer/utils.py'\n","  adding 'apex/transformer/_data/__init__.py'\n","  adding 'apex/transformer/_data/_batchsampler.py'\n","  adding 'apex/transformer/amp/__init__.py'\n","  adding 'apex/transformer/amp/grad_scaler.py'\n","  adding 'apex/transformer/functional/__init__.py'\n","  adding 'apex/transformer/functional/fused_softmax.py'\n","  adding 'apex/transformer/layers/__init__.py'\n","  adding 'apex/transformer/layers/layer_norm.py'\n","  adding 'apex/transformer/pipeline_parallel/__init__.py'\n","  adding 'apex/transformer/pipeline_parallel/_timers.py'\n","  adding 'apex/transformer/pipeline_parallel/p2p_communication.py'\n","  adding 'apex/transformer/pipeline_parallel/utils.py'\n","  adding 'apex/transformer/pipeline_parallel/schedules/__init__.py'\n","  adding 'apex/transformer/pipeline_parallel/schedules/common.py'\n","  adding 'apex/transformer/pipeline_parallel/schedules/fwd_bwd_no_pipelining.py'\n","  adding 'apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_with_interleaving.py'\n","  adding 'apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_without_interleaving.py'\n","  adding 'apex/transformer/tensor_parallel/__init__.py'\n","  adding 'apex/transformer/tensor_parallel/cross_entropy.py'\n","  adding 'apex/transformer/tensor_parallel/data.py'\n","  adding 'apex/transformer/tensor_parallel/layers.py'\n","  adding 'apex/transformer/tensor_parallel/mappings.py'\n","  adding 'apex/transformer/tensor_parallel/memory.py'\n","  adding 'apex/transformer/tensor_parallel/random.py'\n","  adding 'apex/transformer/tensor_parallel/utils.py'\n","  adding 'apex/transformer/testing/__init__.py'\n","  adding 'apex/transformer/testing/arguments.py'\n","  adding 'apex/transformer/testing/commons.py'\n","  adding 'apex/transformer/testing/distributed_test_base.py'\n","  adding 'apex/transformer/testing/global_vars.py'\n","  adding 'apex/transformer/testing/standalone_bert.py'\n","  adding 'apex/transformer/testing/standalone_gpt.py'\n","  adding 'apex/transformer/testing/standalone_transformer_lm.py'\n","  adding 'apex-0.1.dist-info/LICENSE'\n","  adding 'apex-0.1.dist-info/METADATA'\n","  adding 'apex-0.1.dist-info/WHEEL'\n","  adding 'apex-0.1.dist-info/top_level.txt'\n","  adding 'apex-0.1.dist-info/RECORD'\n","  removing build/bdist.linux-x86_64/wheel\n","  Building wheel for apex (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for apex: filename=apex-0.1-cp310-cp310-linux_x86_64.whl size=40366852 sha256=b30ea41b45b5577d2f023147917e0eb0a38308f4f8e7ffdcd82cf3871b7c101a\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-1p6h3gnc/wheels/83/7e/8e/84a535a8280d2de7a77a3fed6710fa86220721b5045c017df9\n","Successfully built apex\n","Installing collected packages: apex\n","Successfully installed apex-0.1\n","CPU times: user 7.28 s, sys: 1.01 s, total: 8.28 s\n","Wall time: 24min 40s\n"]}],"source":["%%time\n","\n","!git clone https://github.com/NVIDIA/apex\n","%cd /content/apex\n","!pip install -v --disable-pip-version-check --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./"]},{"cell_type":"markdown","metadata":{"id":"yUSNtuVeTUwl"},"source":["## Optimazer"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"HZMtCepVRDaJ","executionInfo":{"status":"ok","timestamp":1685488248855,"user_tz":180,"elapsed":6,"user":{"displayName":"Antonio Santos","userId":"03265893617080544823"}}},"outputs":[],"source":["# Based on https://github.com/pytorch/pytorch/pull/3740\n","import torch\n","import math\n","\n","\n","class AdamW(torch.optim.Optimizer):\n","    \"\"\"Implements AdamW algorithm.\n","\n","    It has been proposed in `Fixing Weight Decay Regularization in Adam`_.\n","\n","    Arguments:\n","        params (iterable): iterable of parameters to optimize or dicts defining\n","            parameter groups\n","        lr (float, optional): learning rate (default: 1e-3)\n","        betas (Tuple[float, float], optional): coefficients used for computing\n","            running averages of gradient and its square (default: (0.9, 0.999))\n","        eps (float, optional): term added to the denominator to improve\n","            numerical stability (default: 1e-8)\n","        weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n","\n","    .. Fixing Weight Decay Regularization in Adam:\n","    https://arxiv.org/abs/1711.05101\n","    \"\"\"\n","\n","    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8,\n","                 weight_decay=0):\n","        defaults = dict(lr=lr, betas=betas, eps=eps,\n","                        weight_decay=weight_decay)\n","        super(AdamW, self).__init__(params, defaults)\n","\n","    def step(self, closure=None):\n","        \"\"\"Performs a single optimization step.\n","\n","        Arguments:\n","            closure (callable, optional): A closure that reevaluates the model\n","                and returns the loss.\n","        \"\"\"\n","        loss = None\n","        if closure is not None:\n","            loss = closure()\n","\n","        for group in self.param_groups:\n","            for p in group['params']:\n","                if p.grad is None:\n","                    continue\n","                grad = p.grad.data\n","                if grad.is_sparse:\n","                    raise RuntimeError('AdamW does not support sparse gradients, please consider SparseAdam instead')\n","\n","                state = self.state[p]\n","\n","                # State initialization\n","                if len(state) == 0:\n","                    state['step'] = 0\n","                    # Exponential moving average of gradient values\n","                    state['exp_avg'] = torch.zeros_like(p.data)\n","                    # Exponential moving average of squared gradient values\n","                    state['exp_avg_sq'] = torch.zeros_like(p.data)\n","\n","                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n","                beta1, beta2 = group['betas']\n","\n","                state['step'] += 1\n","\n","                # according to the paper, this penalty should come after the bias correction\n","                # if group['weight_decay'] != 0:\n","                #     grad = grad.add(group['weight_decay'], p.data)\n","\n","                # Decay the first and second moment running average coefficient\n","                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n","                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n","\n","                denom = exp_avg_sq.sqrt().add_(group['eps'])\n","\n","                bias_correction1 = 1 - beta1 ** state['step']\n","                bias_correction2 = 1 - beta2 ** state['step']\n","                step_size = group['lr'] * math.sqrt(bias_correction2) / bias_correction1\n","\n","                # w = w - wd * lr * w\n","                if group['weight_decay'] != 0:\n","                    p.data.add_(-group['weight_decay'] * group['lr'], p.data)\n","\n","                # w = w - lr * w.grad\n","                p.data.addcdiv_(-step_size, exp_avg, denom)\n","\n","                # w = w - wd * lr * w - lr * w.grad\n","                # See http://www.fast.ai/2018/07/02/adam-weight-decay/\n","\n","        return loss"]},{"cell_type":"markdown","metadata":{"id":"pTW3yt84TQMf"},"source":["## Losses"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"MR5-L7m_SCwH","executionInfo":{"status":"ok","timestamp":1685488248855,"user_tz":180,"elapsed":6,"user":{"displayName":"Antonio Santos","userId":"03265893617080544823"}}},"outputs":[],"source":["import numpy as np\n","import torch\n","import torch.nn.functional as F\n","from torch import nn\n","from torch.autograd import Variable\n","\n","try:\n","    from itertools import ifilterfalse\n","except ImportError:  # py3k\n","    from itertools import filterfalse\n","\n","eps = 1e-6\n","\n","def dice_round(preds, trues):\n","    preds = preds.float()\n","    return soft_dice_loss(preds, trues)\n","\n","\n","def iou_round(preds, trues):\n","    preds = preds.float()\n","    return jaccard(preds, trues)\n","\n","\n","def soft_dice_loss(outputs, targets, per_image=False):\n","    batch_size = outputs.size()[0]\n","    if not per_image:\n","        batch_size = 1\n","    dice_target = targets.contiguous().view(batch_size, -1).float()\n","    dice_output = outputs.contiguous().view(batch_size, -1)\n","    intersection = torch.sum(dice_output * dice_target, dim=1)\n","    union = torch.sum(dice_output, dim=1) + torch.sum(dice_target, dim=1) + eps\n","    loss = (1 - (2 * intersection + eps) / union).mean()\n","    return loss\n","\n","\n","def jaccard(outputs, targets, per_image=False):\n","    batch_size = outputs.size()[0]\n","    if not per_image:\n","        batch_size = 1\n","    dice_target = targets.contiguous().view(batch_size, -1).float()\n","    dice_output = outputs.contiguous().view(batch_size, -1)\n","    intersection = torch.sum(dice_output * dice_target, dim=1)\n","    union = torch.sum(dice_output, dim=1) + torch.sum(dice_target, dim=1) - intersection + eps\n","    losses = 1 - (intersection + eps) / union\n","    return losses.mean()\n","\n","\n","class DiceLoss(nn.Module):\n","    def __init__(self, weight=None, size_average=True, per_image=False):\n","        super().__init__()\n","        self.size_average = size_average\n","        self.register_buffer('weight', weight)\n","        self.per_image = per_image\n","\n","    def forward(self, input, target):\n","        return soft_dice_loss(input, target, per_image=self.per_image)\n","\n","\n","class JaccardLoss(nn.Module):\n","    def __init__(self, weight=None, size_average=True, per_image=False):\n","        super().__init__()\n","        self.size_average = size_average\n","        self.register_buffer('weight', weight)\n","        self.per_image = per_image\n","\n","    def forward(self, input, target):\n","        return jaccard(input, target, per_image=self.per_image)\n","\n","\n","class StableBCELoss(nn.Module):\n","    def __init__(self):\n","        super(StableBCELoss, self).__init__()\n","\n","    def forward(self, input, target):\n","        input = input.float().view(-1)\n","        target = target.float().view(-1)\n","        neg_abs = - input.abs()\n","        # todo check correctness\n","        loss = input.clamp(min=0) - input * target + (1 + neg_abs.exp()).log()\n","        return loss.mean()\n","\n","\n","class ComboLoss(nn.Module):\n","    def __init__(self, weights, per_image=False):\n","        super().__init__()\n","        self.weights = weights\n","        self.bce = StableBCELoss()\n","        self.dice = DiceLoss(per_image=False)\n","        self.jaccard = JaccardLoss(per_image=False)\n","        self.lovasz = LovaszLoss(per_image=per_image)\n","        self.lovasz_sigmoid = LovaszLossSigmoid(per_image=per_image)\n","        self.focal = FocalLoss2d()\n","        self.mapping = {'bce': self.bce,\n","                        'dice': self.dice,\n","                        'focal': self.focal,\n","                        'jaccard': self.jaccard,\n","                        'lovasz': self.lovasz,\n","                        'lovasz_sigmoid': self.lovasz_sigmoid}\n","        self.expect_sigmoid = {'dice', 'focal', 'jaccard', 'lovasz_sigmoid'}\n","        self.values = {}\n","\n","    def forward(self, outputs, targets):\n","        loss = 0\n","        weights = self.weights\n","        sigmoid_input = torch.sigmoid(outputs)\n","        for k, v in weights.items():\n","            if not v:\n","                continue\n","            val = self.mapping[k](sigmoid_input if k in self.expect_sigmoid else outputs, targets)\n","            self.values[k] = val\n","            loss += self.weights[k] * val\n","        return loss\n","\n","\n","def lovasz_grad(gt_sorted):\n","    \"\"\"\n","    Computes gradient of the Lovasz extension w.r.t sorted errors\n","    See Alg. 1 in paper\n","    \"\"\"\n","    p = len(gt_sorted)\n","    gts = gt_sorted.sum()\n","    intersection = gts.float() - gt_sorted.float().cumsum(0)\n","    union = gts.float() + (1 - gt_sorted).float().cumsum(0)\n","    jaccard = 1. - intersection / union\n","    if p > 1:  # cover 1-pixel case\n","        jaccard[1:p] = jaccard[1:p] - jaccard[0:-1]\n","    return jaccard\n","\n","\n","def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n","    \"\"\"\n","    Binary Lovasz hinge loss\n","      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n","      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n","      per_image: compute the loss per image instead of per batch\n","      ignore: void class id\n","    \"\"\"\n","    if per_image:\n","        loss = mean(lovasz_hinge_flat(*flatten_binary_scores(log.unsqueeze(0), lab.unsqueeze(0), ignore))\n","                    for log, lab in zip(logits, labels))\n","    else:\n","        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n","    return loss\n","\n","\n","def lovasz_hinge_flat(logits, labels):\n","    \"\"\"\n","    Binary Lovasz hinge loss\n","      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n","      labels: [P] Tensor, binary ground truth labels (0 or 1)\n","      ignore: label to ignore\n","    \"\"\"\n","    if len(labels) == 0:\n","        # only void pixels, the gradients should be 0\n","        return logits.sum() * 0.\n","    signs = 2. * labels.float() - 1.\n","    errors = (1. - logits * Variable(signs))\n","    errors_sorted, perm = torch.sort(errors, dim=0, descending=True)\n","    perm = perm.data\n","    gt_sorted = labels[perm]\n","    grad = lovasz_grad(gt_sorted)\n","    loss = torch.dot(F.relu(errors_sorted), Variable(grad))\n","    return loss\n","\n","\n","def flatten_binary_scores(scores, labels, ignore=None):\n","    \"\"\"\n","    Flattens predictions in the batch (binary case)\n","    Remove labels equal to 'ignore'\n","    \"\"\"\n","    scores = scores.view(-1)\n","    labels = labels.view(-1)\n","    if ignore is None:\n","        return scores, labels\n","    valid = (labels != ignore)\n","    vscores = scores[valid]\n","    vlabels = labels[valid]\n","    return vscores, vlabels\n","\n","\n","def lovasz_sigmoid(probas, labels, per_image=False, ignore=None):\n","    \"\"\"\n","    Multi-class Lovasz-Softmax loss\n","      probas: [B, C, H, W] Variable, class probabilities at each prediction (between 0 and 1)\n","      labels: [B, H, W] Tensor, ground truth labels (between 0 and C - 1)\n","      only_present: average only on classes present in ground truth\n","      per_image: compute the loss per image instead of per batch\n","      ignore: void class labels\n","    \"\"\"\n","    if per_image:\n","        loss = mean(lovasz_sigmoid_flat(*flatten_binary_scores(prob.unsqueeze(0), lab.unsqueeze(0), ignore))\n","                          for prob, lab in zip(probas, labels))\n","    else:\n","        loss = lovasz_sigmoid_flat(*flatten_binary_scores(probas, labels, ignore))\n","    return loss\n","\n","\n","def lovasz_sigmoid_flat(probas, labels):\n","    \"\"\"\n","    Multi-class Lovasz-Softmax loss\n","      probas: [P, C] Variable, class probabilities at each prediction (between 0 and 1)\n","      labels: [P] Tensor, ground truth labels (between 0 and C - 1)\n","      only_present: average only on classes present in ground truth\n","    \"\"\"\n","    fg = labels.float()\n","    errors = (Variable(fg) - probas).abs()\n","    errors_sorted, perm = torch.sort(errors, 0, descending=True)\n","    perm = perm.data\n","    fg_sorted = fg[perm]\n","    loss = torch.dot(errors_sorted, Variable(lovasz_grad(fg_sorted)))\n","    return loss\n","\n","\n","def mean(l, ignore_nan=False, empty=0):\n","    \"\"\"\n","    nanmean compatible with generators.\n","    \"\"\"\n","    l = iter(l)\n","    if ignore_nan:\n","        l = ifilterfalse(np.isnan, l)\n","    try:\n","        n = 1\n","        acc = next(l)\n","    except StopIteration:\n","        if empty == 'raise':\n","            raise ValueError('Empty mean')\n","        return empty\n","    for n, v in enumerate(l, 2):\n","        acc += v\n","    if n == 1:\n","        return acc\n","    return acc / n\n","\n","\n","class LovaszLoss(nn.Module):\n","    def __init__(self, ignore_index=255, per_image=True):\n","        super().__init__()\n","        self.ignore_index = ignore_index\n","        self.per_image = per_image\n","\n","    def forward(self, outputs, targets):\n","        outputs = outputs.contiguous()\n","        targets = targets.contiguous()\n","        return lovasz_hinge(outputs, targets, per_image=self.per_image, ignore=self.ignore_index)\n","\n","\n","class LovaszLossSigmoid(nn.Module):\n","    def __init__(self, ignore_index=255, per_image=True):\n","        super().__init__()\n","        self.ignore_index = ignore_index\n","        self.per_image = per_image\n","\n","    def forward(self, outputs, targets):\n","        outputs = outputs.contiguous()\n","        targets = targets.contiguous()\n","        return lovasz_sigmoid(outputs, targets, per_image=self.per_image, ignore=self.ignore_index)\n","\n","\n","class FocalLoss2d(nn.Module):\n","    def __init__(self, gamma=2, ignore_index=255):\n","        super().__init__()\n","        self.gamma = gamma\n","        self.ignore_index = ignore_index\n","\n","    def forward(self, outputs, targets):\n","        outputs = outputs.contiguous()\n","        targets = targets.contiguous()\n","        # eps = 1e-8\n","        non_ignored = targets.view(-1) != self.ignore_index\n","        targets = targets.view(-1)[non_ignored].float()\n","        outputs = outputs.contiguous().view(-1)[non_ignored]\n","        outputs = torch.clamp(outputs, eps, 1. - eps)\n","        targets = torch.clamp(targets, eps, 1. - eps)\n","        pt = (1 - targets) * (1 - outputs) + targets * outputs\n","        return (-(1. - pt) ** self.gamma * torch.log(pt)).mean()"]},{"cell_type":"markdown","metadata":{"id":"N5xl5qEyTN3v"},"source":["## Models"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":895454,"status":"ok","timestamp":1685409388850,"user":{"displayName":"Antonio Santos","userId":"03265893617080544823"},"user_tz":180},"id":"pDuOd5udSNOd","outputId":"31f5c395-b5cd-4638-d796-4dc9d04eb136"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading: \"http://data.lip6.fr/cadene/pretrainedmodels/dpn131-71dfe43e0.pth\" to /root/.cache/torch/hub/checkpoints/dpn131-71dfe43e0.pth\n","100%|██████████| 303M/303M [14:53<00:00, 356kB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Sequential(\n","  (conv1_1): InputBlock(\n","    (conv): Conv2d(3, 128, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    (act): ReLU(inplace=True)\n","    (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  )\n","  (conv2_1): DualPathBlock(\n","    (c1x1_w_s1): BnActConv2d(\n","      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(128, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(128, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(160, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv2_2): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(304, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(160, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv2_3): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(320, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(160, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv2_4): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(336, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(160, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv3_1): DualPathBlock(\n","    (c1x1_w_s2): BnActConv2d(\n","      (bn): BatchNorm2d(352, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(352, 576, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","    )\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(352, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(352, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(320, 544, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv3_2): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(608, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(608, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(320, 544, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv3_3): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(320, 544, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv3_4): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(672, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(320, 544, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv3_5): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(704, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(704, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(320, 544, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv3_6): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(736, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(736, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(320, 544, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv3_7): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(768, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(320, 544, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv3_8): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(800, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(800, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(320, 544, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv4_1): DualPathBlock(\n","    (c1x1_w_s2): BnActConv2d(\n","      (bn): BatchNorm2d(832, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(832, 1088, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","    )\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(832, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(832, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv4_2): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(1120, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1120, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv4_3): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1152, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv4_4): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(1184, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1184, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv4_5): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(1216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1216, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv4_6): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(1248, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1248, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv4_7): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv4_8): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(1312, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1312, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv4_9): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1344, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv4_10): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(1376, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1376, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv4_11): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(1408, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1408, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv4_12): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(1440, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1440, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv4_13): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(1472, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1472, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv4_14): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(1504, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1504, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv4_15): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1536, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv4_16): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(1568, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1568, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv4_17): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(1600, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1600, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv4_18): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1632, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv4_19): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(1664, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1664, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv4_20): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(1696, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1696, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv4_21): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(1728, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1728, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv4_22): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(1760, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1760, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv4_23): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(1792, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1792, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv4_24): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1824, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv4_25): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(1856, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1856, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv4_26): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(1888, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1888, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv4_27): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(1920, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv4_28): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(1952, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1952, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(640, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv5_1): DualPathBlock(\n","    (c1x1_w_s2): BnActConv2d(\n","      (bn): BatchNorm2d(1984, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1984, 2304, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","    )\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(1984, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1984, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1280, 2176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv5_2): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(2432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(2432, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1280, 2176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv5_3): DualPathBlock(\n","    (c1x1_a): BnActConv2d(\n","      (bn): BatchNorm2d(2560, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (c3x3_b): BnActConv2d(\n","      (bn): BatchNorm2d(1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","    )\n","    (c1x1_c): BnActConv2d(\n","      (bn): BatchNorm2d(1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv): Conv2d(1280, 2176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv5_bn_ac): CatBnAct(\n","    (bn): BatchNorm2d(2688, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    (act): ReLU(inplace=True)\n","  )\n",") 45\n","DualPathBlock(\n","  (c1x1_a): BnActConv2d(\n","    (bn): BatchNorm2d(304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    (act): ReLU(inplace=True)\n","    (conv): Conv2d(304, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","  )\n","  (c3x3_b): BnActConv2d(\n","    (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    (act): ReLU(inplace=True)\n","    (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n","  )\n","  (c1x1_c): BnActConv2d(\n","    (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    (act): ReLU(inplace=True)\n","    (conv): Conv2d(160, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","  )\n",")\n"]}],"source":["\"\"\" PyTorch implementation of DualPathNetworks\n","Ported to PyTorch by [Ross Wightman](https://github.com/rwightman/pytorch-dpn-pretrained)\n","\n","Based on original MXNet implementation https://github.com/cypw/DPNs with\n","many ideas from another PyTorch implementation https://github.com/oyam/pytorch-DPNs.\n","\n","This implementation is compatible with the pretrained weights\n","from cypw's MXNet implementation.\n","\"\"\"\n","import os\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.utils.model_zoo as model_zoo\n","from collections import OrderedDict\n","\n","__all__ = ['DPN', 'dpn68', 'dpn68b', 'dpn92', 'dpn98', 'dpn131', 'dpn107']\n","\n","pretrained_settings = {\n","    'dpn68': {\n","        'imagenet': {\n","            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/dpn68-66bebafa7.pth',\n","            'input_space': 'RGB',\n","            'input_size': [3, 224, 224],\n","            'input_range': [0, 1],\n","            'mean': [124 / 255, 117 / 255, 104 / 255],\n","            'std': [1 / (.0167 * 255)] * 3,\n","            'num_classes': 1000\n","        }\n","    },\n","    'dpn68b': {\n","        'imagenet+5k': {\n","            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/dpn68b_extra-84854c156.pth',\n","            'input_space': 'RGB',\n","            'input_size': [3, 224, 224],\n","            'input_range': [0, 1],\n","            'mean': [124 / 255, 117 / 255, 104 / 255],\n","            'std': [1 / (.0167 * 255)] * 3,\n","            'num_classes': 1000\n","        }\n","    },\n","    'dpn92': {\n","        # 'imagenet': {\n","        #     'url': 'http://data.lip6.fr/cadene/pretrainedmodels/dpn68-66bebafa7.pth',\n","        #     'input_space': 'RGB',\n","        #     'input_size': [3, 224, 224],\n","        #     'input_range': [0, 1],\n","        #     'mean': [124 / 255, 117 / 255, 104 / 255],\n","        #     'std': [1 / (.0167 * 255)] * 3,\n","        #     'num_classes': 1000\n","        # },\n","        'imagenet+5k': {\n","            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/dpn92_extra-b040e4a9b.pth',\n","            'input_space': 'RGB',\n","            'input_size': [3, 224, 224],\n","            'input_range': [0, 1],\n","            'mean': [124 / 255, 117 / 255, 104 / 255],\n","            'std': [1 / (.0167 * 255)] * 3,\n","            'num_classes': 1000\n","        }\n","    },\n","    'dpn98': {\n","        'imagenet': {\n","            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/dpn98-5b90dec4d.pth',\n","            'input_space': 'RGB',\n","            'input_size': [3, 224, 224],\n","            'input_range': [0, 1],\n","            'mean': [124 / 255, 117 / 255, 104 / 255],\n","            'std': [1 / (.0167 * 255)] * 3,\n","            'num_classes': 1000\n","        }\n","    },\n","    'dpn131': {\n","        'imagenet': {\n","            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/dpn131-71dfe43e0.pth',\n","            'input_space': 'RGB',\n","            'input_size': [3, 224, 224],\n","            'input_range': [0, 1],\n","            'mean': [124 / 255, 117 / 255, 104 / 255],\n","            'std': [1 / (.0167 * 255)] * 3,\n","            'num_classes': 1000\n","        }\n","    },\n","    'dpn107': {\n","        'imagenet+5k': {\n","            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/dpn107_extra-1ac7121e2.pth',\n","            'input_space': 'RGB',\n","            'input_size': [3, 224, 224],\n","            'input_range': [0, 1],\n","            'mean': [124 / 255, 117 / 255, 104 / 255],\n","            'std': [1 / (.0167 * 255)] * 3,\n","            'num_classes': 1000\n","        }\n","    }\n","}\n","\n","def dpn68(num_classes=1000, pretrained='imagenet'):\n","    model = DPN(\n","        small=True, num_init_features=10, k_r=128, groups=32,\n","        k_sec=(3, 4, 12, 3), inc_sec=(16, 32, 32, 64),\n","        num_classes=num_classes, test_time_pool=True)\n","    if pretrained:\n","        settings = pretrained_settings['dpn68'][pretrained]\n","        assert num_classes == settings['num_classes'], \\\n","            \"num_classes should be {}, but is {}\".format(settings['num_classes'], num_classes)\n","\n","        model.load_state_dict(model_zoo.load_url(settings['url']))\n","        model.input_space = settings['input_space']\n","        model.input_size = settings['input_size']\n","        model.input_range = settings['input_range']\n","        model.mean = settings['mean']\n","        model.std = settings['std']\n","    return model\n","\n","def dpn68b(num_classes=1000, pretrained='imagenet+5k'):\n","    model = DPN(\n","        small=True, num_init_features=10, k_r=128, groups=32,\n","        b=True, k_sec=(3, 4, 12, 3), inc_sec=(16, 32, 32, 64),\n","        num_classes=num_classes, test_time_pool=True)\n","    if pretrained:\n","        settings = pretrained_settings['dpn68b'][pretrained]\n","        assert num_classes == settings['num_classes'], \\\n","            \"num_classes should be {}, but is {}\".format(settings['num_classes'], num_classes)\n","\n","        model.load_state_dict(model_zoo.load_url(settings['url']))\n","        model.input_space = settings['input_space']\n","        model.input_size = settings['input_size']\n","        model.input_range = settings['input_range']\n","        model.mean = settings['mean']\n","        model.std = settings['std']\n","    return model\n","\n","def dpn92(num_classes=1000, pretrained='imagenet+5k'):\n","    model = DPN(\n","        num_init_features=64, k_r=96, groups=32,\n","        k_sec=(3, 4, 20, 3), inc_sec=(16, 32, 24, 128),\n","        num_classes=num_classes, test_time_pool=True)\n","    if pretrained:\n","        settings = pretrained_settings['dpn92'][pretrained]\n","        assert num_classes == settings['num_classes'], \\\n","            \"num_classes should be {}, but is {}\".format(settings['num_classes'], num_classes)\n","\n","        model.load_state_dict(model_zoo.load_url(settings['url']))\n","        model.input_space = settings['input_space']\n","        model.input_size = settings['input_size']\n","        model.input_range = settings['input_range']\n","        model.mean = settings['mean']\n","        model.std = settings['std']\n","    return model\n","\n","def dpn98(num_classes=1000, pretrained='imagenet'):\n","    model = DPN(\n","        num_init_features=96, k_r=160, groups=40,\n","        k_sec=(3, 6, 20, 3), inc_sec=(16, 32, 32, 128),\n","        num_classes=num_classes, test_time_pool=True)\n","    if pretrained:\n","        settings = pretrained_settings['dpn98'][pretrained]\n","        assert num_classes == settings['num_classes'], \\\n","            \"num_classes should be {}, but is {}\".format(settings['num_classes'], num_classes)\n","\n","        model.load_state_dict(model_zoo.load_url(settings['url']))\n","        model.input_space = settings['input_space']\n","        model.input_size = settings['input_size']\n","        model.input_range = settings['input_range']\n","        model.mean = settings['mean']\n","        model.std = settings['std']\n","    return model\n","\n","def dpn131(num_classes=1000, pretrained='imagenet'):\n","    model = DPN(\n","        num_init_features=128, k_r=160, groups=40,\n","        k_sec=(4, 8, 28, 3), inc_sec=(16, 32, 32, 128),\n","        num_classes=num_classes, test_time_pool=True)\n","    if pretrained:\n","        settings = pretrained_settings['dpn131'][pretrained]\n","        assert num_classes == settings['num_classes'], \\\n","            \"num_classes should be {}, but is {}\".format(settings['num_classes'], num_classes)\n","\n","        model.load_state_dict(model_zoo.load_url(settings['url']))\n","        model.input_space = settings['input_space']\n","        model.input_size = settings['input_size']\n","        model.input_range = settings['input_range']\n","        model.mean = settings['mean']\n","        model.std = settings['std']\n","    return model\n","\n","def dpn107(num_classes=1000, pretrained='imagenet+5k'):\n","    model = DPN(\n","        num_init_features=128, k_r=200, groups=50,\n","        k_sec=(4, 8, 20, 3), inc_sec=(20, 64, 64, 128),\n","        num_classes=num_classes, test_time_pool=True)\n","    if pretrained:\n","        settings = pretrained_settings['dpn107'][pretrained]\n","        assert num_classes == settings['num_classes'], \\\n","            \"num_classes should be {}, but is {}\".format(settings['num_classes'], num_classes)\n","\n","        model.load_state_dict(model_zoo.load_url(settings['url']))\n","        model.input_space = settings['input_space']\n","        model.input_size = settings['input_size']\n","        model.input_range = settings['input_range']\n","        model.mean = settings['mean']\n","        model.std = settings['std']\n","    return model\n","\n","\n","class CatBnAct(nn.Module):\n","    def __init__(self, in_chs, activation_fn=nn.ReLU(inplace=True)):\n","        super(CatBnAct, self).__init__()\n","        self.bn = nn.BatchNorm2d(in_chs, eps=0.001)\n","        self.act = activation_fn\n","\n","    def forward(self, x):\n","        x = torch.cat(x, dim=1) if isinstance(x, tuple) else x\n","        return self.act(self.bn(x))\n","\n","\n","class BnActConv2d(nn.Module):\n","    def __init__(self, in_chs, out_chs, kernel_size, stride,\n","                 padding=0, groups=1, activation_fn=nn.ReLU(inplace=True)):\n","        super(BnActConv2d, self).__init__()\n","        self.bn = nn.BatchNorm2d(in_chs, eps=0.001)\n","        self.act = activation_fn\n","        self.conv = nn.Conv2d(in_chs, out_chs, kernel_size, stride, padding, groups=groups, bias=False)\n","\n","    def forward(self, x):\n","        return self.conv(self.act(self.bn(x)))\n","\n","\n","class InputBlock(nn.Module):\n","    def __init__(self, num_init_features, kernel_size=7,\n","                 padding=3, activation_fn=nn.ReLU(inplace=True)):\n","        super(InputBlock, self).__init__()\n","        self.conv = nn.Conv2d(\n","            3, num_init_features, kernel_size=kernel_size, stride=2, padding=padding, bias=False)\n","        self.bn = nn.BatchNorm2d(num_init_features, eps=0.001)\n","        self.act = activation_fn\n","        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","\n","    def forward(self, x):\n","        x = self.conv(x)\n","        x = self.bn(x)\n","        x = self.act(x)\n","        x = self.pool(x)\n","        return x\n","\n","\n","class DualPathBlock(nn.Module):\n","    def __init__(\n","            self, in_chs, num_1x1_a, num_3x3_b, num_1x1_c, inc, groups, block_type='normal', b=False):\n","        super(DualPathBlock, self).__init__()\n","        self.num_1x1_c = num_1x1_c\n","        self.inc = inc\n","        self.b = b\n","        if block_type == 'proj':\n","            self.key_stride = 1\n","            self.has_proj = True\n","        elif block_type == 'down':\n","            self.key_stride = 2\n","            self.has_proj = True\n","        else:\n","            assert block_type == 'normal'\n","            self.key_stride = 1\n","            self.has_proj = False\n","\n","        if self.has_proj:\n","            # Using different member names here to allow easier parameter key matching for conversion\n","            if self.key_stride == 2:\n","                self.c1x1_w_s2 = BnActConv2d(\n","                    in_chs=in_chs, out_chs=num_1x1_c + 2 * inc, kernel_size=1, stride=2)\n","            else:\n","                self.c1x1_w_s1 = BnActConv2d(\n","                    in_chs=in_chs, out_chs=num_1x1_c + 2 * inc, kernel_size=1, stride=1)\n","        self.c1x1_a = BnActConv2d(in_chs=in_chs, out_chs=num_1x1_a, kernel_size=1, stride=1)\n","        self.c3x3_b = BnActConv2d(\n","            in_chs=num_1x1_a, out_chs=num_3x3_b, kernel_size=3,\n","            stride=self.key_stride, padding=1, groups=groups)\n","        if b:\n","            self.c1x1_c = CatBnAct(in_chs=num_3x3_b)\n","            self.c1x1_c1 = nn.Conv2d(num_3x3_b, num_1x1_c, kernel_size=1, bias=False)\n","            self.c1x1_c2 = nn.Conv2d(num_3x3_b, inc, kernel_size=1, bias=False)\n","        else:\n","            self.c1x1_c = BnActConv2d(in_chs=num_3x3_b, out_chs=num_1x1_c + inc, kernel_size=1, stride=1)\n","\n","    def forward(self, x):\n","        x_in = torch.cat(x, dim=1) if isinstance(x, tuple) else x\n","        if self.has_proj:\n","            if self.key_stride == 2:\n","                x_s = self.c1x1_w_s2(x_in)\n","            else:\n","                x_s = self.c1x1_w_s1(x_in)\n","            x_s1 = x_s[:, :self.num_1x1_c, :, :]\n","            x_s2 = x_s[:, self.num_1x1_c:, :, :]\n","        else:\n","            x_s1 = x[0]\n","            x_s2 = x[1]\n","        x_in = self.c1x1_a(x_in)\n","        x_in = self.c3x3_b(x_in)\n","        if self.b:\n","            x_in = self.c1x1_c(x_in)\n","            out1 = self.c1x1_c1(x_in)\n","            out2 = self.c1x1_c2(x_in)\n","        else:\n","            x_in = self.c1x1_c(x_in)\n","            out1 = x_in[:, :self.num_1x1_c, :, :]\n","            out2 = x_in[:, self.num_1x1_c:, :, :]\n","        resid = x_s1 + out1\n","        dense = torch.cat([x_s2, out2], dim=1)\n","        return resid, dense\n","\n","\n","class DPN(nn.Module):\n","    def __init__(self, small=False, num_init_features=64, k_r=96, groups=32,\n","                 b=False, k_sec=(3, 4, 20, 3), inc_sec=(16, 32, 24, 128),\n","                 num_classes=1000, test_time_pool=False):\n","        super(DPN, self).__init__()\n","        self.test_time_pool = test_time_pool\n","        self.b = b\n","        bw_factor = 1 if small else 4\n","        self.k_sec = k_sec\n","        self.out_channels = []\n","\n","        self.blocks = OrderedDict()\n","\n","        # conv1\n","        if small:\n","            self.blocks['conv1_1'] = InputBlock(num_init_features, kernel_size=3, padding=1)\n","        else:\n","            self.blocks['conv1_1'] = InputBlock(num_init_features, kernel_size=7, padding=3)\n","\n","        self.out_channels.append(num_init_features)\n","        # conv2\n","        bw = 64 * bw_factor\n","        inc = inc_sec[0]\n","        r = (k_r * bw) // (64 * bw_factor)\n","        self.blocks['conv2_1'] = DualPathBlock(num_init_features, r, r, bw, inc, groups, 'proj', b)\n","        in_chs = bw + 3 * inc\n","        for i in range(2, k_sec[0] + 1):\n","            self.blocks['conv2_' + str(i)] = DualPathBlock(in_chs, r, r, bw, inc, groups, 'normal', b)\n","            in_chs += inc\n","\n","        self.out_channels.append(in_chs)\n","        # conv3\n","        bw = 128 * bw_factor\n","        inc = inc_sec[1]\n","        r = (k_r * bw) // (64 * bw_factor)\n","        self.blocks['conv3_1'] = DualPathBlock(in_chs, r, r, bw, inc, groups, 'down', b)\n","        in_chs = bw + 3 * inc\n","        for i in range(2, k_sec[1] + 1):\n","            self.blocks['conv3_' + str(i)] = DualPathBlock(in_chs, r, r, bw, inc, groups, 'normal', b)\n","            in_chs += inc\n","\n","        self.out_channels.append(in_chs)\n","        # conv4\n","        bw = 256 * bw_factor\n","        inc = inc_sec[2]\n","        r = (k_r * bw) // (64 * bw_factor)\n","        self.blocks['conv4_1'] = DualPathBlock(in_chs, r, r, bw, inc, groups, 'down', b)\n","        in_chs = bw + 3 * inc\n","        for i in range(2, k_sec[2] + 1):\n","            self.blocks['conv4_' + str(i)] = DualPathBlock(in_chs, r, r, bw, inc, groups, 'normal', b)\n","            in_chs += inc\n","\n","        self.out_channels.append(in_chs)\n","        # conv5\n","        bw = 512 * bw_factor\n","        inc = inc_sec[3]\n","        r = (k_r * bw) // (64 * bw_factor)\n","        self.blocks['conv5_1'] = DualPathBlock(in_chs, r, r, bw, inc, groups, 'down', b)\n","        in_chs = bw + 3 * inc\n","        for i in range(2, k_sec[3] + 1):\n","            self.blocks['conv5_' + str(i)] = DualPathBlock(in_chs, r, r, bw, inc, groups, 'normal', b)\n","            in_chs += inc\n","        self.blocks['conv5_bn_ac'] = CatBnAct(in_chs)\n","        self.out_channels.append(in_chs)\n","\n","        self.features = nn.Sequential(self.blocks)\n","\n","        # Using 1x1 conv for the FC layer to allow the extra pooling scheme\n","        self.classifier = nn.Conv2d(in_chs, num_classes, kernel_size=1, bias=True)\n","\n","    def logits(self, features):\n","        if not self.training and self.test_time_pool:\n","            x = F.avg_pool2d(features, kernel_size=7, stride=1)\n","            out = self.classifier(x)\n","            # The extra test time pool should be pooling an img_size//32 - 6 size patch\n","            out = adaptive_avgmax_pool2d(out, pool_type='avgmax')\n","        else:\n","            x = adaptive_avgmax_pool2d(features, pool_type='avg')\n","            out = self.classifier(x)\n","        return out.view(out.size(0), -1)\n","\n","    def forward(self, input):\n","        x = self.features(input)\n","        x = self.logits(x)\n","        return x\n","\n","\"\"\" PyTorch selectable adaptive pooling\n","Adaptive pooling with the ability to select the type of pooling from:\n","    * 'avg' - Average pooling\n","    * 'max' - Max pooling\n","    * 'avgmax' - Sum of average and max pooling re-scaled by 0.5\n","    * 'avgmaxc' - Concatenation of average and max pooling along feature dim, doubles feature dim\n","\n","Both a functional and a nn.Module version of the pooling is provided.\n","\n","Author: Ross Wightman (rwightman)\n","\"\"\"\n","\n","def pooling_factor(pool_type='avg'):\n","    return 2 if pool_type == 'avgmaxc' else 1\n","\n","\n","def adaptive_avgmax_pool2d(x, pool_type='avg', padding=0, count_include_pad=False):\n","    \"\"\"Selectable global pooling function with dynamic input kernel size\n","    \"\"\"\n","    if pool_type == 'avgmaxc':\n","        x = torch.cat([\n","            F.avg_pool2d(\n","                x, kernel_size=(x.size(2), x.size(3)), padding=padding, count_include_pad=count_include_pad),\n","            F.max_pool2d(x, kernel_size=(x.size(2), x.size(3)), padding=padding)\n","        ], dim=1)\n","    elif pool_type == 'avgmax':\n","        x_avg = F.avg_pool2d(\n","                x, kernel_size=(x.size(2), x.size(3)), padding=padding, count_include_pad=count_include_pad)\n","        x_max = F.max_pool2d(x, kernel_size=(x.size(2), x.size(3)), padding=padding)\n","        x = 0.5 * (x_avg + x_max)\n","    elif pool_type == 'max':\n","        x = F.max_pool2d(x, kernel_size=(x.size(2), x.size(3)), padding=padding)\n","    else:\n","        if pool_type != 'avg':\n","            print('Invalid pool type %s specified. Defaulting to average pooling.' % pool_type)\n","        x = F.avg_pool2d(\n","            x, kernel_size=(x.size(2), x.size(3)), padding=padding, count_include_pad=count_include_pad)\n","    return x\n","\n","\n","class AdaptiveAvgMaxPool2d(torch.nn.Module):\n","    \"\"\"Selectable global pooling layer with dynamic input kernel size\n","    \"\"\"\n","    def __init__(self, output_size=1, pool_type='avg'):\n","        super(AdaptiveAvgMaxPool2d, self).__init__()\n","        self.output_size = output_size\n","        self.pool_type = pool_type\n","        if pool_type == 'avgmaxc' or pool_type == 'avgmax':\n","            self.pool = nn.ModuleList([nn.AdaptiveAvgPool2d(output_size), nn.AdaptiveMaxPool2d(output_size)])\n","        elif pool_type == 'max':\n","            self.pool = nn.AdaptiveMaxPool2d(output_size)\n","        else:\n","            if pool_type != 'avg':\n","                print('Invalid pool type %s specified. Defaulting to average pooling.' % pool_type)\n","            self.pool = nn.AdaptiveAvgPool2d(output_size)\n","\n","    def forward(self, x):\n","        if self.pool_type == 'avgmaxc':\n","            x = torch.cat([p(x) for p in self.pool], dim=1)\n","        elif self.pool_type == 'avgmax':\n","            x = 0.5 * torch.sum(torch.stack([p(x) for p in self.pool]), 0).squeeze(dim=0)\n","        else:\n","            x = self.pool(x)\n","        return x\n","\n","    def factor(self):\n","        return pooling_factor(self.pool_type)\n","\n","    def __repr__(self):\n","        return self.__class__.__name__ + ' (' \\\n","               + 'output_size=' + str(self.output_size) \\\n","               + ', pool_type=' + self.pool_type + ')'\n","\n","if __name__ == \"__main__\":\n","    import ssl\n","    ssl._create_default_https_context = ssl._create_unverified_context\n","    model = dpn131()\n","    print(model.features, len(model.features))\n","    print(model.features[2])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":312285,"status":"ok","timestamp":1685409702002,"user":{"displayName":"Antonio Santos","userId":"03265893617080544823"},"user_tz":180},"id":"d1Fm1qEnS6Wm","outputId":"ee498c87-eeed-4c73-d865-f80d6549c170"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading: \"http://data.lip6.fr/cadene/pretrainedmodels/se_resnext50_32x4d-a260b3a4.pth\" to /root/.cache/torch/hub/checkpoints/se_resnext50_32x4d-a260b3a4.pth\n","100%|██████████| 105M/105M [05:10<00:00, 356kB/s]"]},{"name":"stdout","output_type":"stream","text":["SENet(\n","  (pool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n","  (layer0): Sequential(\n","    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu1): ReLU(inplace=True)\n","  )\n","  (layer1): Sequential(\n","    (0): SEResNeXtBottleneck(\n","      (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (se_module): SEModule(\n","        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","        (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n","        (relu): ReLU(inplace=True)\n","        (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n","        (sigmoid): Sigmoid()\n","      )\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): SEResNeXtBottleneck(\n","      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (se_module): SEModule(\n","        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","        (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n","        (relu): ReLU(inplace=True)\n","        (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n","        (sigmoid): Sigmoid()\n","      )\n","    )\n","    (2): SEResNeXtBottleneck(\n","      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (se_module): SEModule(\n","        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","        (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n","        (relu): ReLU(inplace=True)\n","        (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n","        (sigmoid): Sigmoid()\n","      )\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): SEResNeXtBottleneck(\n","      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (se_module): SEModule(\n","        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","        (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n","        (relu): ReLU(inplace=True)\n","        (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n","        (sigmoid): Sigmoid()\n","      )\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): SEResNeXtBottleneck(\n","      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (se_module): SEModule(\n","        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","        (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n","        (relu): ReLU(inplace=True)\n","        (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n","        (sigmoid): Sigmoid()\n","      )\n","    )\n","    (2): SEResNeXtBottleneck(\n","      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (se_module): SEModule(\n","        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","        (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n","        (relu): ReLU(inplace=True)\n","        (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n","        (sigmoid): Sigmoid()\n","      )\n","    )\n","    (3): SEResNeXtBottleneck(\n","      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (se_module): SEModule(\n","        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","        (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n","        (relu): ReLU(inplace=True)\n","        (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n","        (sigmoid): Sigmoid()\n","      )\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): SEResNeXtBottleneck(\n","      (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (se_module): SEModule(\n","        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n","        (relu): ReLU(inplace=True)\n","        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n","        (sigmoid): Sigmoid()\n","      )\n","      (downsample): Sequential(\n","        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): SEResNeXtBottleneck(\n","      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (se_module): SEModule(\n","        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n","        (relu): ReLU(inplace=True)\n","        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n","        (sigmoid): Sigmoid()\n","      )\n","    )\n","    (2): SEResNeXtBottleneck(\n","      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (se_module): SEModule(\n","        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n","        (relu): ReLU(inplace=True)\n","        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n","        (sigmoid): Sigmoid()\n","      )\n","    )\n","    (3): SEResNeXtBottleneck(\n","      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (se_module): SEModule(\n","        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n","        (relu): ReLU(inplace=True)\n","        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n","        (sigmoid): Sigmoid()\n","      )\n","    )\n","    (4): SEResNeXtBottleneck(\n","      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (se_module): SEModule(\n","        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n","        (relu): ReLU(inplace=True)\n","        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n","        (sigmoid): Sigmoid()\n","      )\n","    )\n","    (5): SEResNeXtBottleneck(\n","      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (se_module): SEModule(\n","        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n","        (relu): ReLU(inplace=True)\n","        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n","        (sigmoid): Sigmoid()\n","      )\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): SEResNeXtBottleneck(\n","      (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n","      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (se_module): SEModule(\n","        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","        (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n","        (relu): ReLU(inplace=True)\n","        (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n","        (sigmoid): Sigmoid()\n","      )\n","      (downsample): Sequential(\n","        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): SEResNeXtBottleneck(\n","      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (se_module): SEModule(\n","        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","        (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n","        (relu): ReLU(inplace=True)\n","        (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n","        (sigmoid): Sigmoid()\n","      )\n","    )\n","    (2): SEResNeXtBottleneck(\n","      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (se_module): SEModule(\n","        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","        (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n","        (relu): ReLU(inplace=True)\n","        (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n","        (sigmoid): Sigmoid()\n","      )\n","    )\n","  )\n","  (avg_pool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n","  (last_linear): Linear(in_features=2048, out_features=1000, bias=True)\n",")\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["\"\"\"\n","ResNet code gently borrowed from\n","https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py\n","\"\"\"\n","\n","from collections import OrderedDict\n","import math\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils import model_zoo\n","\n","__all__ = ['SENet', 'senet154', 'se_resnet50', 'se_resnet101', 'se_resnet152',\n","           'se_resnext50_32x4d', 'se_resnext101_32x4d']\n","\n","pretrained_settings = {\n","    'senet154': {\n","        'imagenet': {\n","            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/senet154-c7b49a05.pth',\n","            'input_space': 'RGB',\n","            'input_size': [3, 224, 224],\n","            'input_range': [0, 1],\n","            'mean': [0.485, 0.456, 0.406],\n","            'std': [0.229, 0.224, 0.225],\n","            'num_classes': 1000\n","        }\n","    },\n","    'se_resnet50': {\n","        'imagenet': {\n","            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnet50-ce0d4300.pth',\n","            'input_space': 'RGB',\n","            'input_size': [3, 224, 224],\n","            'input_range': [0, 1],\n","            'mean': [0.485, 0.456, 0.406],\n","            'std': [0.229, 0.224, 0.225],\n","            'num_classes': 1000\n","        }\n","    },\n","    'se_resnet101': {\n","        'imagenet': {\n","            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnet101-7e38fcc6.pth',\n","            'input_space': 'RGB',\n","            'input_size': [3, 224, 224],\n","            'input_range': [0, 1],\n","            'mean': [0.485, 0.456, 0.406],\n","            'std': [0.229, 0.224, 0.225],\n","            'num_classes': 1000\n","        }\n","    },\n","    'se_resnet152': {\n","        'imagenet': {\n","            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnet152-d17c99b7.pth',\n","            'input_space': 'RGB',\n","            'input_size': [3, 224, 224],\n","            'input_range': [0, 1],\n","            'mean': [0.485, 0.456, 0.406],\n","            'std': [0.229, 0.224, 0.225],\n","            'num_classes': 1000\n","        }\n","    },\n","    'se_resnext50_32x4d': {\n","        'imagenet': {\n","            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnext50_32x4d-a260b3a4.pth',\n","            'input_space': 'RGB',\n","            'input_size': [3, 224, 224],\n","            'input_range': [0, 1],\n","            'mean': [0.485, 0.456, 0.406],\n","            'std': [0.229, 0.224, 0.225],\n","            'num_classes': 1000\n","        }\n","    },\n","    'se_resnext101_32x4d': {\n","        'imagenet': {\n","            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnext101_32x4d-3b2fe3d8.pth',\n","            'input_space': 'RGB',\n","            'input_size': [3, 224, 224],\n","            'input_range': [0, 1],\n","            'mean': [0.485, 0.456, 0.406],\n","            'std': [0.229, 0.224, 0.225],\n","            'num_classes': 1000\n","        }\n","    },\n","}\n","\n","\n","class SEModule(nn.Module):\n","\n","    def __init__(self, channels, reduction, concat=False):\n","        super(SEModule, self).__init__()\n","        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n","        self.fc1 = nn.Conv2d(channels, channels // reduction, kernel_size=1,\n","                             padding=0)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.fc2 = nn.Conv2d(channels // reduction, channels, kernel_size=1,\n","                             padding=0)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        module_input = x\n","        x = self.avg_pool(x)\n","        x = self.fc1(x)\n","        x = self.relu(x)\n","        x = self.fc2(x)\n","        x = self.sigmoid(x)\n","        return module_input * x\n","\n","class SCSEModule(nn.Module):\n","    # according to https://arxiv.org/pdf/1808.08127.pdf concat is better\n","    def __init__(self, channels, reduction=16, concat=False):\n","        super(SCSEModule, self).__init__()\n","        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n","        self.fc1 = nn.Conv2d(channels, channels // reduction, kernel_size=1,\n","                             padding=0)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.fc2 = nn.Conv2d(channels // reduction, channels, kernel_size=1,\n","                             padding=0)\n","        self.sigmoid = nn.Sigmoid()\n","\n","        self.spatial_se = nn.Sequential(nn.Conv2d(channels, 1, kernel_size=1,\n","                                                  stride=1, padding=0, bias=False),\n","                                        nn.Sigmoid())\n","        self.concat = concat\n","\n","    def forward(self, x):\n","        module_input = x\n","\n","        x = self.avg_pool(x)\n","        x = self.fc1(x)\n","        x = self.relu(x)\n","        x = self.fc2(x)\n","        chn_se = self.sigmoid(x)\n","        chn_se = chn_se * module_input\n","\n","        spa_se = self.spatial_se(module_input)\n","        spa_se = module_input * spa_se\n","        if self.concat:\n","            return torch.cat([chn_se, spa_se], dim=1)\n","        else:\n","            return chn_se + spa_se\n","\n","class Bottleneck(nn.Module):\n","    \"\"\"\n","    Base class for bottlenecks that implements `forward()` method.\n","    \"\"\"\n","    def forward(self, x):\n","        residual = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out = self.relu(out)\n","\n","        out = self.conv3(out)\n","        out = self.bn3(out)\n","\n","        if self.downsample is not None:\n","            residual = self.downsample(x)\n","\n","        out = self.se_module(out) + residual\n","        out = self.relu(out)\n","\n","        return out\n","\n","\n","class SEBottleneck(Bottleneck):\n","    \"\"\"\n","    Bottleneck for SENet154.\n","    \"\"\"\n","    expansion = 4\n","\n","    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n","                 downsample=None):\n","        super(SEBottleneck, self).__init__()\n","        self.conv1 = nn.Conv2d(inplanes, planes * 2, kernel_size=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes * 2)\n","        self.conv2 = nn.Conv2d(planes * 2, planes * 4, kernel_size=3,\n","                               stride=stride, padding=1, groups=groups,\n","                               bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes * 4)\n","        self.conv3 = nn.Conv2d(planes * 4, planes * 4, kernel_size=1,\n","                               bias=False)\n","        self.bn3 = nn.BatchNorm2d(planes * 4)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.se_module = SEModule(planes * 4, reduction=reduction)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","\n","class SCSEBottleneck(Bottleneck):\n","    \"\"\"\n","    Bottleneck for SENet154.\n","    \"\"\"\n","    expansion = 4\n","\n","    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n","                 downsample=None):\n","        super(SCSEBottleneck, self).__init__()\n","        self.conv1 = nn.Conv2d(inplanes, planes * 2, kernel_size=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes * 2)\n","        self.conv2 = nn.Conv2d(planes * 2, planes * 4, kernel_size=3,\n","                               stride=stride, padding=1, groups=groups,\n","                               bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes * 4)\n","        self.conv3 = nn.Conv2d(planes * 4, planes * 4, kernel_size=1,\n","                               bias=False)\n","        self.bn3 = nn.BatchNorm2d(planes * 4)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.se_module = SCSEModule(planes * 4, reduction=reduction)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","\n","class SEResNetBottleneck(Bottleneck):\n","    \"\"\"\n","    ResNet bottleneck with a Squeeze-and-Excitation module. It follows Caffe\n","    implementation and uses `stride=stride` in `conv1` and not in `conv2`\n","    (the latter is used in the torchvision implementation of ResNet).\n","    \"\"\"\n","    expansion = 4\n","\n","    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n","                 downsample=None):\n","        super(SEResNetBottleneck, self).__init__()\n","        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False,\n","                               stride=stride)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, padding=1,\n","                               groups=groups, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(planes * 4)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.se_module = SEModule(planes * 4, reduction=reduction)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","\n","class SEResNeXtBottleneck(Bottleneck):\n","    \"\"\"\n","    ResNeXt bottleneck type C with a Squeeze-and-Excitation module.\n","    \"\"\"\n","    expansion = 4\n","\n","    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n","                 downsample=None, base_width=4):\n","        super(SEResNeXtBottleneck, self).__init__()\n","        width = math.floor(planes * (base_width / 64)) * groups\n","        self.conv1 = nn.Conv2d(inplanes, width, kernel_size=1, bias=False,\n","                               stride=1)\n","        self.bn1 = nn.BatchNorm2d(width)\n","        self.conv2 = nn.Conv2d(width, width, kernel_size=3, stride=stride,\n","                               padding=1, groups=groups, bias=False)\n","        self.bn2 = nn.BatchNorm2d(width)\n","        self.conv3 = nn.Conv2d(width, planes * 4, kernel_size=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(planes * 4)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.se_module = SEModule(planes * 4, reduction=reduction)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","\n","\n","class SCSEResNeXtBottleneck(Bottleneck):\n","    \"\"\"\n","    ResNeXt bottleneck type C with a Concurrent Spatial Squeeze-and-Excitation module.\n","    \"\"\"\n","    expansion = 4\n","\n","    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n","                 downsample=None, base_width=4, final=False):\n","        super(SCSEResNeXtBottleneck, self).__init__()\n","        width = math.floor(planes * (base_width / 64)) * groups\n","        self.conv1 = nn.Conv2d(inplanes, width, kernel_size=1, bias=False,\n","                               stride=1)\n","        self.bn1 = nn.BatchNorm2d(width)\n","        self.conv2 = nn.Conv2d(width, width, kernel_size=3, stride=stride,\n","                               padding=1, groups=groups, bias=False)\n","        self.bn2 = nn.BatchNorm2d(width)\n","        self.conv3 = nn.Conv2d(width, planes * 4, kernel_size=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(planes * 4)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.se_module = SCSEModule(planes * 4, reduction=reduction)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","\n","class SENet(nn.Module):\n","\n","    def __init__(self, block, layers, groups, reduction, dropout_p=0.2,\n","                 inplanes=128, input_3x3=True, downsample_kernel_size=3,\n","                 downsample_padding=1, num_classes=1000):\n","        \"\"\"\n","        Parameters\n","        ----------\n","        block (nn.Module): Bottleneck class.\n","            - For SENet154: SEBottleneck\n","            - For SE-ResNet models: SEResNetBottleneck\n","            - For SE-ResNeXt models:  SEResNeXtBottleneck\n","        layers (list of ints): Number of residual blocks for 4 layers of the\n","            network (layer1...layer4).\n","        groups (int): Number of groups for the 3x3 convolution in each\n","            bottleneck block.\n","            - For SENet154: 64\n","            - For SE-ResNet models: 1\n","            - For SE-ResNeXt models:  32\n","        reduction (int): Reduction ratio for Squeeze-and-Excitation modules.\n","            - For all models: 16\n","        dropout_p (float or None): Drop probability for the Dropout layer.\n","            If `None` the Dropout layer is not used.\n","            - For SENet154: 0.2\n","            - For SE-ResNet models: None\n","            - For SE-ResNeXt models: None\n","        inplanes (int):  Number of input channels for layer1.\n","            - For SENet154: 128\n","            - For SE-ResNet models: 64\n","            - For SE-ResNeXt models: 64\n","        input_3x3 (bool): If `True`, use three 3x3 convolutions instead of\n","            a single 7x7 convolution in layer0.\n","            - For SENet154: True\n","            - For SE-ResNet models: False\n","            - For SE-ResNeXt models: False\n","        downsample_kernel_size (int): Kernel size for downsampling convolutions\n","            in layer2, layer3 and layer4.\n","            - For SENet154: 3\n","            - For SE-ResNet models: 1\n","            - For SE-ResNeXt models: 1\n","        downsample_padding (int): Padding for downsampling convolutions in\n","            layer2, layer3 and layer4.\n","            - For SENet154: 1\n","            - For SE-ResNet models: 0\n","            - For SE-ResNeXt models: 0\n","        num_classes (int): Number of outputs in `last_linear` layer.\n","            - For all models: 1000\n","        \"\"\"\n","        super(SENet, self).__init__()\n","        self.inplanes = inplanes\n","        if input_3x3:\n","            layer0_modules = [\n","                ('conv1', nn.Conv2d(3, 64, 3, stride=2, padding=1,\n","                                    bias=False)),\n","                ('bn1', nn.BatchNorm2d(64)),\n","                ('relu1', nn.ReLU(inplace=True)),\n","                ('conv2', nn.Conv2d(64, 64, 3, stride=1, padding=1,\n","                                    bias=False)),\n","                ('bn2', nn.BatchNorm2d(64)),\n","                ('relu2', nn.ReLU(inplace=True)),\n","                ('conv3', nn.Conv2d(64, inplanes, 3, stride=1, padding=1,\n","                                    bias=False)),\n","                ('bn3', nn.BatchNorm2d(inplanes)),\n","                ('relu3', nn.ReLU(inplace=True)),\n","            ]\n","        else:\n","            layer0_modules = [\n","                ('conv1', nn.Conv2d(3, inplanes, kernel_size=7, stride=2,\n","                                    padding=3, bias=False)),\n","                ('bn1', nn.BatchNorm2d(inplanes)),\n","                ('relu1', nn.ReLU(inplace=True)),\n","            ]\n","        # To preserve compatibility with Caffe weights `ceil_mode=True`\n","        # is used instead of `padding=1`.\n","        self.pool = nn.MaxPool2d(3, stride=2, ceil_mode=True)\n","        self.layer0 = nn.Sequential(OrderedDict(layer0_modules))\n","        self.layer1 = self._make_layer(\n","            block,\n","            planes=64,\n","            blocks=layers[0],\n","            groups=groups,\n","            reduction=reduction,\n","            downsample_kernel_size=1,\n","            downsample_padding=0\n","        )\n","        self.layer2 = self._make_layer(\n","            block,\n","            planes=128,\n","            blocks=layers[1],\n","            stride=2,\n","            groups=groups,\n","            reduction=reduction,\n","            downsample_kernel_size=downsample_kernel_size,\n","            downsample_padding=downsample_padding\n","        )\n","        self.layer3 = self._make_layer(\n","            block,\n","            planes=256,\n","            blocks=layers[2],\n","            stride=2,\n","            groups=groups,\n","            reduction=reduction,\n","            downsample_kernel_size=downsample_kernel_size,\n","            downsample_padding=downsample_padding\n","        )\n","        self.layer4 = self._make_layer(\n","            block,\n","            planes=512,\n","            blocks=layers[3],\n","            stride=2,\n","            groups=groups,\n","            reduction=reduction,\n","            downsample_kernel_size=downsample_kernel_size,\n","            downsample_padding=downsample_padding\n","        )\n","        self.avg_pool = nn.AvgPool2d(7, stride=1)\n","        self.dropout = nn.Dropout(dropout_p) if dropout_p is not None else None\n","        self.last_linear = nn.Linear(512 * block.expansion, num_classes)\n","        self._initialize_weights()\n","\n","    def _make_layer(self, block, planes, blocks, groups, reduction, stride=1,\n","                    downsample_kernel_size=1, downsample_padding=0):\n","        downsample = None\n","        if stride != 1 or self.inplanes != planes * block.expansion:\n","            downsample = nn.Sequential(\n","                nn.Conv2d(self.inplanes, planes * block.expansion,\n","                          kernel_size=downsample_kernel_size, stride=stride,\n","                          padding=downsample_padding, bias=False),\n","                nn.BatchNorm2d(planes * block.expansion),\n","            )\n","\n","        layers = []\n","        layers.append(block(self.inplanes, planes, groups, reduction, stride,\n","                            downsample))\n","        self.inplanes = planes * block.expansion\n","        for i in range(1, blocks):\n","            layers.append(block(self.inplanes, planes, groups, reduction))\n","\n","        return nn.Sequential(*layers)\n","\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n","                m.weight.data = nn.init.kaiming_normal_(m.weight.data)\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","\n","    def features(self, x):\n","        x = self.layer0(x)\n","        x = self.pool(x)\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","        return x\n","\n","    def logits(self, x):\n","        x = self.avg_pool(x)\n","        if self.dropout is not None:\n","            x = self.dropout(x)\n","        x = x.view(x.size(0), -1)\n","        x = self.last_linear(x)\n","        return x\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = self.logits(x)\n","        return x\n","\n","\n","def initialize_pretrained_model(model, num_classes, settings):\n","    assert num_classes == settings['num_classes'], \\\n","        'num_classes should be {}, but is {}'.format(\n","            settings['num_classes'], num_classes)\n","    model.load_state_dict(model_zoo.load_url(settings['url']), strict=False)\n","    model.input_space = settings['input_space']\n","    model.input_size = settings['input_size']\n","    model.input_range = settings['input_range']\n","    model.mean = settings['mean']\n","    model.std = settings['std']\n","\n","\n","def senet154(num_classes=1000, pretrained='imagenet'):\n","    model = SENet(SEBottleneck, [3, 8, 36, 3], groups=64, reduction=16,\n","                  dropout_p=0.2, num_classes=num_classes)\n","    if pretrained is not None:\n","        settings = pretrained_settings['senet154'][pretrained]\n","        initialize_pretrained_model(model, num_classes, settings)\n","    return model\n","\n","def scsenet154(num_classes=1000, pretrained='imagenet'):\n","    print(\"scsenet154\")\n","    model = SENet(SCSEBottleneck, [3, 8, 36, 3], groups=64, reduction=16,\n","                  dropout_p=0.2, num_classes=num_classes)\n","    if pretrained is not None:\n","        settings = pretrained_settings['senet154'][pretrained]\n","        initialize_pretrained_model(model, num_classes, settings)\n","    return model\n","\n","\n","def se_resnet50(num_classes=1000, pretrained='imagenet'):\n","    model = SENet(SEResNetBottleneck, [3, 4, 6, 3], groups=1, reduction=16,\n","                  dropout_p=None, inplanes=64, input_3x3=False,\n","                  downsample_kernel_size=1, downsample_padding=0,\n","                  num_classes=num_classes)\n","    if pretrained is not None:\n","        settings = pretrained_settings['se_resnet50'][pretrained]\n","        initialize_pretrained_model(model, num_classes, settings)\n","    return model\n","\n","\n","def se_resnet101(num_classes=1000, pretrained='imagenet'):\n","    model = SENet(SEResNetBottleneck, [3, 4, 23, 3], groups=1, reduction=16,\n","                  dropout_p=None, inplanes=64, input_3x3=False,\n","                  downsample_kernel_size=1, downsample_padding=0,\n","                  num_classes=num_classes)\n","    if pretrained is not None:\n","        settings = pretrained_settings['se_resnet101'][pretrained]\n","        initialize_pretrained_model(model, num_classes, settings)\n","    return model\n","\n","\n","def se_resnet152(num_classes=1000, pretrained='imagenet'):\n","    model = SENet(SEResNetBottleneck, [3, 8, 36, 3], groups=1, reduction=16,\n","                  dropout_p=None, inplanes=64, input_3x3=False,\n","                  downsample_kernel_size=1, downsample_padding=0,\n","                  num_classes=num_classes)\n","    if pretrained is not None:\n","        settings = pretrained_settings['se_resnet152'][pretrained]\n","        initialize_pretrained_model(model, num_classes, settings)\n","    return model\n","\n","\n","def se_resnext50_32x4d(num_classes=1000, pretrained='imagenet'):\n","    model = SENet(SEResNeXtBottleneck, [3, 4, 6, 3], groups=32, reduction=16,\n","                  dropout_p=None, inplanes=64, input_3x3=False,\n","                  downsample_kernel_size=1, downsample_padding=0,\n","                  num_classes=num_classes)\n","    if pretrained is not None:\n","        settings = pretrained_settings['se_resnext50_32x4d'][pretrained]\n","        initialize_pretrained_model(model, num_classes, settings)\n","    return model\n","\n","\n","def scse_resnext50_32x4d(num_classes=1000, pretrained='imagenet'):\n","    model = SENet(SCSEResNeXtBottleneck, [3, 4, 6, 3], groups=32, reduction=16,\n","                  dropout_p=None, inplanes=64, input_3x3=False,\n","                  downsample_kernel_size=1, downsample_padding=0,\n","                  num_classes=num_classes)\n","    if pretrained is not None:\n","        settings = pretrained_settings['se_resnext50_32x4d'][pretrained]\n","        initialize_pretrained_model(model, num_classes, settings)\n","    return model\n","\n","\n","def se_resnext101_32x4d(num_classes=1000, pretrained='imagenet'):\n","    model = SENet(SEResNeXtBottleneck, [3, 4, 23, 3], groups=32, reduction=16,\n","                  dropout_p=None, inplanes=64, input_3x3=False,\n","                  downsample_kernel_size=1, downsample_padding=0,\n","                  num_classes=num_classes)\n","    if pretrained is not None:\n","        settings = pretrained_settings['se_resnext101_32x4d'][pretrained]\n","        initialize_pretrained_model(model, num_classes, settings)\n","    return model\n","if __name__ == '__main__':\n","    print(se_resnext50_32x4d())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eIU2hEMNTCf1"},"outputs":[],"source":["import numpy as np\n","\n","import torch\n","from torch import nn\n","import torch.nn.functional as F\n","import torchvision.models\n","\n","class ConvReluBN(nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size=3):\n","        super(ConvReluBN, self).__init__()\n","        self.layer = nn.Sequential(\n","            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, padding=1),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True)\n","        )\n","    def forward(self, x):\n","        return self.layer(x)\n","\n","\n","class ConvRelu(nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size=3):\n","        super(ConvRelu, self).__init__()\n","        self.layer = nn.Sequential(\n","            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, padding=1),\n","            nn.ReLU(inplace=True)\n","        )\n","    def forward(self, x):\n","        return self.layer(x)\n","\n","\n","class SCSEModule(nn.Module):\n","    # according to https://arxiv.org/pdf/1808.08127.pdf concat is better\n","    def __init__(self, channels, reduction=16, concat=False):\n","        super(SCSEModule, self).__init__()\n","        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n","        self.fc1 = nn.Conv2d(channels, channels // reduction, kernel_size=1,\n","                             padding=0)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.fc2 = nn.Conv2d(channels // reduction, channels, kernel_size=1,\n","                             padding=0)\n","        self.sigmoid = nn.Sigmoid()\n","\n","        self.spatial_se = nn.Sequential(nn.Conv2d(channels, 1, kernel_size=1,\n","                                                  stride=1, padding=0, bias=False),\n","                                        nn.Sigmoid())\n","        self.concat = concat\n","\n","    def forward(self, x):\n","        module_input = x\n","\n","        x = self.avg_pool(x)\n","        x = self.fc1(x)\n","        x = self.relu(x)\n","        x = self.fc2(x)\n","        chn_se = self.sigmoid(x)\n","        chn_se = chn_se * module_input\n","\n","        spa_se = self.spatial_se(module_input)\n","        spa_se = module_input * spa_se\n","        if self.concat:\n","            return torch.cat([chn_se, spa_se], dim=1)\n","        else:\n","            return chn_se + spa_se\n","\n","\n","class SeResNext50_Unet_Loc(nn.Module):\n","    def __init__(self, pretrained='imagenet', **kwargs):\n","        super(SeResNext50_Unet_Loc, self).__init__()\n","        \n","        encoder_filters = [64, 256, 512, 1024, 2048]\n","        decoder_filters = np.asarray([64, 96, 128, 256, 512]) // 2\n","\n","        self.conv6 = ConvRelu(encoder_filters[-1], decoder_filters[-1])\n","        self.conv6_2 = ConvRelu(decoder_filters[-1] + encoder_filters[-2], decoder_filters[-1])\n","        self.conv7 = ConvRelu(decoder_filters[-1], decoder_filters[-2])\n","        self.conv7_2 = ConvRelu(decoder_filters[-2] + encoder_filters[-3], decoder_filters[-2])\n","        self.conv8 = ConvRelu(decoder_filters[-2], decoder_filters[-3])\n","        self.conv8_2 = ConvRelu(decoder_filters[-3] + encoder_filters[-4], decoder_filters[-3])\n","        self.conv9 = ConvRelu(decoder_filters[-3], decoder_filters[-4])\n","        self.conv9_2 = ConvRelu(decoder_filters[-4] + encoder_filters[-5], decoder_filters[-4])\n","        self.conv10 = ConvRelu(decoder_filters[-4], decoder_filters[-5])\n","        \n","        \n","        self.res = nn.Conv2d(decoder_filters[-5], 1, 1, stride=1, padding=0)\n","\n","        self._initialize_weights()\n","\n","        encoder = se_resnext50_32x4d(pretrained=pretrained)\n","\n","        # conv1_new = nn.Conv2d(6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","        # _w = encoder.layer0.conv1.state_dict()\n","        # _w['weight'] = torch.cat([0.5 * _w['weight'], 0.5 * _w['weight']], 1)\n","        # conv1_new.load_state_dict(_w)\n","        self.conv1 = nn.Sequential(encoder.layer0.conv1, encoder.layer0.bn1, encoder.layer0.relu1) #encoder.layer0.conv1\n","        self.conv2 = nn.Sequential(encoder.pool, encoder.layer1)\n","        self.conv3 = encoder.layer2\n","        self.conv4 = encoder.layer3\n","        self.conv5 = encoder.layer4\n","\n","\n","    def forward(self, x):\n","        batch_size, C, H, W = x.shape\n","\n","        enc1 = self.conv1(x)\n","        enc2 = self.conv2(enc1)\n","        enc3 = self.conv3(enc2)\n","        enc4 = self.conv4(enc3)\n","        enc5 = self.conv5(enc4)\n","\n","        dec6 = self.conv6(F.interpolate(enc5, scale_factor=2))\n","        dec6 = self.conv6_2(torch.cat([dec6, enc4\n","                ], 1))\n","\n","        dec7 = self.conv7(F.interpolate(dec6, scale_factor=2))\n","        dec7 = self.conv7_2(torch.cat([dec7, enc3\n","                ], 1))\n","        \n","        dec8 = self.conv8(F.interpolate(dec7, scale_factor=2))\n","        dec8 = self.conv8_2(torch.cat([dec8, enc2\n","                ], 1))\n","\n","        dec9 = self.conv9(F.interpolate(dec8, scale_factor=2))\n","        dec9 = self.conv9_2(torch.cat([dec9, \n","                enc1\n","                ], 1))\n","\n","        dec10 = self.conv10(F.interpolate(dec9, scale_factor=2))\n","\n","        return self.res(dec10)\n","\n","\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Linear):\n","                m.weight.data = nn.init.kaiming_normal_(m.weight.data)\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","\n","\n","class SeResNext50_Unet_Double(nn.Module):\n","    def __init__(self, pretrained='imagenet', **kwargs):\n","        super(SeResNext50_Unet_Double, self).__init__()\n","        \n","        encoder_filters = [64, 256, 512, 1024, 2048]\n","        decoder_filters = np.asarray([64, 96, 128, 256, 512]) // 2\n","\n","        self.conv6 = ConvRelu(encoder_filters[-1], decoder_filters[-1])\n","        self.conv6_2 = ConvRelu(decoder_filters[-1] + encoder_filters[-2], decoder_filters[-1])\n","        self.conv7 = ConvRelu(decoder_filters[-1], decoder_filters[-2])\n","        self.conv7_2 = ConvRelu(decoder_filters[-2] + encoder_filters[-3], decoder_filters[-2])\n","        self.conv8 = ConvRelu(decoder_filters[-2], decoder_filters[-3])\n","        self.conv8_2 = ConvRelu(decoder_filters[-3] + encoder_filters[-4], decoder_filters[-3])\n","        self.conv9 = ConvRelu(decoder_filters[-3], decoder_filters[-4])\n","        self.conv9_2 = ConvRelu(decoder_filters[-4] + encoder_filters[-5], decoder_filters[-4])\n","        self.conv10 = ConvRelu(decoder_filters[-4], decoder_filters[-5])\n","        \n","        \n","        self.res = nn.Conv2d(decoder_filters[-5] * 2, 5, 1, stride=1, padding=0)\n","\n","        self._initialize_weights()\n","\n","        encoder = se_resnext50_32x4d(pretrained=pretrained)\n","\n","        # conv1_new = nn.Conv2d(6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","        # _w = encoder.layer0.conv1.state_dict()\n","        # _w['weight'] = torch.cat([0.5 * _w['weight'], 0.5 * _w['weight']], 1)\n","        # conv1_new.load_state_dict(_w)\n","        self.conv1 = nn.Sequential(encoder.layer0.conv1, encoder.layer0.bn1, encoder.layer0.relu1) #encoder.layer0.conv1\n","        self.conv2 = nn.Sequential(encoder.pool, encoder.layer1)\n","        self.conv3 = encoder.layer2\n","        self.conv4 = encoder.layer3\n","        self.conv5 = encoder.layer4\n","\n","\n","    def forward1(self, x):\n","        batch_size, C, H, W = x.shape\n","\n","        enc1 = self.conv1(x)\n","        enc2 = self.conv2(enc1)\n","        enc3 = self.conv3(enc2)\n","        enc4 = self.conv4(enc3)\n","        enc5 = self.conv5(enc4)\n","\n","        dec6 = self.conv6(F.interpolate(enc5, scale_factor=2))\n","        dec6 = self.conv6_2(torch.cat([dec6, enc4\n","                ], 1))\n","\n","        dec7 = self.conv7(F.interpolate(dec6, scale_factor=2))\n","        dec7 = self.conv7_2(torch.cat([dec7, enc3\n","                ], 1))\n","        \n","        dec8 = self.conv8(F.interpolate(dec7, scale_factor=2))\n","        dec8 = self.conv8_2(torch.cat([dec8, enc2\n","                ], 1))\n","\n","        dec9 = self.conv9(F.interpolate(dec8, scale_factor=2))\n","        dec9 = self.conv9_2(torch.cat([dec9, \n","                enc1\n","                ], 1))\n","\n","        dec10 = self.conv10(F.interpolate(dec9, scale_factor=2))\n","\n","        return dec10\n","\n","\n","    def forward(self, x):\n","\n","        dec10_0 = self.forward1(x[:, :3, :, :])\n","        dec10_1 = self.forward1(x[:, 3:, :, :])\n","\n","        dec10 = torch.cat([dec10_0, dec10_1], 1)\n","\n","        return self.res(dec10)\n","\n","\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Linear):\n","                m.weight.data = nn.init.kaiming_normal_(m.weight.data)\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","\n","\n","class Dpn92_Unet_Loc(nn.Module):\n","    def __init__(self, pretrained='imagenet+5k', **kwargs):\n","        super(Dpn92_Unet_Loc, self).__init__()\n","        \n","        encoder_filters = [64, 336, 704, 1552, 2688]\n","        decoder_filters = np.asarray([64, 96, 128, 256, 512]) // 2\n","\n","        self.conv6 = ConvRelu(encoder_filters[-1], decoder_filters[-1])\n","        self.conv6_2 = nn.Sequential(ConvRelu(decoder_filters[-1]+encoder_filters[-2], decoder_filters[-1]), SCSEModule(decoder_filters[-1], reduction=16, concat=True))\n","        self.conv7 = ConvRelu(decoder_filters[-1] * 2, decoder_filters[-2])\n","        self.conv7_2 = nn.Sequential(ConvRelu(decoder_filters[-2]+encoder_filters[-3], decoder_filters[-2]), SCSEModule(decoder_filters[-2], reduction=16, concat=True))\n","        self.conv8 = ConvRelu(decoder_filters[-2] * 2, decoder_filters[-3])\n","        self.conv8_2 = nn.Sequential(ConvRelu(decoder_filters[-3]+encoder_filters[-4], decoder_filters[-3]), SCSEModule(decoder_filters[-3], reduction=16, concat=True))\n","        self.conv9 = ConvRelu(decoder_filters[-3] * 2, decoder_filters[-4])\n","        self.conv9_2 = nn.Sequential(ConvRelu(decoder_filters[-4]+encoder_filters[-5], decoder_filters[-4]), SCSEModule(decoder_filters[-4], reduction=16, concat=True))\n","        self.conv10 = ConvRelu(decoder_filters[-4] * 2, decoder_filters[-5])\n","\n","        self.res = nn.Conv2d(decoder_filters[-5], 1, 1, stride=1, padding=0)\n","        \n","        self._initialize_weights()\n","\n","        encoder = dpn92(pretrained=pretrained)\n","\n","        # conv1_new = nn.Conv2d(6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","        # _w = encoder.blocks['conv1_1'].conv.state_dict()\n","        # _w['weight'] = torch.cat([0.5 * _w['weight'], 0.5 * _w['weight']], 1)\n","        # conv1_new.load_state_dict(_w)\n","        \n","        self.conv1 = nn.Sequential(\n","                encoder.blocks['conv1_1'].conv,  # conv\n","                encoder.blocks['conv1_1'].bn,  # bn\n","                encoder.blocks['conv1_1'].act,  # relu\n","            )\n","        self.conv2 = nn.Sequential(\n","                encoder.blocks['conv1_1'].pool,  # maxpool\n","                *[b for k, b in encoder.blocks.items() if k.startswith('conv2_')]\n","            )\n","        self.conv3 = nn.Sequential(*[b for k, b in encoder.blocks.items() if k.startswith('conv3_')])\n","        self.conv4 = nn.Sequential(*[b for k, b in encoder.blocks.items() if k.startswith('conv4_')])\n","        self.conv5 = nn.Sequential(*[b for k, b in encoder.blocks.items() if k.startswith('conv5_')])\n","\n","    def forward(self, x):\n","        batch_size, C, H, W = x.shape\n","\n","        enc1 = self.conv1(x)\n","        enc2 = self.conv2(enc1)\n","        enc3 = self.conv3(enc2)\n","        enc4 = self.conv4(enc3)\n","        enc5 = self.conv5(enc4)\n","\n","        enc1 = (torch.cat(enc1, dim=1) if isinstance(enc1, tuple) else enc1)\n","        enc2 = (torch.cat(enc2, dim=1) if isinstance(enc2, tuple) else enc2)\n","        enc3 = (torch.cat(enc3, dim=1) if isinstance(enc3, tuple) else enc3)\n","        enc4 = (torch.cat(enc4, dim=1) if isinstance(enc4, tuple) else enc4)\n","        enc5 = (torch.cat(enc5, dim=1) if isinstance(enc5, tuple) else enc5)\n","\n","        dec6 = self.conv6(F.interpolate(enc5, scale_factor=2))\n","        dec6 = self.conv6_2(torch.cat([dec6, enc4], 1))\n","\n","        dec7 = self.conv7(F.interpolate(dec6, scale_factor=2))\n","        dec7 = self.conv7_2(torch.cat([dec7, enc3], 1))\n","\n","        dec8 = self.conv8(F.interpolate(dec7, scale_factor=2))\n","        dec8 = self.conv8_2(torch.cat([dec8, enc2], 1))\n","\n","        dec9 = self.conv9(F.interpolate(dec8, scale_factor=2))\n","        dec9 = self.conv9_2(torch.cat([dec9, \n","                enc1], 1))\n","\n","        dec10 = self.conv10(F.interpolate(dec9, scale_factor=2))\n","\n","        return self.res(dec10)\n","\n","\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Linear):\n","                m.weight.data = nn.init.kaiming_normal_(m.weight.data)\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","\n","\n","class Dpn92_Unet_Double(nn.Module):\n","    def __init__(self, pretrained='imagenet+5k', **kwargs):\n","        super(Dpn92_Unet_Double, self).__init__()\n","        \n","        encoder_filters = [64, 336, 704, 1552, 2688]\n","        decoder_filters = np.asarray([64, 96, 128, 256, 512]) // 2\n","\n","        self.conv6 = ConvRelu(encoder_filters[-1], decoder_filters[-1])\n","        self.conv6_2 = nn.Sequential(ConvRelu(decoder_filters[-1]+encoder_filters[-2], decoder_filters[-1]), SCSEModule(decoder_filters[-1], reduction=16, concat=True))\n","        self.conv7 = ConvRelu(decoder_filters[-1] * 2, decoder_filters[-2])\n","        self.conv7_2 = nn.Sequential(ConvRelu(decoder_filters[-2]+encoder_filters[-3], decoder_filters[-2]), SCSEModule(decoder_filters[-2], reduction=16, concat=True))\n","        self.conv8 = ConvRelu(decoder_filters[-2] * 2, decoder_filters[-3])\n","        self.conv8_2 = nn.Sequential(ConvRelu(decoder_filters[-3]+encoder_filters[-4], decoder_filters[-3]), SCSEModule(decoder_filters[-3], reduction=16, concat=True))\n","        self.conv9 = ConvRelu(decoder_filters[-3] * 2, decoder_filters[-4])\n","        self.conv9_2 = nn.Sequential(ConvRelu(decoder_filters[-4]+encoder_filters[-5], decoder_filters[-4]), SCSEModule(decoder_filters[-4], reduction=16, concat=True))\n","        self.conv10 = ConvRelu(decoder_filters[-4] * 2, decoder_filters[-5])\n","\n","        self.res = nn.Conv2d(decoder_filters[-5] * 2, 5, 1, stride=1, padding=0)\n","        \n","        self._initialize_weights()\n","\n","        encoder = dpn92(pretrained=pretrained)\n","\n","        # conv1_new = nn.Conv2d(6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","        # _w = encoder.blocks['conv1_1'].conv.state_dict()\n","        # _w['weight'] = torch.cat([0.5 * _w['weight'], 0.5 * _w['weight']], 1)\n","        # conv1_new.load_state_dict(_w)\n","        \n","        self.conv1 = nn.Sequential(\n","                encoder.blocks['conv1_1'].conv,  # conv\n","                encoder.blocks['conv1_1'].bn,  # bn\n","                encoder.blocks['conv1_1'].act,  # relu\n","            )\n","        self.conv2 = nn.Sequential(\n","                encoder.blocks['conv1_1'].pool,  # maxpool\n","                *[b for k, b in encoder.blocks.items() if k.startswith('conv2_')]\n","            )\n","        self.conv3 = nn.Sequential(*[b for k, b in encoder.blocks.items() if k.startswith('conv3_')])\n","        self.conv4 = nn.Sequential(*[b for k, b in encoder.blocks.items() if k.startswith('conv4_')])\n","        self.conv5 = nn.Sequential(*[b for k, b in encoder.blocks.items() if k.startswith('conv5_')])\n","\n","\n","    def forward1(self, x):\n","        batch_size, C, H, W = x.shape\n","\n","        enc1 = self.conv1(x)\n","        enc2 = self.conv2(enc1)\n","        enc3 = self.conv3(enc2)\n","        enc4 = self.conv4(enc3)\n","        enc5 = self.conv5(enc4)\n","\n","        enc1 = (torch.cat(enc1, dim=1) if isinstance(enc1, tuple) else enc1)\n","        enc2 = (torch.cat(enc2, dim=1) if isinstance(enc2, tuple) else enc2)\n","        enc3 = (torch.cat(enc3, dim=1) if isinstance(enc3, tuple) else enc3)\n","        enc4 = (torch.cat(enc4, dim=1) if isinstance(enc4, tuple) else enc4)\n","        enc5 = (torch.cat(enc5, dim=1) if isinstance(enc5, tuple) else enc5)\n","\n","        dec6 = self.conv6(F.interpolate(enc5, scale_factor=2))\n","        dec6 = self.conv6_2(torch.cat([dec6, enc4], 1))\n","\n","        dec7 = self.conv7(F.interpolate(dec6, scale_factor=2))\n","        dec7 = self.conv7_2(torch.cat([dec7, enc3], 1))\n","\n","        dec8 = self.conv8(F.interpolate(dec7, scale_factor=2))\n","        dec8 = self.conv8_2(torch.cat([dec8, enc2], 1))\n","\n","        dec9 = self.conv9(F.interpolate(dec8, scale_factor=2))\n","        dec9 = self.conv9_2(torch.cat([dec9, \n","                enc1], 1))\n","\n","        dec10 = self.conv10(F.interpolate(dec9, scale_factor=2))\n","\n","        return dec10\n","\n","\n","    def forward(self, x):\n","\n","        dec10_0 = self.forward1(x[:, :3, :, :])\n","        dec10_1 = self.forward1(x[:, 3:, :, :])\n","\n","        dec10 = torch.cat([dec10_0, dec10_1], 1)\n","\n","        return self.res(dec10)\n","\n","\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Linear):\n","                m.weight.data = nn.init.kaiming_normal_(m.weight.data)\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","\n","\n","class Res34_Unet_Loc(nn.Module):\n","    def __init__(self, pretrained=True, **kwargs):\n","        super(Res34_Unet_Loc, self).__init__()\n","        \n","        encoder_filters = [64, 64, 128, 256, 512]\n","        decoder_filters = np.asarray([48, 64, 96, 160, 320])\n","\n","        self.conv6 = ConvRelu(encoder_filters[-1], decoder_filters[-1])\n","        self.conv6_2 = ConvRelu(decoder_filters[-1] + encoder_filters[-2], decoder_filters[-1])\n","        self.conv7 = ConvRelu(decoder_filters[-1], decoder_filters[-2])\n","        self.conv7_2 = ConvRelu(decoder_filters[-2] + encoder_filters[-3], decoder_filters[-2])\n","        self.conv8 = ConvRelu(decoder_filters[-2], decoder_filters[-3])\n","        self.conv8_2 = ConvRelu(decoder_filters[-3] + encoder_filters[-4], decoder_filters[-3])\n","        self.conv9 = ConvRelu(decoder_filters[-3], decoder_filters[-4])\n","        self.conv9_2 = ConvRelu(decoder_filters[-4] + encoder_filters[-5], decoder_filters[-4])\n","        self.conv10 = ConvRelu(decoder_filters[-4], decoder_filters[-5])\n","        \n","        self.res = nn.Conv2d(decoder_filters[-5], 1, 1, stride=1, padding=0)\n","\n","        self._initialize_weights()\n","\n","        encoder = torchvision.models.resnet34(pretrained=pretrained)\n","        self.conv1 = nn.Sequential(\n","                        encoder.conv1,\n","                        encoder.bn1,\n","                        encoder.relu)\n","        self.conv2 = nn.Sequential(\n","                        encoder.maxpool,\n","                        encoder.layer1)\n","        self.conv3 = encoder.layer2\n","        self.conv4 = encoder.layer3\n","        self.conv5 = encoder.layer4\n","\n","    def forward(self, x):\n","        batch_size, C, H, W = x.shape\n","\n","        enc1 = self.conv1(x)\n","        enc2 = self.conv2(enc1)\n","        enc3 = self.conv3(enc2)\n","        enc4 = self.conv4(enc3)\n","        enc5 = self.conv5(enc4)\n","\n","        dec6 = self.conv6(F.interpolate(enc5, scale_factor=2))\n","        dec6 = self.conv6_2(torch.cat([dec6, enc4\n","                ], 1))\n","\n","        dec7 = self.conv7(F.interpolate(dec6, scale_factor=2))\n","        dec7 = self.conv7_2(torch.cat([dec7, enc3\n","                ], 1))\n","        \n","        dec8 = self.conv8(F.interpolate(dec7, scale_factor=2))\n","        dec8 = self.conv8_2(torch.cat([dec8, enc2\n","                ], 1))\n","\n","        dec9 = self.conv9(F.interpolate(dec8, scale_factor=2))\n","        dec9 = self.conv9_2(torch.cat([dec9, \n","                enc1\n","                ], 1))\n","\n","        dec10 = self.conv10(F.interpolate(dec9, scale_factor=2))\n","\n","        return self.res(dec10)\n","\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Linear):\n","                m.weight.data = nn.init.kaiming_normal_(m.weight.data)\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","\n","\n","class Res34_Unet_Double(nn.Module):\n","    def __init__(self, pretrained=True, **kwargs):\n","        super(Res34_Unet_Double, self).__init__()\n","        \n","        encoder_filters = [64, 64, 128, 256, 512]\n","        decoder_filters = np.asarray([48, 64, 96, 160, 320])\n","\n","        self.conv6 = ConvRelu(encoder_filters[-1], decoder_filters[-1])\n","        self.conv6_2 = ConvRelu(decoder_filters[-1] + encoder_filters[-2], decoder_filters[-1])\n","        self.conv7 = ConvRelu(decoder_filters[-1], decoder_filters[-2])\n","        self.conv7_2 = ConvRelu(decoder_filters[-2] + encoder_filters[-3], decoder_filters[-2])\n","        self.conv8 = ConvRelu(decoder_filters[-2], decoder_filters[-3])\n","        self.conv8_2 = ConvRelu(decoder_filters[-3] + encoder_filters[-4], decoder_filters[-3])\n","        self.conv9 = ConvRelu(decoder_filters[-3], decoder_filters[-4])\n","        self.conv9_2 = ConvRelu(decoder_filters[-4] + encoder_filters[-5], decoder_filters[-4])\n","        self.conv10 = ConvRelu(decoder_filters[-4], decoder_filters[-5])\n","        \n","        self.res = nn.Conv2d(decoder_filters[-5] * 2, 5, 1, stride=1, padding=0)\n","\n","        self._initialize_weights()\n","\n","        encoder = torchvision.models.resnet34(pretrained=pretrained)\n","        self.conv1 = nn.Sequential(\n","                        encoder.conv1,\n","                        encoder.bn1,\n","                        encoder.relu)\n","        self.conv2 = nn.Sequential(\n","                        encoder.maxpool,\n","                        encoder.layer1)\n","        self.conv3 = encoder.layer2\n","        self.conv4 = encoder.layer3\n","        self.conv5 = encoder.layer4\n","\n","    def forward1(self, x):\n","        batch_size, C, H, W = x.shape\n","\n","        enc1 = self.conv1(x)\n","        enc2 = self.conv2(enc1)\n","        enc3 = self.conv3(enc2)\n","        enc4 = self.conv4(enc3)\n","        enc5 = self.conv5(enc4)\n","\n","        dec6 = self.conv6(F.interpolate(enc5, scale_factor=2))\n","        dec6 = self.conv6_2(torch.cat([dec6, enc4\n","                ], 1))\n","\n","        dec7 = self.conv7(F.interpolate(dec6, scale_factor=2))\n","        dec7 = self.conv7_2(torch.cat([dec7, enc3\n","                ], 1))\n","        \n","        dec8 = self.conv8(F.interpolate(dec7, scale_factor=2))\n","        dec8 = self.conv8_2(torch.cat([dec8, enc2\n","                ], 1))\n","\n","        dec9 = self.conv9(F.interpolate(dec8, scale_factor=2))\n","        dec9 = self.conv9_2(torch.cat([dec9, \n","                enc1\n","                ], 1))\n","\n","        dec10 = self.conv10(F.interpolate(dec9, scale_factor=2))\n","\n","        return dec10\n","\n","    def forward(self, x):\n","        dec10_0 = self.forward1(x[:, :3, :, :])\n","        dec10_1 = self.forward1(x[:, 3:, :, :])\n","        dec10 = torch.cat([dec10_0, dec10_1], 1)\n","        return self.res(dec10)\n","        \n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Linear):\n","                m.weight.data = nn.init.kaiming_normal_(m.weight.data)\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","\n","\n","class SeNet154_Unet_Loc(nn.Module):\n","    def __init__(self, pretrained='imagenet', **kwargs):\n","        super(SeNet154_Unet_Loc, self).__init__()\n","        \n","        encoder_filters = [128, 256, 512, 1024, 2048]\n","        decoder_filters = np.asarray([48, 64, 96, 160, 320])\n","\n","        self.conv6 = ConvRelu(encoder_filters[-1], decoder_filters[-1])\n","        self.conv6_2 = ConvRelu(decoder_filters[-1] + encoder_filters[-2], decoder_filters[-1])\n","        self.conv7 = ConvRelu(decoder_filters[-1], decoder_filters[-2])\n","        self.conv7_2 = ConvRelu(decoder_filters[-2] + encoder_filters[-3], decoder_filters[-2])\n","        self.conv8 = ConvRelu(decoder_filters[-2], decoder_filters[-3])\n","        self.conv8_2 = ConvRelu(decoder_filters[-3] + encoder_filters[-4], decoder_filters[-3])\n","        self.conv9 = ConvRelu(decoder_filters[-3], decoder_filters[-4])\n","        self.conv9_2 = ConvRelu(decoder_filters[-4] + encoder_filters[-5], decoder_filters[-4])\n","        self.conv10 = ConvRelu(decoder_filters[-4], decoder_filters[-5])\n","        \n","        self.res = nn.Conv2d(decoder_filters[-5], 1, 1, stride=1, padding=0)\n","\n","        self._initialize_weights()\n","\n","        encoder = senet154(pretrained=pretrained)\n","\n","        # conv1_new = nn.Conv2d(9, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        # _w = encoder.layer0.conv1.state_dict()\n","        # _w['weight'] = torch.cat([0.8 * _w['weight'], 0.1 * _w['weight'], 0.1 * _w['weight']], 1)\n","        # conv1_new.load_state_dict(_w)\n","        self.conv1 = nn.Sequential(encoder.layer0.conv1, encoder.layer0.bn1, encoder.layer0.relu1, encoder.layer0.conv2, encoder.layer0.bn2, encoder.layer0.relu2, encoder.layer0.conv3, encoder.layer0.bn3, encoder.layer0.relu3)\n","        self.conv2 = nn.Sequential(encoder.pool, encoder.layer1)\n","        self.conv3 = encoder.layer2\n","        self.conv4 = encoder.layer3\n","        self.conv5 = encoder.layer4\n","\n","\n","    def forward(self, x):\n","        batch_size, C, H, W = x.shape\n","\n","        enc1 = self.conv1(x)\n","        enc2 = self.conv2(enc1)\n","        enc3 = self.conv3(enc2)\n","        enc4 = self.conv4(enc3)\n","        enc5 = self.conv5(enc4)\n","\n","        dec6 = self.conv6(F.interpolate(enc5, scale_factor=2))\n","        dec6 = self.conv6_2(torch.cat([dec6, enc4\n","                ], 1))\n","\n","        dec7 = self.conv7(F.interpolate(dec6, scale_factor=2))\n","        dec7 = self.conv7_2(torch.cat([dec7, enc3\n","                ], 1))\n","        \n","        dec8 = self.conv8(F.interpolate(dec7, scale_factor=2))\n","        dec8 = self.conv8_2(torch.cat([dec8, enc2\n","                ], 1))\n","\n","        dec9 = self.conv9(F.interpolate(dec8, scale_factor=2))\n","        dec9 = self.conv9_2(torch.cat([dec9, \n","                enc1\n","                ], 1))\n","\n","        dec10 = self.conv10(F.interpolate(dec9, scale_factor=2))\n","\n","        return self.res(dec10)\n","\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Linear):\n","                m.weight.data = nn.init.kaiming_normal_(m.weight.data)\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","\n","\n","class SeNet154_Unet_Double(nn.Module):\n","    def __init__(self, pretrained='imagenet', **kwargs):\n","        super(SeNet154_Unet_Double, self).__init__()\n","        \n","        encoder_filters = [128, 256, 512, 1024, 2048]\n","        decoder_filters = np.asarray([48, 64, 96, 160, 320])\n","\n","        self.conv6 = ConvRelu(encoder_filters[-1], decoder_filters[-1])\n","        self.conv6_2 = ConvRelu(decoder_filters[-1] + encoder_filters[-2], decoder_filters[-1])\n","        self.conv7 = ConvRelu(decoder_filters[-1], decoder_filters[-2])\n","        self.conv7_2 = ConvRelu(decoder_filters[-2] + encoder_filters[-3], decoder_filters[-2])\n","        self.conv8 = ConvRelu(decoder_filters[-2], decoder_filters[-3])\n","        self.conv8_2 = ConvRelu(decoder_filters[-3] + encoder_filters[-4], decoder_filters[-3])\n","        self.conv9 = ConvRelu(decoder_filters[-3], decoder_filters[-4])\n","        self.conv9_2 = ConvRelu(decoder_filters[-4] + encoder_filters[-5], decoder_filters[-4])\n","        self.conv10 = ConvRelu(decoder_filters[-4], decoder_filters[-5])\n","        \n","        self.res = nn.Conv2d(decoder_filters[-5] * 2, 5, 1, stride=1, padding=0)\n","\n","        self._initialize_weights()\n","\n","        encoder = senet154(pretrained=pretrained)\n","\n","        # conv1_new = nn.Conv2d(9, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        # _w = encoder.layer0.conv1.state_dict()\n","        # _w['weight'] = torch.cat([0.8 * _w['weight'], 0.1 * _w['weight'], 0.1 * _w['weight']], 1)\n","        # conv1_new.load_state_dict(_w)\n","        self.conv1 = nn.Sequential(encoder.layer0.conv1, encoder.layer0.bn1, encoder.layer0.relu1, encoder.layer0.conv2, encoder.layer0.bn2, encoder.layer0.relu2, encoder.layer0.conv3, encoder.layer0.bn3, encoder.layer0.relu3)\n","        self.conv2 = nn.Sequential(encoder.pool, encoder.layer1)\n","        self.conv3 = encoder.layer2\n","        self.conv4 = encoder.layer3\n","        self.conv5 = encoder.layer4\n","\n","    def forward1(self, x):\n","        batch_size, C, H, W = x.shape\n","\n","        enc1 = self.conv1(x)\n","        enc2 = self.conv2(enc1)\n","        enc3 = self.conv3(enc2)\n","        enc4 = self.conv4(enc3)\n","        enc5 = self.conv5(enc4)\n","\n","        dec6 = self.conv6(F.interpolate(enc5, scale_factor=2))\n","        dec6 = self.conv6_2(torch.cat([dec6, enc4\n","                ], 1))\n","\n","        dec7 = self.conv7(F.interpolate(dec6, scale_factor=2))\n","        dec7 = self.conv7_2(torch.cat([dec7, enc3\n","                ], 1))\n","        \n","        dec8 = self.conv8(F.interpolate(dec7, scale_factor=2))\n","        dec8 = self.conv8_2(torch.cat([dec8, enc2\n","                ], 1))\n","\n","        dec9 = self.conv9(F.interpolate(dec8, scale_factor=2))\n","        dec9 = self.conv9_2(torch.cat([dec9, \n","                enc1\n","                ], 1))\n","\n","        dec10 = self.conv10(F.interpolate(dec9, scale_factor=2))\n","\n","        return dec10\n","\n","    def forward(self, x):\n","\n","        dec10_0 = self.forward1(x[:, :3, :, :])\n","        dec10_1 = self.forward1(x[:, 3:, :, :])\n","\n","        dec10 = torch.cat([dec10_0, dec10_1], 1)\n","\n","        return self.res(dec10)\n","\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Linear):\n","                m.weight.data = nn.init.kaiming_normal_(m.weight.data)\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()"]},{"cell_type":"markdown","metadata":{"id":"FXa807PbTjxn"},"source":["## Utils"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"7Fs2XBvfToVf","executionInfo":{"status":"ok","timestamp":1685488248855,"user_tz":180,"elapsed":5,"user":{"displayName":"Antonio Santos","userId":"03265893617080544823"}}},"outputs":[],"source":["import numpy as np\n","import cv2\n","\n","#### Augmentations\n","def shift_image(img, shift_pnt):\n","    M = np.float32([[1, 0, shift_pnt[0]], [0, 1, shift_pnt[1]]])\n","    res = cv2.warpAffine(img, M, (img.shape[1], img.shape[0]), borderMode=cv2.BORDER_REFLECT_101)\n","    return res\n","\n","\n","def rotate_image(image, angle, scale, rot_pnt):\n","    rot_mat = cv2.getRotationMatrix2D(rot_pnt, angle, scale)\n","    result = cv2.warpAffine(image, rot_mat, (image.shape[1], image.shape[0]), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT_101) #INTER_NEAREST\n","    return result\n","\n","\n","def gauss_noise(img, var=30):\n","    row, col, ch = img.shape\n","    mean = var\n","    sigma = var**0.5\n","    gauss = np.random.normal(mean,sigma,(row,col,ch))\n","    gauss = gauss.reshape(row,col,ch)\n","    gauss = (gauss - np.min(gauss)).astype(np.uint8)\n","    return np.clip(img.astype(np.int32) + gauss, 0, 255).astype('uint8')\n","\n","\n","def clahe(img, clipLimit=2.0, tileGridSize=(5,5)):\n","    img_yuv = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n","    clahe = cv2.createCLAHE(clipLimit=clipLimit, tileGridSize=tileGridSize)\n","    img_yuv[:, :, 0] = clahe.apply(img_yuv[:, :, 0])\n","    img_output = cv2.cvtColor(img_yuv, cv2.COLOR_LAB2RGB)\n","    return img_output\n","\n","\n","def _blend(img1, img2, alpha):\n","    return np.clip(img1 * alpha + (1 - alpha) * img2, 0, 255).astype('uint8')\n","\n","\n","_alpha = np.asarray([0.114, 0.587, 0.299]).reshape((1, 1, 3))\n","def _grayscale(img):\n","    return np.sum(_alpha * img, axis=2, keepdims=True)\n","\n","\n","def saturation(img, alpha):\n","    gs = _grayscale(img)\n","    return _blend(img, gs, alpha)\n","\n","\n","def brightness(img, alpha):\n","    gs = np.zeros_like(img)\n","    return _blend(img, gs, alpha)\n","\n","\n","def contrast(img, alpha):\n","    gs = _grayscale(img)\n","    gs = np.repeat(gs.mean(), 3)\n","    return _blend(img, gs, alpha)\n","\n","\n","def change_hsv(img, h, s, v):\n","    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n","    hsv = hsv.astype(int)\n","    hsv[:,:,0] += h\n","    hsv[:,:,0] = np.clip(hsv[:,:,0], 0, 255)\n","    hsv[:,:,1] += s\n","    hsv[:,:,1] = np.clip(hsv[:,:,1], 0, 255)\n","    hsv[:,:,2] += v\n","    hsv[:,:,2] = np.clip(hsv[:,:,2], 0, 255)\n","    hsv = hsv.astype('uint8')\n","    img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n","    return img\n","\n","def shift_channels(img, b_shift, g_shift, r_shift):\n","    img = img.astype(int)\n","    img[:,:,0] += b_shift\n","    img[:,:,0] = np.clip(img[:,:,0], 0, 255)\n","    img[:,:,1] += g_shift\n","    img[:,:,1] = np.clip(img[:,:,1], 0, 255)\n","    img[:,:,2] += r_shift\n","    img[:,:,2] = np.clip(img[:,:,2], 0, 255)\n","    img = img.astype('uint8')\n","    return img\n","    \n","def invert(img):\n","    return 255 - img\n","\n","def channel_shuffle(img):\n","    ch_arr = [0, 1, 2]\n","    np.random.shuffle(ch_arr)\n","    img = img[..., ch_arr]\n","    return img\n","    \n","#######\n","\n","\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","\n","def preprocess_inputs(x):\n","    x = np.asarray(x, dtype='float32')\n","    x /= 127\n","    x -= 1\n","    return x\n","\n","\n","def dice(im1, im2, empty_score=1.0):\n","    \"\"\"\n","    Computes the Dice coefficient, a measure of set similarity.\n","    Parameters\n","    ----------\n","    im1 : array-like, bool\n","        Any array of arbitrary size. If not boolean, will be converted.\n","    im2 : array-like, bool\n","        Any other array of identical size. If not boolean, will be converted.\n","    Returns\n","    -------\n","    dice : float\n","        Dice coefficient as a float on range [0,1].\n","        Maximum similarity = 1\n","        No similarity = 0\n","        Both are empty (sum eq to zero) = empty_score\n","\n","    Notes\n","    -----\n","    The order of inputs for `dice` is irrelevant. The result will be\n","    identical if `im1` and `im2` are switched.\n","    \"\"\"\n","    im1 = np.asarray(im1).astype(np.bool)\n","    im2 = np.asarray(im2).astype(np.bool)\n","\n","    if im1.shape != im2.shape:\n","        raise ValueError(\"Shape mismatch: im1 and im2 must have the same shape.\")\n","\n","    im_sum = im1.sum() + im2.sum()\n","    if im_sum == 0:\n","        return empty_score\n","\n","    # Compute Dice coefficient\n","    intersection = np.logical_and(im1, im2)\n","\n","    return 2. * intersection.sum() / im_sum\n","\n","\n","def iou(im1, im2, empty_score=1.0):\n","    im1 = np.asarray(im1).astype(np.bool)\n","    im2 = np.asarray(im2).astype(np.bool)\n","\n","    if im1.shape != im2.shape:\n","        raise ValueError(\"Shape mismatch: im1 and im2 must have the same shape.\")\n","\n","    union = np.logical_or(im1, im2)\n","    im_sum = union.sum()\n","    if im_sum == 0:\n","        return empty_score\n","\n","    # Compute Dice coefficient\n","    intersection = np.logical_and(im1, im2)\n","\n","    return intersection.sum() / im_sum"]},{"cell_type":"markdown","metadata":{"id":"Ifa7HjK2FVf3"},"source":["## modelMscale"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"RoOkAXB2n4nS","executionInfo":{"status":"ok","timestamp":1685488252113,"user_tz":180,"elapsed":3263,"user":{"displayName":"Antonio Santos","userId":"03265893617080544823"}}},"outputs":[],"source":["import numpy as np\n","from tensorflow.keras import Model\n","from tensorflow.keras.layers import Conv2D, Activation, UpSampling2D, Concatenate, Input\n","from tensorflow.keras.applications import ResNet50\n","from tensorflow.keras.initializers import HeNormal\n","from tensorflow.keras import backend as K\n","\n","class ConvRelu(nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size=3):\n","        super(ConvRelu, self).__init__()\n","        self.layer = nn.Sequential(\n","            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, padding=1),\n","            nn.ReLU(inplace=True, )\n","        )\n","    #@autocast()\n","    def forward(self, x):\n","        return self.layer(x)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"sDIsasbMn5W8","executionInfo":{"status":"ok","timestamp":1685488252113,"user_tz":180,"elapsed":4,"user":{"displayName":"Antonio Santos","userId":"03265893617080544823"}}},"outputs":[],"source":["\"\"\"\n","ResNet code gently borrowed from\n","https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py\n","\"\"\"\n","\n","from collections import OrderedDict\n","import math\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils import model_zoo\n","\n","__all__ = ['SENet', 'senet154', 'se_resnet50', 'se_resnet101', 'se_resnet152',\n","           'se_resnext50_32x4d', 'se_resnext101_32x4d']\n","\n","pretrained_settings = {\n","    'senet154': {\n","        'imagenet': {\n","            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/senet154-c7b49a05.pth',\n","            'input_space': 'RGB',\n","            'input_size': [3, 224, 224],\n","            'input_range': [0, 1],\n","            'mean': [0.485, 0.456, 0.406],\n","            'std': [0.229, 0.224, 0.225],\n","            'num_classes': 1000\n","        }\n","    },\n","    'se_resnet50': {\n","        'imagenet': {\n","            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnet50-ce0d4300.pth',\n","            'input_space': 'RGB',\n","            'input_size': [3, 224, 224],\n","            'input_range': [0, 1],\n","            'mean': [0.485, 0.456, 0.406],\n","            'std': [0.229, 0.224, 0.225],\n","            'num_classes': 1000\n","        }\n","    },\n","    'se_resnet101': {\n","        'imagenet': {\n","            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnet101-7e38fcc6.pth',\n","            'input_space': 'RGB',\n","            'input_size': [3, 224, 224],\n","            'input_range': [0, 1],\n","            'mean': [0.485, 0.456, 0.406],\n","            'std': [0.229, 0.224, 0.225],\n","            'num_classes': 1000\n","        }\n","    },\n","    'se_resnet152': {\n","        'imagenet': {\n","            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnet152-d17c99b7.pth',\n","            'input_space': 'RGB',\n","            'input_size': [3, 224, 224],\n","            'input_range': [0, 1],\n","            'mean': [0.485, 0.456, 0.406],\n","            'std': [0.229, 0.224, 0.225],\n","            'num_classes': 1000\n","        }\n","    },\n","    'se_resnext50_32x4d': {\n","        'imagenet': {\n","            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnext50_32x4d-a260b3a4.pth',\n","            'input_space': 'RGB',\n","            'input_size': [3, 224, 224],\n","            'input_range': [0, 1],\n","            'mean': [0.485, 0.456, 0.406],\n","            'std': [0.229, 0.224, 0.225],\n","            'num_classes': 1000\n","        }\n","    },\n","    'se_resnext101_32x4d': {\n","        'imagenet': {\n","            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnext101_32x4d-3b2fe3d8.pth',\n","            'input_space': 'RGB',\n","            'input_size': [3, 224, 224],\n","            'input_range': [0, 1],\n","            'mean': [0.485, 0.456, 0.406],\n","            'std': [0.229, 0.224, 0.225],\n","            'num_classes': 1000\n","        }\n","    },\n","}\n","\n","\n","class SEModule(nn.Module):\n","\n","    def __init__(self, channels, reduction, concat=False):\n","        super(SEModule, self).__init__()\n","        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n","        self.fc1 = nn.Conv2d(channels, channels // reduction, kernel_size=1,\n","                             padding=0)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.fc2 = nn.Conv2d(channels // reduction, channels, kernel_size=1,\n","                             padding=0)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        module_input = x\n","        x = self.avg_pool(x)\n","        x = self.fc1(x)\n","        x = self.relu(x)\n","        x = self.fc2(x)\n","        x = self.sigmoid(x)\n","        return module_input * x\n","\n","class SCSEModule(nn.Module):\n","    # according to https://arxiv.org/pdf/1808.08127.pdf concat is better\n","    def __init__(self, channels, reduction=16, concat=False):\n","        super(SCSEModule, self).__init__()\n","        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n","        self.fc1 = nn.Conv2d(channels, channels // reduction, kernel_size=1,\n","                             padding=0)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.fc2 = nn.Conv2d(channels // reduction, channels, kernel_size=1,\n","                             padding=0)\n","        self.sigmoid = nn.Sigmoid()\n","\n","        self.spatial_se = nn.Sequential(nn.Conv2d(channels, 1, kernel_size=1,\n","                                                  stride=1, padding=0, bias=False),\n","                                        nn.Sigmoid())\n","        self.concat = concat\n","\n","    def forward(self, x):\n","        module_input = x\n","\n","        x = self.avg_pool(x)\n","        x = self.fc1(x)\n","        x = self.relu(x)\n","        x = self.fc2(x)\n","        chn_se = self.sigmoid(x)\n","        chn_se = chn_se * module_input\n","\n","        spa_se = self.spatial_se(module_input)\n","        spa_se = module_input * spa_se\n","        if self.concat:\n","            return torch.cat([chn_se, spa_se], dim=1)\n","        else:\n","            return chn_se + spa_se\n","\n","class Bottleneck(nn.Module):\n","    \"\"\"\n","    Base class for bottlenecks that implements `forward()` method.\n","    \"\"\"\n","    def forward(self, x):\n","        residual = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out = self.relu(out)\n","\n","        out = self.conv3(out)\n","        out = self.bn3(out)\n","\n","        if self.downsample is not None:\n","            residual = self.downsample(x)\n","\n","        out = self.se_module(out) + residual\n","        out = self.relu(out)\n","\n","        return out\n","\n","\n","class SEBottleneck(Bottleneck):\n","    \"\"\"\n","    Bottleneck for SENet154.\n","    \"\"\"\n","    expansion = 4\n","\n","    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n","                 downsample=None):\n","        super(SEBottleneck, self).__init__()\n","        self.conv1 = nn.Conv2d(inplanes, planes * 2, kernel_size=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes * 2)\n","        self.conv2 = nn.Conv2d(planes * 2, planes * 4, kernel_size=3,\n","                               stride=stride, padding=1, groups=groups,\n","                               bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes * 4)\n","        self.conv3 = nn.Conv2d(planes * 4, planes * 4, kernel_size=1,\n","                               bias=False)\n","        self.bn3 = nn.BatchNorm2d(planes * 4)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.se_module = SEModule(planes * 4, reduction=reduction)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","\n","class SCSEBottleneck(Bottleneck):\n","    \"\"\"\n","    Bottleneck for SENet154.\n","    \"\"\"\n","    expansion = 4\n","\n","    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n","                 downsample=None):\n","        super(SCSEBottleneck, self).__init__()\n","        self.conv1 = nn.Conv2d(inplanes, planes * 2, kernel_size=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes * 2)\n","        self.conv2 = nn.Conv2d(planes * 2, planes * 4, kernel_size=3,\n","                               stride=stride, padding=1, groups=groups,\n","                               bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes * 4)\n","        self.conv3 = nn.Conv2d(planes * 4, planes * 4, kernel_size=1,\n","                               bias=False)\n","        self.bn3 = nn.BatchNorm2d(planes * 4)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.se_module = SCSEModule(planes * 4, reduction=reduction)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","\n","class SEResNetBottleneck(Bottleneck):\n","    \"\"\"\n","    ResNet bottleneck with a Squeeze-and-Excitation module. It follows Caffe\n","    implementation and uses `stride=stride` in `conv1` and not in `conv2`\n","    (the latter is used in the torchvision implementation of ResNet).\n","    \"\"\"\n","    expansion = 4\n","\n","    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n","                 downsample=None):\n","        super(SEResNetBottleneck, self).__init__()\n","        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False,\n","                               stride=stride)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, padding=1,\n","                               groups=groups, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(planes * 4)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.se_module = SEModule(planes * 4, reduction=reduction)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","\n","class SEResNeXtBottleneck(Bottleneck):\n","    \"\"\"\n","    ResNeXt bottleneck type C with a Squeeze-and-Excitation module.\n","    \"\"\"\n","    expansion = 4\n","\n","    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n","                 downsample=None, base_width=4):\n","        super(SEResNeXtBottleneck, self).__init__()\n","        width = math.floor(planes * (base_width / 64)) * groups\n","        self.conv1 = nn.Conv2d(inplanes, width, kernel_size=1, bias=False,\n","                               stride=1)\n","        self.bn1 = nn.BatchNorm2d(width)\n","        self.conv2 = nn.Conv2d(width, width, kernel_size=3, stride=stride,\n","                               padding=1, groups=groups, bias=False)\n","        self.bn2 = nn.BatchNorm2d(width)\n","        self.conv3 = nn.Conv2d(width, planes * 4, kernel_size=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(planes * 4)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.se_module = SEModule(planes * 4, reduction=reduction)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","\n","\n","class SCSEResNeXtBottleneck(Bottleneck):\n","    \"\"\"\n","    ResNeXt bottleneck type C with a Concurrent Spatial Squeeze-and-Excitation module.\n","    \"\"\"\n","    expansion = 4\n","\n","    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n","                 downsample=None, base_width=4, final=False):\n","        super(SCSEResNeXtBottleneck, self).__init__()\n","        width = math.floor(planes * (base_width / 64)) * groups\n","        self.conv1 = nn.Conv2d(inplanes, width, kernel_size=1, bias=False,\n","                               stride=1)\n","        self.bn1 = nn.BatchNorm2d(width)\n","        self.conv2 = nn.Conv2d(width, width, kernel_size=3, stride=stride,\n","                               padding=1, groups=groups, bias=False)\n","        self.bn2 = nn.BatchNorm2d(width)\n","        self.conv3 = nn.Conv2d(width, planes * 4, kernel_size=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(planes * 4)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.se_module = SCSEModule(planes * 4, reduction=reduction)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","\n","class SENet(nn.Module):\n","\n","    def __init__(self, block, layers, groups, reduction, dropout_p=0.2,\n","                 inplanes=128, input_3x3=True, downsample_kernel_size=3,\n","                 downsample_padding=1, num_classes=1000):\n","        \"\"\"\n","        Parameters\n","        ----------\n","        block (nn.Module): Bottleneck class.\n","            - For SENet154: SEBottleneck\n","            - For SE-ResNet models: SEResNetBottleneck\n","            - For SE-ResNeXt models:  SEResNeXtBottleneck\n","        layers (list of ints): Number of residual blocks for 4 layers of the\n","            network (layer1...layer4).\n","        groups (int): Number of groups for the 3x3 convolution in each\n","            bottleneck block.\n","            - For SENet154: 64\n","            - For SE-ResNet models: 1\n","            - For SE-ResNeXt models:  32\n","        reduction (int): Reduction ratio for Squeeze-and-Excitation modules.\n","            - For all models: 16\n","        dropout_p (float or None): Drop probability for the Dropout layer.\n","            If `None` the Dropout layer is not used.\n","            - For SENet154: 0.2\n","            - For SE-ResNet models: None\n","            - For SE-ResNeXt models: None\n","        inplanes (int):  Number of input channels for layer1.\n","            - For SENet154: 128\n","            - For SE-ResNet models: 64\n","            - For SE-ResNeXt models: 64\n","        input_3x3 (bool): If `True`, use three 3x3 convolutions instead of\n","            a single 7x7 convolution in layer0.\n","            - For SENet154: True\n","            - For SE-ResNet models: False\n","            - For SE-ResNeXt models: False\n","        downsample_kernel_size (int): Kernel size for downsampling convolutions\n","            in layer2, layer3 and layer4.\n","            - For SENet154: 3\n","            - For SE-ResNet models: 1\n","            - For SE-ResNeXt models: 1\n","        downsample_padding (int): Padding for downsampling convolutions in\n","            layer2, layer3 and layer4.\n","            - For SENet154: 1\n","            - For SE-ResNet models: 0\n","            - For SE-ResNeXt models: 0\n","        num_classes (int): Number of outputs in `last_linear` layer.\n","            - For all models: 1000\n","        \"\"\"\n","        super(SENet, self).__init__()\n","        self.inplanes = inplanes\n","        if input_3x3:\n","            layer0_modules = [\n","                ('conv1', nn.Conv2d(3, 64, 3, stride=2, padding=1,\n","                                    bias=False)),\n","                ('bn1', nn.BatchNorm2d(64)),\n","                ('relu1', nn.ReLU(inplace=True)),\n","                ('conv2', nn.Conv2d(64, 64, 3, stride=1, padding=1,\n","                                    bias=False)),\n","                ('bn2', nn.BatchNorm2d(64)),\n","                ('relu2', nn.ReLU(inplace=True)),\n","                ('conv3', nn.Conv2d(64, inplanes, 3, stride=1, padding=1,\n","                                    bias=False)),\n","                ('bn3', nn.BatchNorm2d(inplanes)),\n","                ('relu3', nn.ReLU(inplace=True)),\n","            ]\n","        else:\n","            layer0_modules = [\n","                ('conv1', nn.Conv2d(3, inplanes, kernel_size=7, stride=2,\n","                                    padding=3, bias=False)),\n","                ('bn1', nn.BatchNorm2d(inplanes)),\n","                ('relu1', nn.ReLU(inplace=True)),\n","            ]\n","        # To preserve compatibility with Caffe weights `ceil_mode=True`\n","        # is used instead of `padding=1`.\n","        self.pool = nn.MaxPool2d(3, stride=2, ceil_mode=True)\n","        self.layer0 = nn.Sequential(OrderedDict(layer0_modules))\n","        self.layer1 = self._make_layer(\n","            block,\n","            planes=64,\n","            blocks=layers[0],\n","            groups=groups,\n","            reduction=reduction,\n","            downsample_kernel_size=1,\n","            downsample_padding=0\n","        )\n","        self.layer2 = self._make_layer(\n","            block,\n","            planes=128,\n","            blocks=layers[1],\n","            stride=2,\n","            groups=groups,\n","            reduction=reduction,\n","            downsample_kernel_size=downsample_kernel_size,\n","            downsample_padding=downsample_padding\n","        )\n","        self.layer3 = self._make_layer(\n","            block,\n","            planes=256,\n","            blocks=layers[2],\n","            stride=2,\n","            groups=groups,\n","            reduction=reduction,\n","            downsample_kernel_size=downsample_kernel_size,\n","            downsample_padding=downsample_padding\n","        )\n","        self.layer4 = self._make_layer(\n","            block,\n","            planes=512,\n","            blocks=layers[3],\n","            stride=2,\n","            groups=groups,\n","            reduction=reduction,\n","            downsample_kernel_size=downsample_kernel_size,\n","            downsample_padding=downsample_padding\n","        )\n","        self.avg_pool = nn.AvgPool2d(7, stride=1)\n","        self.dropout = nn.Dropout(dropout_p) if dropout_p is not None else None\n","        self.last_linear = nn.Linear(512 * block.expansion, num_classes)\n","        self._initialize_weights()\n","\n","    def _make_layer(self, block, planes, blocks, groups, reduction, stride=1,\n","                    downsample_kernel_size=1, downsample_padding=0):\n","        downsample = None\n","        if stride != 1 or self.inplanes != planes * block.expansion:\n","            downsample = nn.Sequential(\n","                nn.Conv2d(self.inplanes, planes * block.expansion,\n","                          kernel_size=downsample_kernel_size, stride=stride,\n","                          padding=downsample_padding, bias=False),\n","                nn.BatchNorm2d(planes * block.expansion),\n","            )\n","\n","        layers = []\n","        layers.append(block(self.inplanes, planes, groups, reduction, stride,\n","                            downsample))\n","        self.inplanes = planes * block.expansion\n","        for i in range(1, blocks):\n","            layers.append(block(self.inplanes, planes, groups, reduction))\n","\n","        return nn.Sequential(*layers)\n","\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n","                m.weight.data = nn.init.kaiming_normal_(m.weight.data)\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","\n","    def features(self, x):\n","        x = self.layer0(x)\n","        x = self.pool(x)\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","        return x\n","\n","    def logits(self, x):\n","        x = self.avg_pool(x)\n","        if self.dropout is not None:\n","            x = self.dropout(x)\n","        x = x.view(x.size(0), -1)\n","        x = self.last_linear(x)\n","        return x\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = self.logits(x)\n","        return x\n","\n","\n","def initialize_pretrained_model(model, num_classes, settings):\n","    assert num_classes == settings['num_classes'], \\\n","        'num_classes should be {}, but is {}'.format(\n","            settings['num_classes'], num_classes)\n","    model.load_state_dict(model_zoo.load_url(settings['url']), strict=False)\n","    model.input_space = settings['input_space']\n","    model.input_size = settings['input_size']\n","    model.input_range = settings['input_range']\n","    model.mean = settings['mean']\n","    model.std = settings['std']\n","\n","\n","def senet154(num_classes=1000, pretrained='imagenet'):\n","    model = SENet(SEBottleneck, [3, 8, 36, 3], groups=64, reduction=16,\n","                  dropout_p=0.2, num_classes=num_classes)\n","    if pretrained is not None:\n","        settings = pretrained_settings['senet154'][pretrained]\n","        initialize_pretrained_model(model, num_classes, settings)\n","    return model\n","\n","def scsenet154(num_classes=1000, pretrained='imagenet'):\n","    print(\"scsenet154\")\n","    model = SENet(SCSEBottleneck, [3, 8, 36, 3], groups=64, reduction=16,\n","                  dropout_p=0.2, num_classes=num_classes)\n","    if pretrained is not None:\n","        settings = pretrained_settings['senet154'][pretrained]\n","        initialize_pretrained_model(model, num_classes, settings)\n","    return model\n","\n","\n","def se_resnet50(num_classes=1000, pretrained='imagenet'):\n","    model = SENet(SEResNetBottleneck, [3, 4, 6, 3], groups=1, reduction=16,\n","                  dropout_p=None, inplanes=64, input_3x3=False,\n","                  downsample_kernel_size=1, downsample_padding=0,\n","                  num_classes=num_classes)\n","    if pretrained is not None:\n","        settings = pretrained_settings['se_resnet50'][pretrained]\n","        initialize_pretrained_model(model, num_classes, settings)\n","    return model\n","\n","\n","def se_resnet101(num_classes=1000, pretrained='imagenet'):\n","    model = SENet(SEResNetBottleneck, [3, 4, 23, 3], groups=1, reduction=16,\n","                  dropout_p=None, inplanes=64, input_3x3=False,\n","                  downsample_kernel_size=1, downsample_padding=0,\n","                  num_classes=num_classes)\n","    if pretrained is not None:\n","        settings = pretrained_settings['se_resnet101'][pretrained]\n","        initialize_pretrained_model(model, num_classes, settings)\n","    return model\n","\n","\n","def se_resnet152(num_classes=1000, pretrained='imagenet'):\n","    model = SENet(SEResNetBottleneck, [3, 8, 36, 3], groups=1, reduction=16,\n","                  dropout_p=None, inplanes=64, input_3x3=False,\n","                  downsample_kernel_size=1, downsample_padding=0,\n","                  num_classes=num_classes)\n","    if pretrained is not None:\n","        settings = pretrained_settings['se_resnet152'][pretrained]\n","        initialize_pretrained_model(model, num_classes, settings)\n","    return model\n","\n","\n","def se_resnext50_32x4d(num_classes=1000, pretrained='imagenet'):\n","    model = SENet(SEResNeXtBottleneck, [3, 4, 6, 3], groups=32, reduction=16,\n","                  dropout_p=None, inplanes=64, input_3x3=False,\n","                  downsample_kernel_size=1, downsample_padding=0,\n","                  num_classes=num_classes)\n","    if pretrained is not None:\n","        settings = pretrained_settings['se_resnext50_32x4d'][pretrained]\n","        initialize_pretrained_model(model, num_classes, settings)\n","    return model\n","\n","\n","def scse_resnext50_32x4d(num_classes=1000, pretrained='imagenet'):\n","    model = SENet(SCSEResNeXtBottleneck, [3, 4, 6, 3], groups=32, reduction=16,\n","                  dropout_p=None, inplanes=64, input_3x3=False,\n","                  downsample_kernel_size=1, downsample_padding=0,\n","                  num_classes=num_classes)\n","    if pretrained is not None:\n","        settings = pretrained_settings['se_resnext50_32x4d'][pretrained]\n","        initialize_pretrained_model(model, num_classes, settings)\n","    return model\n","\n","\n","def se_resnext101_32x4d(num_classes=1000, pretrained='imagenet'):\n","    model = SENet(SEResNeXtBottleneck, [3, 4, 23, 3], groups=32, reduction=16,\n","                  dropout_p=None, inplanes=64, input_3x3=False,\n","                  downsample_kernel_size=1, downsample_padding=0,\n","                  num_classes=num_classes)\n","    if pretrained is not None:\n","        settings = pretrained_settings['se_resnext101_32x4d'][pretrained]\n","        initialize_pretrained_model(model, num_classes, settings)\n","    return model"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"YEmiREpPoCWI","executionInfo":{"status":"ok","timestamp":1685488252114,"user_tz":180,"elapsed":4,"user":{"displayName":"Antonio Santos","userId":"03265893617080544823"}}},"outputs":[],"source":["class SeResNext50_Unet_2Ssum(nn.Module):\n","    def __init__(self, pretrained='imagenet', **kwargs):\n","        super(SeResNext50_Unet_2Ssum, self).__init__()\n","\n","        encoder_filters = [64, 256, 512, 1024, 2048]\n","        decoder_filters = np.asarray([64, 96, 128, 256, 512]) // 2\n","\n","        self.conv6 = ConvRelu(encoder_filters[-1], decoder_filters[-1])\n","        self.conv6_2 = ConvRelu(decoder_filters[-1] + encoder_filters[-2], decoder_filters[-1])\n","        self.conv7 = ConvRelu(decoder_filters[-1], decoder_filters[-2])\n","        self.conv7_2 = ConvRelu(decoder_filters[-2] + encoder_filters[-3] , decoder_filters[-2] )\n","        self.conv8 = ConvRelu(decoder_filters[-2], decoder_filters[-3])\n","        self.conv8_2 = ConvRelu(decoder_filters[-3] + encoder_filters[-4] , decoder_filters[-3])\n","        self.conv9 = ConvRelu(decoder_filters[-3], decoder_filters[-4])\n","        self.conv9_2 = ConvRelu(decoder_filters[-4] + encoder_filters[-5], decoder_filters[-4])\n","\n","        # self.convx9_3 = ConvRelu(encoder_filters[-4], encoder_filters[-4])\n","\n","\n","        self.conv10 = ConvRelu(decoder_filters[-4], decoder_filters[-5])\n","        self.conv10_s = nn.Sequential(ConvRelu(decoder_filters[-5], decoder_filters[-5]),\n","                                      nn.Conv2d(decoder_filters[-5] , 1, 1, stride=1, padding=0),\n","                                      nn.Sigmoid())\n","        # self.convxx = nn.Sequential(ConvRelu(decoder_filters[-5]*2, decoder_filters[-5]*2),\n","        #                             nn.Conv2d(decoder_filters[-5] * 2, decoder_filters[-5], 1, stride=1, padding=0))\n","\n","        self.res = nn.Conv2d(decoder_filters[-5] * 2, 5, 1, stride=1, padding=0)\n","\n","        self._initialize_weights()\n","\n","        encoder = se_resnext50_32x4d(pretrained=pretrained)\n","        #encoder = torchvision.models.resnet50(pretrained=pretrained)\n","        self.conv1 = nn.Sequential(encoder.layer0.conv1, encoder.layer0.bn1, encoder.layer0.relu1) #encoder.layer0.conv1\n","        self.conv2 = nn.Sequential(encoder.pool, encoder.layer1)\n","        self.conv3 = encoder.layer2\n","        self.conv4 = encoder.layer3\n","        self.conv5 = encoder.layer4\n","\n","\n","    def forward1(self, x):\n","        batch_size, C, H, W = x.shape\n","        xx = F.interpolate(x, scale_factor=0.5, mode='bilinear', align_corners=False)\n","\n","        enc1 = self.conv1(x)\n","        enc2 = self.conv2(enc1)\n","        enc3 = self.conv3(enc2)\n","        enc4 = self.conv4(enc3)\n","        enc5 = self.conv5(enc4)\n","\n","        encx1 = self.conv1(xx)   # 64 128 128\n","        encx2 = self.conv2(encx1) # 64\n","        encx3 = self.conv3(encx2) # 32\n","        encx4 = self.conv4(encx3) # 16\n","        encx5 = self.conv5(encx4) # 8\n","\n","        dec6 = self.conv6(F.interpolate(enc5, scale_factor=2))\n","        dec6 = self.conv6_2(torch.cat([dec6, enc4 ], 1))\n","        dec7 = self.conv7(F.interpolate(dec6, scale_factor=2))\n","        dec7 = self.conv7_2(torch.cat([dec7, enc3], 1))\n","        dec8 = self.conv8(F.interpolate(dec7, scale_factor=2))\n","        dec8 = self.conv8_2(torch.cat([dec8, enc2], 1))\n","        dec9 = self.conv9(F.interpolate(dec8, scale_factor=2))\n","        dec9 = self.conv9_2(torch.cat([dec9,  enc1], 1))   #256\n","\n","        decx6 = self.conv6(F.interpolate(encx5, scale_factor=2))\n","        decx6 = self.conv6_2(torch.cat([decx6, encx4 ], 1))\n","        decx7 = self.conv7(F.interpolate(decx6, scale_factor=2))\n","        decx7 = self.conv7_2(torch.cat([decx7, encx3], 1))\n","        decx8 = self.conv8(F.interpolate(decx7, scale_factor=2))\n","        decx8 = self.conv8_2(torch.cat([decx8, encx2], 1))\n","        decx9 = self.conv9(F.interpolate(decx8, scale_factor=2))\n","        decx9 = self.conv9_2(torch.cat([decx9,  encx1], 1))   #128\n","        #decx9 = self.convx9_3(F.interpolate(decx9, scale_factor=4))\n","\n","\n","        dec10 = self.conv10(F.interpolate(dec9, scale_factor=2))\n","        alpha = self.conv10_s(dec10)\n","        decx10 = self.conv10(F.interpolate(decx9, scale_factor=4))\n","\n","        dec = alpha * dec10 + (1-alpha)*decx10\n","\n","        return dec\n","\n","    def forward(self, x):\n","        dec10_0 = self.forward1(x[:, :3, :, :])\n","        dec10_1 = self.forward1(x[:, 3:, :, :])\n","\n","        dec10 = torch.cat([dec10_0, dec10_1], 1)\n","\n","        return self.res(dec10)\n","\n","\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Linear):\n","                m.weight.data = nn.init.kaiming_normal_(m.weight.data)\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()"]},{"cell_type":"markdown","metadata":{"id":"Jbp9HIBOoO4H"},"source":["## modelMscale2"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4178,"status":"ok","timestamp":1685458792613,"user":{"displayName":"Antonio Santos","userId":"03265893617080544823"},"user_tz":180},"id":"8FP0bCaeP1Qw","outputId":"ec45231b-3ca6-408b-d575-a7002880a737"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: thop in /usr/local/lib/python3.10/dist-packages (0.1.1.post2209072238)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from thop) (2.0.1+cu118)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->thop) (3.12.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->thop) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->thop) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->thop) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->thop) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->thop) (16.0.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->thop) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->thop) (1.3.0)\n"]}],"source":["!pip install thop"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1685458792613,"user":{"displayName":"Antonio Santos","userId":"03265893617080544823"},"user_tz":180},"id":"BzErVOmmFYtF"},"outputs":[],"source":["import numpy as np\n","\n","import torch\n","from torch import nn\n","import torch.nn.functional as F\n","import torchvision.models\n","#import apex\n","import apex.parallel.sync_batchnorm as BN\n","#from .dpn import dpn92\n","from torch.nn.parameter import Parameter\n","from thop import profile\n","#from .antialias import Downsample as downsamp\n","\n","class ResidualDownSample(nn.Module):\n","    def __init__(self, in_channels, bias=False):\n","        super(ResidualDownSample, self).__init__()\n","        self.bot = nn.Sequential(downsamp(channels=in_channels,filt_size=3,stride=2),\n","                                nn.Conv2d(in_channels, in_channels*2, 1, stride=1, padding=0, bias=bias))\n","\n","    def forward(self, x):\n","        out = self.bot(x)\n","        return out\n","\n","class DownSample(nn.Module):\n","    def __init__(self, in_channels, scale_factor, stride=2, kernel_size=3):\n","        super(DownSample, self).__init__()\n","        self.scale_factor = int(np.log2(scale_factor))\n","\n","        modules_body = []\n","        for i in range(self.scale_factor):\n","            modules_body.append(ResidualDownSample(in_channels))\n","            in_channels = int(in_channels * stride)\n","\n","        self.body = nn.Sequential(*modules_body)\n","\n","    def forward(self, x):\n","        x = self.body(x)\n","        return x\n","\n","class ResidualUpSample(nn.Module):\n","    def __init__(self, in_channels, bias=False):\n","        super(ResidualUpSample, self).__init__()\n","\n","        self.bot = nn.Sequential(nn.Upsample(scale_factor=2, mode='bilinear', align_corners=bias),\n","                                nn.Conv2d(in_channels, in_channels//2, 1, stride=1, padding=0, bias=bias))\n","\n","    def forward(self, x):\n","        out = self.bot(x)\n","\n","        return out\n","\n","class UpSample(nn.Module):\n","    def __init__(self, in_channels, scale_factor, stride=2, kernel_size=3):\n","        super(UpSample, self).__init__()\n","        self.scale_factor = int(np.log2(scale_factor))\n","\n","        modules_body = []\n","        for i in range(self.scale_factor):\n","            modules_body.append(ResidualUpSample(in_channels))\n","            in_channels = int(in_channels // stride)\n","\n","        self.body = nn.Sequential(*modules_body)\n","\n","    def forward(self, x):\n","        x = self.body(x)\n","        return x\n","\n","\n","class ConvReluBN(nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size=3):\n","        super(ConvReluBN, self).__init__()\n","        self.layer = nn.Sequential(\n","            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, padding=1),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True)\n","        )\n","    def forward(self, x):\n","        return self.layer(x)\n","\n","\n","class ConvBNReluNkernel(nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size=1, BN = True):\n","        super(ConvBNReluNkernel, self).__init__()\n","        self.kernel_size = kernel_size\n","        if kernel_size == 5:\n","            self.conv= nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size = self.kernel_size, padding=2)\n","        if kernel_size == 3:\n","            self.conv= nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size = self.kernel_size, padding=1)\n","        if kernel_size == 1:\n","            self.conv= nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size = self.kernel_size, padding=0)\n","        if BN == True:\n","            self.BN = nn.BatchNorm2d(out_channels)\n","        self.relu = nn.ReLU(inplace=True)\n","\n","    def forward(self, x):\n","        y = self.relu(self.BN(self.conv(x)))\n","        return y\n","\n","\n","class Attention_block(nn.Module):\n","    def __init__(self, F_c, F_de,  reduction=16, concat=True):\n","        super(Attention_block,self).__init__()\n","        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n","        self.fc1 = nn.Conv2d(F_c, F_c//reduction, kernel_size=1, stride=1, padding=0, bias=False)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.fc2 =  nn.Conv2d(F_c//reduction, F_de, kernel_size=1, stride=1, padding=0, bias=False)\n","\n","        self.sigmoid = nn.Sigmoid()\n","\n","\n","        self.spatial_se = nn.Sequential(nn.Conv2d(F_de, 1, kernel_size=1,\n","                                                  stride=1, padding=0, bias=False),\n","                                        nn.Sigmoid())\n","        self.concat = concat\n","\n","    def forward(self,f, x):\n","        f=self.avg_pool(f)\n","        f = self.fc1(f)\n","        f = self.relu(f)\n","        f = self.fc2(f)\n","        chn_se = self.sigmoid(f)\n","        chn_se = chn_se * x\n","\n","        spa_se = self.spatial_se(x)\n","        spa_se = x * spa_se\n","\n","        if self.concat:\n","            return torch.cat([chn_se, spa_se], dim=1)\n","        else:\n","            return chn_se + spa_se\n","\n","\n","class ConvRelu(nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size=3):\n","        super(ConvRelu, self).__init__()\n","        self.layer = nn.Sequential(\n","            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, padding=1),\n","            nn.ReLU(inplace=True, )\n","        )\n","    #@autocast()\n","    def forward(self, x):\n","        return self.layer(x)\n","\n","class BasicResBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size=3, groups=16):\n","        super(BasicResBlock, self).__init__()\n","        self.layer = nn.Sequential(\n","            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, padding=1),\n","            nn.GroupNorm(num_groups=4, num_channels=out_channels),\n","            nn.ReLU(inplace=True)\n","        )\n","        # self.conv3 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, padding=1)\n","        # self.norm = nn.GroupNorm(num_groups=16, num_channels=out_channels)\n","        # self.relu= nn.ReLU(inplace=True)\n","    #@autocast()\n","    def forward(self, x):\n","        x = self.layer(x)\n","        # x = self.conv3(x)\n","        # x = self.norm(x)\n","        #\n","        # x = self.relu(x)\n","        return x\n","\n","class SCSEModule2(nn.Module):\n","    # according to https://arxiv.org/pdf/1808.08127.pdf concat is better\n","    def __init__(self, channels, reduction=16, concat=False):\n","        super(SCSEModule2, self).__init__()\n","        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n","        self.fc1 = nn.Conv2d(channels, channels // reduction, kernel_size=1,\n","                             padding=0)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.fc2 = nn.Conv2d(channels // reduction, channels, kernel_size=1,\n","                             padding=0)\n","        self.sigmoid = nn.Sigmoid()\n","\n","        self.spatial_se = nn.Sequential(nn.Conv2d(channels, 1, kernel_size=1,\n","                                                  stride=1, padding=0, bias=False),\n","                                        nn.Sigmoid())\n","        self.concat = concat\n","\n","    def forward(self, x):\n","        module_input = x\n","\n","        x = self.avg_pool(x)\n","        x = self.fc1(x)\n","        x = self.relu(x)\n","        x = self.fc2(x)\n","        chn_se = self.sigmoid(x)\n","        chn_se = chn_se * module_input + module_input\n","\n","        spa_se = self.spatial_se(module_input)\n","        #chn_se = chn_se * spa_se\n","        spa_se = module_input * spa_se + module_input\n","        if self.concat:\n","            return torch.cat([chn_se, spa_se], dim=1)\n","        else:\n","            return (chn_se + spa_se)/2\n","\n","\n","class SCSEModule(nn.Module):\n","    # according to https://arxiv.org/pdf/1808.08127.pdf concat is better\n","    def __init__(self, channels, reduction=16, concat=False):\n","        super(SCSEModule, self).__init__()\n","        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n","        self.fc1 = nn.Conv2d(channels, channels // reduction, kernel_size=1,\n","                             padding=0)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.fc2 = nn.Conv2d(channels // reduction, channels, kernel_size=1,\n","                             padding=0)\n","        self.sigmoid = nn.Sigmoid()\n","\n","        self.spatial_se = nn.Sequential(nn.Conv2d(channels, 1, kernel_size=1,\n","                                                  stride=1, padding=0, bias=False),\n","                                        nn.Sigmoid())\n","        self.concat = concat\n","\n","    def forward(self, x):\n","        module_input = x\n","\n","        x = self.avg_pool(x)\n","        x = self.fc1(x)\n","        x = self.relu(x)\n","        x = self.fc2(x)\n","        chn_se = self.sigmoid(x)\n","        chn_se = chn_se * module_input\n","\n","        spa_se = self.spatial_se(module_input)\n","        spa_se = module_input * spa_se\n","        if self.concat:\n","            return torch.cat([chn_se, spa_se], dim=1)\n","        else:\n","            return chn_se + spa_se\n","\n","\n","\n","class SeResNext50_Unet_MScale(nn.Module):\n","    def __init__(self, pretrained='imagenet', **kwargs):\n","        super(SeResNext50_Unet_MScale, self).__init__()\n","\n","        encoder_filters = [64, 256, 512, 1024, 2048]\n","        decoder_filters = [48,  128, 256, 256, 2048]\n","        f_filter = 24\n","\n","        # self.convF2 = ConvRelu(encoder_filters[1]+encoder_filters[1], encoder_filters[1])\n","        # self.convF3 = ConvRelu(encoder_filters[2]+encoder_filters[1], encoder_filters[2])\n","        # self.convF4 = ConvRelu(encoder_filters[3]+encoder_filters[1], encoder_filters[3])\n","\n","        # self.convF1 = nn.Sequential(ConvRelu(f_filter + encoder_filters[0], encoder_filters[0]), BasicResBlock(encoder_filters[0], encoder_filters[0]))\n","        # self.convF2 = nn.Sequential(ConvRelu(encoder_filters[1]+ encoder_filters[1], encoder_filters[1]), BasicResBlock(encoder_filters[1], encoder_filters[1]))\n","        # self.convF3 = nn.Sequential(ConvRelu(encoder_filters[1]+ encoder_filters[2], encoder_filters[2]), BasicResBlock(encoder_filters[2], encoder_filters[2]))\n","        self.convF1 = nn.Sequential( BasicResBlock(f_filter + encoder_filters[0], encoder_filters[0]))\n","        self.convF2 = nn.Sequential( BasicResBlock(f_filter + encoder_filters[1], encoder_filters[1]))\n","        #self.convF3 = nn.Sequential(BasicResBlock(f_filter +encoder_filters[2], encoder_filters[2]))\n","        #self.convF4 = nn.Sequential(ConvRelu(encoder_filters[1]+ encoder_filters[3], encoder_filters[3]), BasicResBlock(encoder_filters[3], encoder_filters[3]))\n","        self.xconv256 =  nn.Sequential(BasicResBlock(3, f_filter))\n","        self.xconv128 =  nn.Sequential(BasicResBlock(3, f_filter))\n","        #self.xconv64 = nn.Sequential(BasicResBlock(3, f_filter))\n","        #self.xconv32 =  nn.Sequential(ConvReluBN(in_channels=3, out_channels=64), encoder.layer1 )\n","        self.dconv5 = ConvRelu(encoder_filters[4], decoder_filters[3])\n","        self.dconv5_2 = ConvRelu(encoder_filters[3]+decoder_filters[3], decoder_filters[3])\n","\n","        self.dconv6 = ConvRelu(decoder_filters[3], decoder_filters[2])\n","        self.dconv6_2 = ConvRelu(encoder_filters[2]+decoder_filters[2], decoder_filters[2])\n","        self.dconv7 = ConvRelu(decoder_filters[2], decoder_filters[1])\n","        self.dconv7_2 = ConvRelu(encoder_filters[1]+decoder_filters[1], decoder_filters[1])\n","        self.dconv8 = ConvRelu(decoder_filters[1], decoder_filters[0])\n","        self.dconv8_2 = ConvRelu(encoder_filters[0]+decoder_filters[0], decoder_filters[0])\n","\n","        self.dconv9 = ConvRelu(decoder_filters[0], decoder_filters[0])\n","\n","        self.res = nn.Conv2d(decoder_filters[0]*2, 5, 1, stride=1, padding=0)\n","\n","        self._initialize_weights()\n","\n","        encoder = se_resnext50_32x4d(pretrained=pretrained)\n","        #encoder = torchvision.models.resnet50(pretrained=pretrained)\n","        self.conv1 = nn.Sequential(encoder.layer0.conv1, encoder.layer0.bn1, encoder.layer0.relu1) #encoder.layer0.conv1\n","        self.conv2 = nn.Sequential(encoder.pool, encoder.layer1)\n","        self.conv3 = encoder.layer2\n","        self.conv4 = encoder.layer3\n","        self.conv5 = encoder.layer4\n","\n","        #self.xconv128 =  nn.Sequential(ConvReluBN(in_channels=3, out_channels=64), encoder.layer1 )\n","        #self.xconv64 = nn.Sequential(ConvReluBN(in_channels=3, out_channels=64), encoder.layer1 )\n","        #self.xconv32 =  nn.Sequential(ConvReluBN(in_channels=3, out_channels=64), encoder.layer1 )\n","\n","    def forward1(self, x):\n","        batch_size, C, H, W = x.shape\n","        x256 = F.interpolate(x, scale_factor=0.5)\n","        x128 = F.interpolate(x, scale_factor=0.25)\n","        #x64 = F.interpolate(x, scale_factor=0.125)\n","        #x32 = F.interpolate(x, scale_factor=0.0625)\n","\n","        enc1 = self.conv1(x)\n","        enc2 = self.conv2(enc1)\n","        enc3 = self.conv3(enc2)\n","        enc4 = self.conv4(enc3)\n","        enc5 = self.conv5(enc4)\n","\n","        enc256 = self.xconv256(x256)\n","        enc128 = self.xconv128(x128)\n","        #enc64 = self.xconv64(x64)\n","        #enc32 = self.xconv32(x32)\n","\n","        enc1 = self.convF1(torch.cat([enc1, enc256],1))\n","        enc2 = self.convF2(torch.cat([enc2, enc128], 1))\n","        #enc3 = self.convF3(torch.cat([enc3, enc64], 1))\n","        #enc4 = self.convF4(torch.cat([enc4, enc32], 1))\n","\n","\n","        dec5 = self.dconv5(F.interpolate(enc5, scale_factor=2))\n","        dec5 = self.dconv5_2(torch.cat([dec5,enc4], 1))\n","        dec6 = self.dconv6(F.interpolate(dec5, scale_factor=2))\n","        dec6 = self.dconv6_2(torch.cat([dec6,enc3], 1))\n","        dec7 = self.dconv7(F.interpolate(dec6, scale_factor=2))\n","        dec7 = self.dconv7_2(torch.cat([dec7,enc2], 1))\n","        dec8 = self.dconv8(F.interpolate(dec7, scale_factor=2))\n","        dec8 = self.dconv8_2(torch.cat([dec8,enc1], 1))\n","\n","        dec9 = self.dconv9(F.interpolate(dec8,scale_factor=2))\n","\n","        return dec9\n","\n","    def forward(self, x):\n","        dec10_0 = self.forward1(x[:, :3, :, :])\n","        dec10_1 = self.forward1(x[:, 3:, :, :])\n","\n","        dec10 = torch.cat([dec10_0, dec10_1], 1)\n","\n","        return self.res(dec10)\n","\n","\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Linear):\n","                m.weight.data = nn.init.kaiming_normal_(m.weight.data)\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","\n","class SeResNext50_Unet_MScale2(nn.Module):\n","    def __init__(self, pretrained='imagenet', **kwargs):\n","        super(SeResNext50_Unet_MScale2, self).__init__()\n","\n","        encoder_filters = [64, 256, 512, 1024, 2048]\n","        decoder_filters = [48,  128, 256, 256, 2048]\n","        f_filter = 24\n","\n","        # self.convF2 = ConvRelu(encoder_filters[1]+encoder_filters[1], encoder_filters[1])\n","        # self.convF3 = ConvRelu(encoder_filters[2]+encoder_filters[1], encoder_filters[2])\n","        # self.convF4 = ConvRelu(encoder_filters[3]+encoder_filters[1], encoder_filters[3])\n","\n","        # self.convF1 = nn.Sequential(ConvRelu(f_filter + encoder_filters[0], encoder_filters[0]), BasicResBlock(encoder_filters[0], encoder_filters[0]))\n","        # self.convF2 = nn.Sequential(ConvRelu(encoder_filters[1]+ encoder_filters[1], encoder_filters[1]), BasicResBlock(encoder_filters[1], encoder_filters[1]))\n","        # self.convF3 = nn.Sequential(ConvRelu(encoder_filters[1]+ encoder_filters[2], encoder_filters[2]), BasicResBlock(encoder_filters[2], encoder_filters[2]))\n","        #self.convF1 = nn.Sequential( BasicResBlock(f_filter + encoder_filters[0], encoder_filters[0]))\n","        self.convF2 = nn.Sequential( BasicResBlock(f_filter + encoder_filters[1], encoder_filters[1]))\n","        #self.convF3 = nn.Sequential(BasicResBlock(f_filter +encoder_filters[2], encoder_filters[2]))\n","        #self.convF4 = nn.Sequential(ConvRelu(encoder_filters[1]+ encoder_filters[3], encoder_filters[3]), BasicResBlock(encoder_filters[3], encoder_filters[3]))\n","        #self.xconv256 =  nn.Sequential(BasicResBlock(3, f_filter))\n","        self.xconv128 =  nn.Sequential(BasicResBlock(3, f_filter))\n","        #self.xconv64 = nn.Sequential(BasicResBlock(3, f_filter))\n","        #self.xconv32 =  nn.Sequential(ConvReluBN(in_channels=3, out_channels=64), encoder.layer1 )\n","        #self.dconv5 = ConvRelu(encoder_filters[4], decoder_filters[3])\n","        #self.dconv5_2 = ConvRelu(encoder_filters[3]+decoder_filters[3], decoder_filters[3])\n","\n","        self.dconv6 = ConvReluBN(encoder_filters[3], decoder_filters[2])\n","        self.dconv6_2 = ConvRelu(encoder_filters[2]+decoder_filters[2], decoder_filters[2])\n","        self.dconv7 = ConvRelu(decoder_filters[2], decoder_filters[1])\n","        self.dconv7_2 = ConvRelu(encoder_filters[1]+decoder_filters[1], decoder_filters[1])\n","        self.dconv8 = ConvRelu(decoder_filters[1], decoder_filters[0])\n","        self.dconv8_2 = ConvRelu(encoder_filters[0]+decoder_filters[0], decoder_filters[0])\n","        self.dconv8_2 = nn.Sequential( ConvRelu(encoder_filters[0]+decoder_filters[0], decoder_filters[0]), SCSEModule(decoder_filters[0], reduction=2, concat=True))\n","\n","        self.dconv9 = ConvRelu(decoder_filters[0]*2, decoder_filters[0])\n","\n","        self.res = nn.Conv2d(decoder_filters[0]*2, 5, 1, stride=1, padding=0)\n","\n","        self._initialize_weights()\n","\n","        encoder = se_resnext50_32x4d(pretrained=pretrained)\n","        #encoder = torchvision.models.resnet50(pretrained=pretrained)\n","        self.conv1 = nn.Sequential(encoder.layer0.conv1, encoder.layer0.bn1, encoder.layer0.relu1) #encoder.layer0.conv1\n","        self.conv2 = nn.Sequential(encoder.pool, encoder.layer1)\n","        self.conv3 = encoder.layer2\n","        self.conv4 = encoder.layer3\n","        #self.conv5 = encoder.layer4\n","\n","        #self.xconv128 =  nn.Sequential(ConvReluBN(in_channels=3, out_channels=64), encoder.layer1 )\n","        #self.xconv64 = nn.Sequential(ConvReluBN(in_channels=3, out_channels=64), encoder.layer1 )\n","        #self.xconv32 =  nn.Sequential(ConvReluBN(in_channels=3, out_channels=64), encoder.layer1 )\n","\n","    def forward1(self, x):\n","        batch_size, C, H, W = x.shape\n","        #x256 = F.interpolate(x, scale_factor=0.5)\n","        x128 = F.interpolate(x, scale_factor=0.25)\n","        #x64 = F.interpolate(x, scale_factor=0.125)\n","        #x32 = F.interpolate(x, scale_factor=0.0625)\n","\n","        enc1 = self.conv1(x)\n","        enc2 = self.conv2(enc1)\n","        enc3 = self.conv3(enc2)\n","        enc4 = self.conv4(enc3)\n","        #enc5 = self.conv5(enc4)\n","\n","        #enc256 = self.xconv256(x256)\n","        enc128 = self.xconv128(x128)\n","        #enc64 = self.xconv64(x64)\n","        #enc32 = self.xconv32(x32)\n","\n","        #enc1 = self.convF1(torch.cat([enc1, enc256],1))\n","        enc2 = self.convF2(torch.cat([enc2, enc128], 1))\n","        #enc3 = self.convF3(torch.cat([enc3, enc64], 1))\n","        #enc4 = self.convF4(torch.cat([enc4, enc32], 1))\n","\n","\n","        #dec5 = self.dconv5(F.interpolate(enc5, scale_factor=2))\n","        #dec5 = self.dconv5_2(torch.cat([dec5,enc4], 1))\n","        dec6 = self.dconv6(F.interpolate(enc4, scale_factor=2))\n","        dec6 = self.dconv6_2(torch.cat([dec6,enc3], 1))\n","        dec7 = self.dconv7(F.interpolate(dec6, scale_factor=2))\n","        dec7 = self.dconv7_2(torch.cat([dec7,enc2], 1))\n","        dec8 = self.dconv8(F.interpolate(dec7, scale_factor=2))\n","        dec8 = self.dconv8_2(torch.cat([dec8,enc1], 1))\n","\n","        dec9 = self.dconv9(F.interpolate(dec8,scale_factor=2))\n","\n","        return dec9\n","\n","    def forward(self, x):\n","        dec10_0 = self.forward1(x[:, :3, :, :])\n","        dec10_1 = self.forward1(x[:, 3:, :, :])\n","\n","        dec10 = torch.cat([dec10_0, dec10_1], 1)\n","\n","        return self.res(dec10)\n","\n","\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Linear):\n","                m.weight.data = nn.init.kaiming_normal_(m.weight.data)\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","\n","class SeResNext50_Unet_Double(nn.Module):\n","    def __init__(self, pretrained='imagenet', **kwargs):\n","        super(SeResNext50_Unet_Double, self).__init__()\n","\n","        encoder_filters = [64, 256, 512, 1024, 2048]\n","        decoder_filters = np.asarray([64, 96, 128, 256, 512]) // 2\n","\n","        self.conv6 = ConvRelu(encoder_filters[-1], decoder_filters[-1])\n","        self.conv6_2 = ConvRelu(decoder_filters[-1] + encoder_filters[-2], decoder_filters[-1])\n","        self.conv7 = ConvRelu(decoder_filters[-1], decoder_filters[-2])\n","        self.conv7_2 = ConvRelu(decoder_filters[-2] + encoder_filters[-3], decoder_filters[-2])\n","        self.conv8 = ConvRelu(decoder_filters[-2], decoder_filters[-3])\n","        self.conv8_2 = ConvRelu(decoder_filters[-3] + encoder_filters[-4], decoder_filters[-3])\n","        self.conv9 = ConvRelu(decoder_filters[-3], decoder_filters[-4])\n","        self.conv9_2 = ConvRelu(decoder_filters[-4] + encoder_filters[-5], decoder_filters[-4])\n","        self.conv10 = ConvRelu(decoder_filters[-4], decoder_filters[-5])\n","\n","\n","        self.res = nn.Conv2d(decoder_filters[-5] * 2, 5, 1, stride=1, padding=0)\n","\n","        self._initialize_weights()\n","\n","        encoder = se_resnext50_32x4d(pretrained=pretrained)\n","        #encoder = torchvision.models.resnet50(pretrained=pretrained)\n","\n","        # conv1_new = nn.Conv2d(6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","        # _w = encoder.layer0.conv1.state_dict()\n","        # _w['weight'] = torch.cat([0.5 * _w['weight'], 0.5 * _w['weight']], 1)\n","        # conv1_new.load_state_dict(_w)\n","        self.conv1 = nn.Sequential(encoder.layer0.conv1, encoder.layer0.bn1, encoder.layer0.relu1) #encoder.layer0.conv1\n","        self.conv2 = nn.Sequential(encoder.pool, encoder.layer1)\n","        self.conv3 = encoder.layer2\n","        self.conv4 = encoder.layer3\n","        self.conv5 = encoder.layer4\n","\n","\n","    def forward1(self, x):\n","        batch_size, C, H, W = x.shape\n","\n","        enc1 = self.conv1(x)\n","        enc2 = self.conv2(enc1)\n","        enc3 = self.conv3(enc2)\n","        enc4 = self.conv4(enc3)\n","        enc5 = self.conv5(enc4)\n","\n","        dec6 = self.conv6(F.interpolate(enc5, scale_factor=2))\n","        dec6 = self.conv6_2(torch.cat([dec6, enc4 ], 1))\n","\n","        dec7 = self.conv7(F.interpolate(dec6, scale_factor=2))\n","        dec7 = self.conv7_2(torch.cat([dec7, enc3 ], 1))\n","\n","        dec8 = self.conv8(F.interpolate(dec7, scale_factor=2))\n","        dec8 = self.conv8_2(torch.cat([dec8, enc2 ], 1))\n","\n","        dec9 = self.conv9(F.interpolate(dec8, scale_factor=2))\n","        dec9 = self.conv9_2(torch.cat([dec9,  enc1  ], 1))\n","\n","        dec10 = self.conv10(F.interpolate(dec9, scale_factor=2))\n","\n","        return dec10\n","\n","\n","    def forward(self, x):\n","        dec10_0 = self.forward1(x[:, :3, :, :])\n","        dec10_1 = self.forward1(x[:, 3:, :, :])\n","\n","        dec10 = torch.cat([dec10_0, dec10_1], 1)\n","\n","        return self.res(dec10)\n","\n","\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Linear):\n","                m.weight.data = nn.init.kaiming_normal_(m.weight.data)\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","\n","class SeResNext50_Unet_MultiScale(nn.Module):\n","    def __init__(self, pretrained='imagenet', **kwargs):\n","        super(SeResNext50_Unet_MultiScale, self).__init__()\n","\n","        #encoder_filters = [64, 256, 512, 1024, 2048]\n","        encoder_filters = [128, 256, 512, 1024, 2048]\n","        fuse_filter = 64\n","\n","        self.down12 = DownSample(encoder_filters[0], 2)\n","        self.down13 = DownSample(encoder_filters[0]*2, 2)\n","        self.down23 = DownSample(encoder_filters[1], 2)\n","        self.up21 = UpSample(encoder_filters[1], 2)\n","        self.up31 = UpSample(encoder_filters[2]//2, 2)\n","        self.up32 = UpSample(encoder_filters[2], 2)\n","\n","        # self.convF1 = ConvBNReluNkernel(encoder_filters[0], decoder_filters[0])\n","        # self.convF2 = ConvBNReluNkernel(encoder_filters[1], decoder_filters[1])\n","        # self.convF3 = ConvBNReluNkernel(encoder_filters[2], decoder_filters[2])\n","        self.conv0 = ConvRelu(encoder_filters[0]//2, encoder_filters[0])\n","        self.convF1 = nn.Sequential(ConvRelu(encoder_filters[0], encoder_filters[0]), SCSEModule(encoder_filters[0], reduction=4, concat=True))\n","        self.conv1_1 = ConvRelu(encoder_filters[0]*2, encoder_filters[0])\n","        self.convF2 = nn.Sequential(ConvRelu(encoder_filters[1], encoder_filters[1]), SCSEModule(encoder_filters[1], reduction=8, concat=True))\n","        self.conv2_1 = ConvRelu(encoder_filters[1]*2, encoder_filters[1])\n","        self.convF3 = nn.Sequential(ConvRelu(encoder_filters[2], encoder_filters[2]), SCSEModule(encoder_filters[2], reduction=16, concat=True))\n","        self.conv3_1 = ConvRelu(encoder_filters[2]*2, encoder_filters[2])\n","\n","        self.conv1_2 = ConvRelu(encoder_filters[0] * 2, fuse_filter)\n","        self.conv2_2 = ConvRelu(encoder_filters[1] * 2, fuse_filter)\n","        self.conv3_2 = ConvRelu(encoder_filters[2] * 2, fuse_filter*2)\n","        self.up31_2 = UpSample(fuse_filter*2, 4)   #32\n","        self.up21_2 = UpSample(fuse_filter, 2)   #32\n","\n","        self.conv4 = ConvRelu(fuse_filter * 2, fuse_filter)  # 32+32+64\n","        self.conv4_2 = nn.Conv2d(fuse_filter, fuse_filter, 1, stride=1, padding=0)\n","        self.relu = nn.ReLU(inplace=True)\n","\n","        self.res = nn.Conv2d(fuse_filter*2, 5, 1, stride=1, padding=0)\n","\n","        self._initialize_weights()\n","\n","        encoder = se_resnext50_32x4d(pretrained=pretrained)\n","        #encoder = torchvision.models.resnet50(pretrained=pretrained)\n","        self.conv1 = nn.Sequential(encoder.layer0.conv1, encoder.layer0.bn1, encoder.layer0.relu1) #encoder.layer0.conv1\n","        self.conv2 = nn.Sequential(encoder.pool, encoder.layer1)\n","        self.conv3 = encoder.layer2\n","        #self.conv4 = encoder.layer3\n","\n","\n","    def forward1(self, x):\n","        batch_size, C, H, W = x.shape\n","\n","        enc1 = self.conv1(x)\n","        enc2 = self.conv2(enc1)\n","        enc3 = self.conv3(enc2)\n","\n","        enc1 = self.conv0(enc1)\n","\n","        f12 = self.down12(enc1)\n","        f13 = self.down13(f12)\n","        f23 = self.down23(enc2)\n","        f21 = self.up21(enc2)\n","        f32 = self.up32(enc3)\n","        f31 = self.up31(f32)\n","\n","        fusion1 = self.convF1(enc1+f21+f31)\n","        fusion1 = self.conv1_1(fusion1)\n","        fusion2 = self.convF2(enc2+f12+f32)\n","        fusion2 = self.conv2_1(fusion2)\n","        fusion3 = self.convF3(enc3+f23+f13)\n","        fusion3 = self.conv3_1(fusion3)\n","\n","        dec1 = self.conv1_2(torch.cat([enc1, fusion1], 1))\n","        dec2 = self.conv2_2(torch.cat([enc2, fusion2], 1))\n","        dec3 = self.conv3_2(torch.cat([enc3, fusion3], 1))\n","\n","        dec2 = self.up21_2(dec2)\n","        dec3 = self.up31_2(dec3)\n","        dec4 = self.conv4(torch.cat([dec1, dec2, dec3], 1))\n","        dec4 = self.conv4_2(F.interpolate(dec4, scale_factor=2, mode='bilinear'))\n","        dec4 = self.relu(dec4)\n","\n","        return dec4\n","\n","    def forward(self, x):\n","        dec10_0 = self.forward1(x[:, :3, :, :])\n","        dec10_1 = self.forward1(x[:, 3:, :, :])\n","\n","        dec10 = torch.cat([dec10_0, dec10_1], 1)\n","\n","        return self.res(dec10)\n","\n","\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Linear):\n","                m.weight.data = nn.init.kaiming_normal_(m.weight.data)\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","\n","class SeResNext50_Unet_2SUnet(nn.Module):\n","    def __init__(self, pretrained='imagenet', **kwargs):\n","        super(SeResNext50_Unet_2SUnet, self).__init__()\n","\n","        encoder_filters = [64, 256, 512, 1024, 2048]\n","        decoder_filters = np.asarray([64, 96, 128, 256, 512]) // 2\n","\n","        self.conv6 = ConvRelu(encoder_filters[-1], decoder_filters[-1])\n","        self.conv6_2 = ConvRelu(decoder_filters[-1] + encoder_filters[-2], decoder_filters[-1])\n","        self.conv7 = ConvRelu(decoder_filters[-1], decoder_filters[-2])\n","        self.conv7_2 = ConvRelu(decoder_filters[-2] + encoder_filters[-3] , decoder_filters[-2] )\n","        self.conv8 = ConvRelu(decoder_filters[-2], decoder_filters[-3])\n","        self.conv8_2 = ConvRelu(decoder_filters[-3] + encoder_filters[-4] , decoder_filters[-3])\n","        self.conv9 = ConvRelu(decoder_filters[-3], decoder_filters[-4])\n","        self.conv9_2 = ConvRelu(decoder_filters[-4] + encoder_filters[-5], decoder_filters[-4])\n","        # self.conv9_3 = nn.Sequential(ConvRelu(encoder_filters[-4], encoder_filters[-4]), nn.Sigmoid())\n","        # self.convx9_3 = ConvRelu(encoder_filters[-4], encoder_filters[-4])\n","\n","        self.conv10 = ConvRelu(decoder_filters[-4], decoder_filters[-5])\n","        self.convxx = nn.Sequential(ConvRelu(decoder_filters[-5]*2, decoder_filters[-5]*2),\n","                                    nn.Conv2d(decoder_filters[-5] * 2, decoder_filters[-5], 1, stride=1, padding=0))\n","\n","\n","        self.res = nn.Conv2d(decoder_filters[-5] * 2, 5, 1, stride=1, padding=0)\n","\n","        self._initialize_weights()\n","\n","        encoder = se_resnext50_32x4d(pretrained=pretrained)\n","        #encoder = torchvision.models.resnet50(pretrained=pretrained)\n","        self.conv1 = nn.Sequential(encoder.layer0.conv1, encoder.layer0.bn1, encoder.layer0.relu1) #encoder.layer0.conv1\n","        self.conv2 = nn.Sequential(encoder.pool, encoder.layer1)\n","        self.conv3 = encoder.layer2\n","        self.conv4 = encoder.layer3\n","        self.conv5 = encoder.layer4\n","\n","\n","    def forward1(self, x):\n","        batch_size, C, H, W = x.shape\n","        xx = F.interpolate(x, scale_factor=0.5, mode='bilinear', align_corners=False)\n","\n","        enc1 = self.conv1(x)\n","        enc2 = self.conv2(enc1)\n","        enc3 = self.conv3(enc2)\n","        enc4 = self.conv4(enc3)\n","        enc5 = self.conv5(enc4)\n","\n","        encx1 = self.conv1(xx)   # 64 128 128\n","        encx2 = self.conv2(encx1) # 64\n","        encx3 = self.conv3(encx2) # 32\n","        encx4 = self.conv4(encx3) # 16\n","        encx5 = self.conv5(encx4) # 8\n","\n","        dec6 = self.conv6(F.interpolate(enc5, scale_factor=2))\n","        dec6 = self.conv6_2(torch.cat([dec6, enc4 ], 1))\n","        dec7 = self.conv7(F.interpolate(dec6, scale_factor=2))\n","        dec7 = self.conv7_2(torch.cat([dec7, enc3], 1))\n","        dec8 = self.conv8(F.interpolate(dec7, scale_factor=2))\n","        dec8 = self.conv8_2(torch.cat([dec8, enc2], 1))\n","        dec9 = self.conv9(F.interpolate(dec8, scale_factor=2))\n","        dec9 = self.conv9_2(torch.cat([dec9,  enc1], 1))   #256\n","\n","\n","        decx6 = self.conv6(F.interpolate(encx5, scale_factor=2))\n","        decx6 = self.conv6_2(torch.cat([decx6, encx4 ], 1))\n","        decx7 = self.conv7(F.interpolate(decx6, scale_factor=2))\n","        decx7 = self.conv7_2(torch.cat([decx7, encx3], 1))\n","        decx8 = self.conv8(F.interpolate(decx7, scale_factor=2))\n","        decx8 = self.conv8_2(torch.cat([decx8, encx2], 1))\n","        decx9 = self.conv9(F.interpolate(decx8, scale_factor=2))\n","        decx9 = self.conv9_2(torch.cat([decx9,  encx1], 1))   #128\n","        #decx9 = self.convx9_3(F.interpolate(decx9, scale_factor=4))\n","\n","\n","        dec10 = self.conv10(F.interpolate(dec9, scale_factor=2))\n","        decx10 = self.conv10(F.interpolate(decx9, scale_factor=4))\n","\n","        dec = self.convxx(torch.cat([dec10, decx10], 1))\n","\n","        return dec\n","\n","    def forward(self, x):\n","        dec10_0 = self.forward1(x[:, :3, :, :])\n","        dec10_1 = self.forward1(x[:, 3:, :, :])\n","\n","        dec10 = torch.cat([dec10_0, dec10_1], 1)\n","\n","        return self.res(dec10)\n","\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Linear):\n","                m.weight.data = nn.init.kaiming_normal_(m.weight.data)\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","\n","class SeResNext50_Unet_2Ssum(nn.Module):\n","    def __init__(self, pretrained='imagenet', **kwargs):\n","        super(SeResNext50_Unet_2Ssum, self).__init__()\n","\n","        encoder_filters = [64, 256, 512, 1024, 2048]\n","        decoder_filters = np.asarray([64, 96, 128, 256, 512]) // 2\n","\n","        self.conv6 = ConvRelu(encoder_filters[-1], decoder_filters[-1])\n","        self.conv6_2 = ConvRelu(decoder_filters[-1] + encoder_filters[-2], decoder_filters[-1])\n","        self.conv7 = ConvRelu(decoder_filters[-1], decoder_filters[-2])\n","        self.conv7_2 = ConvRelu(decoder_filters[-2] + encoder_filters[-3] , decoder_filters[-2] )\n","        self.conv8 = ConvRelu(decoder_filters[-2], decoder_filters[-3])\n","        self.conv8_2 = ConvRelu(decoder_filters[-3] + encoder_filters[-4] , decoder_filters[-3])\n","        self.conv9 = ConvRelu(decoder_filters[-3], decoder_filters[-4])\n","        self.conv9_2 = ConvRelu(decoder_filters[-4] + encoder_filters[-5], decoder_filters[-4])\n","\n","        # self.convx9_3 = ConvRelu(encoder_filters[-4], encoder_filters[-4])\n","\n","\n","        self.conv10 = ConvRelu(decoder_filters[-4], decoder_filters[-5])\n","        self.conv10_s = nn.Sequential(ConvRelu(decoder_filters[-5], decoder_filters[-5]),\n","                                      nn.Conv2d(decoder_filters[-5] , 1, 1, stride=1, padding=0),\n","                                      nn.Sigmoid())\n","        # self.convxx = nn.Sequential(ConvRelu(decoder_filters[-5]*2, decoder_filters[-5]*2),\n","        #                             nn.Conv2d(decoder_filters[-5] * 2, decoder_filters[-5], 1, stride=1, padding=0))\n","\n","        self.res = nn.Conv2d(decoder_filters[-5] * 2, 5, 1, stride=1, padding=0)\n","\n","        self._initialize_weights()\n","\n","        encoder = se_resnext50_32x4d(pretrained=pretrained)\n","        #encoder = torchvision.models.resnet50(pretrained=pretrained)\n","        self.conv1 = nn.Sequential(encoder.layer0.conv1, encoder.layer0.bn1, encoder.layer0.relu1) #encoder.layer0.conv1\n","        self.conv2 = nn.Sequential(encoder.pool, encoder.layer1)\n","        self.conv3 = encoder.layer2\n","        self.conv4 = encoder.layer3\n","        self.conv5 = encoder.layer4\n","\n","\n","    def forward1(self, x):\n","        batch_size, C, H, W = x.shape\n","        xx = F.interpolate(x, scale_factor=0.5, mode='bilinear', align_corners=False)\n","\n","        enc1 = self.conv1(x)\n","        enc2 = self.conv2(enc1)\n","        enc3 = self.conv3(enc2)\n","        enc4 = self.conv4(enc3)\n","        enc5 = self.conv5(enc4)\n","\n","        encx1 = self.conv1(xx)   # 64 128 128\n","        encx2 = self.conv2(encx1) # 64\n","        encx3 = self.conv3(encx2) # 32\n","        encx4 = self.conv4(encx3) # 16\n","        encx5 = self.conv5(encx4) # 8\n","\n","        dec6 = self.conv6(F.interpolate(enc5, scale_factor=2))\n","        dec6 = self.conv6_2(torch.cat([dec6, enc4 ], 1))\n","        dec7 = self.conv7(F.interpolate(dec6, scale_factor=2))\n","        dec7 = self.conv7_2(torch.cat([dec7, enc3], 1))\n","        dec8 = self.conv8(F.interpolate(dec7, scale_factor=2))\n","        dec8 = self.conv8_2(torch.cat([dec8, enc2], 1))\n","        dec9 = self.conv9(F.interpolate(dec8, scale_factor=2))\n","        dec9 = self.conv9_2(torch.cat([dec9,  enc1], 1))   #256\n","\n","        decx6 = self.conv6(F.interpolate(encx5, scale_factor=2))\n","        decx6 = self.conv6_2(torch.cat([decx6, encx4 ], 1))\n","        decx7 = self.conv7(F.interpolate(decx6, scale_factor=2))\n","        decx7 = self.conv7_2(torch.cat([decx7, encx3], 1))\n","        decx8 = self.conv8(F.interpolate(decx7, scale_factor=2))\n","        decx8 = self.conv8_2(torch.cat([decx8, encx2], 1))\n","        decx9 = self.conv9(F.interpolate(decx8, scale_factor=2))\n","        decx9 = self.conv9_2(torch.cat([decx9,  encx1], 1))   #128\n","        #decx9 = self.convx9_3(F.interpolate(decx9, scale_factor=4))\n","\n","\n","        dec10 = self.conv10(F.interpolate(dec9, scale_factor=2))\n","        alpha = self.conv10_s(dec10)\n","        decx10 = self.conv10(F.interpolate(decx9, scale_factor=4))\n","\n","        dec = alpha * dec10 + (1-alpha)*decx10\n","\n","        return dec\n","\n","    def forward(self, x):\n","        dec10_0 = self.forward1(x[:, :3, :, :])\n","        dec10_1 = self.forward1(x[:, 3:, :, :])\n","\n","        dec10 = torch.cat([dec10_0, dec10_1], 1)\n","\n","        return self.res(dec10)\n","\n","\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Linear):\n","                m.weight.data = nn.init.kaiming_normal_(m.weight.data)\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()"]},{"cell_type":"markdown","metadata":{"id":"tHCAM2vfRK7e"},"source":["# TrainBDANet"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":73450,"status":"ok","timestamp":1685488327350,"user":{"displayName":"Antonio Santos","userId":"03265893617080544823"},"user_tz":180},"id":"Un2B5Ov0F8f-","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0d055907-5116-4d72-d00d-a08f1bb09884"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 2/2 [01:11<00:00, 35.77s/it]\n"]}],"source":["import os\n","os.environ[\"MKL_NUM_THREADS\"] = \"2\" \n","os.environ[\"NUMEXPR_NUM_THREADS\"] = \"2\" \n","os.environ[\"OMP_NUM_THREADS\"] = \"2\" \n","\n","from os import path, makedirs, listdir\n","import sys\n","import numpy as np\n","np.random.seed(1)\n","import random\n","random.seed(1)\n","\n","import torch\n","from torch import nn\n","from torch.backends import cudnn\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","import torch.optim.lr_scheduler as lr_scheduler\n","\n","#from apex import amp\n","\n","import pandas as pd\n","from tqdm import tqdm\n","import timeit\n","import cv2\n","\n","from imgaug import augmenters as iaa\n","\n","from skimage.morphology import square, dilation\n","\n","from sklearn.model_selection import train_test_split\n","\n","from sklearn.metrics import accuracy_score\n","\n","import gc\n","\n","cv2.setNumThreads(0)\n","cv2.ocl.setUseOpenCL(False)\n","\n","train_dirs = ['/content/drive/MyDrive/Modeling Satelities Images Building Damaged/data/train', '/content/drive/MyDrive/Modeling Satelities Images Building Damaged/data/test']\n","\n","models_folder = '/content/drive/MyDrive/Modeling Satelities Images Building Damaged/src/train/weights'\n","\n","loc_folder = 'pred_loc_val'\n","\n","input_shape = (512, 512)\n","\n","\n","all_files = []\n","for d in tqdm(train_dirs):\n","    for f in sorted(listdir(path.join(d, 'images'))):\n","        if '_pre_disaster.png' in f:\n","            post_disaster_file = f.replace('_pre_disaster.png', '_post_disaster.png')\n","            if path.exists(path.join(d, 'images', post_disaster_file)):\n","                all_files.append(path.join(d, 'images', f))"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1685488327351,"user":{"displayName":"Antonio Santos","userId":"03265893617080544823"},"user_tz":180},"id":"3_V8N6ykQ2g0"},"outputs":[],"source":["def rand_bbox(size, lam):\n","    W = size[0]\n","    H = size[1]\n","    cut_rat = np.sqrt(1. - lam)\n","    cut_w = int(W * cut_rat)\n","    cut_h = int(H * cut_rat)\n","    # if cut_rat > 0.9:\n","    #   cut_w = np.int(W * cut_rat * 0.9)\n","    #   cut_h = np.int(H * cut_rat * 0.9)\n","\n","    # uniform\n","    cx = np.random.randint(W)\n","    cy = np.random.randint(H)\n","\n","    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n","    bby1 = np.clip(cy - cut_h // 2, 0, H)\n","    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n","    bby2 = np.clip(cy + cut_h // 2, 0, H)\n","\n","    return bbx1, bby1, bbx2, bby2\n","\n","class TrainData(Dataset):\n","    def __init__(self, train_idxs, low, high):\n","        super().__init__()\n","        self.train_idxs = train_idxs\n","        self.elastic = iaa.ElasticTransformation(alpha=(0.25, 1.2), sigma=0.2)\n","        self.low =low\n","        self.high = high\n","\n","    def __len__(self):\n","        return len(self.train_idxs)\n","\n","    def __getitem__(self, idx):\n","        _idx = self.train_idxs[idx]\n","\n","        fn = all_files[_idx]\n","\n","        img = cv2.imread(fn, cv2.IMREAD_COLOR)\n","        img2 = cv2.imread(fn.replace('_pre_disaster', '_post_disaster'), cv2.IMREAD_COLOR)\n","        if img is None and img2 is None:\n","          sample = {'img': None, 'msk': None, 'lbl_msk': None, 'fn': None}\n","\n","        msk0 = cv2.imread(fn.replace('/images/', '/targets/').replace('.png', '_target.png'), cv2.IMREAD_UNCHANGED)\n","        lbl_msk1 = cv2.imread(fn.replace('/images/', '/targets/').replace('_pre_disaster', '_post_disaster').replace('.png', '_target.png'), cv2.IMREAD_UNCHANGED)\n","        msk1 = np.zeros_like(lbl_msk1)\n","        msk2 = np.zeros_like(lbl_msk1)\n","        msk3 = np.zeros_like(lbl_msk1)\n","        msk4 = np.zeros_like(lbl_msk1)\n","        msk2[lbl_msk1 == 2] = 255\n","        msk3[lbl_msk1 == 3] = 255\n","        msk4[lbl_msk1 == 4] = 255\n","        msk1[lbl_msk1 == 1] = 255\n","\n","        try:\n","          if random.random() > 0.87:\n","              lam = np.random.beta(2, 1.8)\n","              rand_inx = torch.randint(low=self.low,high=self.high,size=(1,))\n","              ttt = self.train_idxs[rand_inx]\n","              fn_rand = all_files[ttt]\n","              img_random = cv2.imread(fn_rand, cv2.IMREAD_COLOR)\n","              img2_random = cv2.imread(fn_rand.replace('_pre_disaster', '_post_disaster'), cv2.IMREAD_COLOR)\n","              msk0_random = cv2.imread(fn_rand.replace('/images/', '/targets/').replace('.png', '_target.png'), cv2.IMREAD_UNCHANGED)\n","              lbl_msk1_random = cv2.imread(fn_rand.replace('/images/', '/targets/').replace('_pre_disaster', '_post_disaster').replace('.png', '_target.png'), cv2.IMREAD_UNCHANGED)\n","              bbx1, bby1, bbx2, bby2 = rand_bbox((1024, 1024), lam)\n","              img[bbx1:bbx2, bby1:bby2, :] = img_random[bbx1:bbx2, bby1:bby2, :]\n","              img2[bbx1:bbx2, bby1:bby2, :] = img2_random[bbx1:bbx2, bby1:bby2, :]\n","              msk0[bbx1:bbx2, bby1:bby2] = msk0_random[bbx1:bbx2, bby1:bby2]\n","              lbl_msk1[bbx1:bbx2, bby1:bby2] = lbl_msk1_random[bbx1:bbx2, bby1:bby2]\n","              # lbl_msk1[lbl_msk1==1]=70\n","              # lbl_msk1[lbl_msk1==2]=130\n","              # lbl_msk1[lbl_msk1==3]=190\n","              # lbl_msk1[lbl_msk1==4]=255\n","              # cv2.imshow('input_image', lbl_msk1)\n","              # cv2.waitKey(5000)\n","        except:\n","          None\n","\n","        msk2[lbl_msk1 == 2] = 255\n","        msk3[lbl_msk1 == 3] = 255\n","        msk4[lbl_msk1 == 4] = 255\n","        msk1[lbl_msk1 == 1] = 255\n","\n","        try:\n","          if random.random() > 0.5:\n","              img = img[::-1, ...]\n","              img2 = img2[::-1, ...]\n","              msk0 = msk0[::-1, ...]\n","              msk1 = msk1[::-1, ...]\n","              msk2 = msk2[::-1, ...]\n","              msk3 = msk3[::-1, ...]\n","              msk4 = msk4[::-1, ...]\n","        except:\n","          None\n","\n","        try:\n","          if random.random() > 0.05:\n","              rot = random.randrange(4)\n","              if rot > 0:\n","                img = np.rot90(img, k=rot)\n","                img2 = np.rot90(img2, k=rot)\n","                msk0 = np.rot90(msk0, k=rot)\n","                msk1 = np.rot90(msk1, k=rot)\n","                msk2 = np.rot90(msk2, k=rot)\n","                msk3 = np.rot90(msk3, k=rot)\n","                msk4 = np.rot90(msk4, k=rot)\n","        except:\n","          None\n","        \n","        try:\n","          if random.random() > 0.8:\n","              shift_pnt = (random.randint(-320, 320), random.randint(-320, 320))\n","              img = shift_image(img, shift_pnt)\n","              img2 = shift_image(img2, shift_pnt)\n","              msk0 = shift_image(msk0, shift_pnt)\n","              msk1 = shift_image(msk1, shift_pnt)\n","              msk2 = shift_image(msk2, shift_pnt)\n","              msk3 = shift_image(msk3, shift_pnt)\n","              msk4 = shift_image(msk4, shift_pnt)\n","        except:\n","          None\n","        \n","        try:\n","          if random.random() > 0.2:\n","              rot_pnt =  (img.shape[0] // 2 + random.randint(-320, 320), img.shape[1] // 2 + random.randint(-320, 320))\n","              scale = 0.9 + random.random() * 0.2\n","              angle = random.randint(0, 20) - 10\n","              if (angle != 0) or (scale != 1):\n","                  img = rotate_image(img, angle, scale, rot_pnt)\n","                  img2 = rotate_image(img2, angle, scale, rot_pnt)\n","                  msk0 = rotate_image(msk0, angle, scale, rot_pnt)\n","                  msk1 = rotate_image(msk1, angle, scale, rot_pnt)\n","                  msk2 = rotate_image(msk2, angle, scale, rot_pnt)\n","                  msk3 = rotate_image(msk3, angle, scale, rot_pnt)\n","                  msk4 = rotate_image(msk4, angle, scale, rot_pnt)\n","        except:\n","          None\n","\n","        crop_size = input_shape[0]\n","\n","        try:\n","          if random.random() > 0.1:\n","              crop_size = random.randint(int(input_shape[0] / 1.15), int(input_shape[0] / 0.85))\n","        except:\n","          None\n","\n","        try:\n","          bst_x0 = random.randint(0, img.shape[1] - crop_size)\n","          bst_y0 = random.randint(0, img.shape[0] - crop_size)\n","          bst_sc = -1\n","          try_cnt = random.randint(1, 10)\n","          for i in range(try_cnt):\n","              x0 = random.randint(0, img.shape[1] - crop_size)\n","              y0 = random.randint(0, img.shape[0] - crop_size)\n","              _sc = msk2[y0:y0+crop_size, x0:x0+crop_size].sum() * 5 + msk3[y0:y0+crop_size, x0:x0+crop_size].sum() * 5 + msk4[y0:y0+crop_size, x0:x0+crop_size].sum() * 2 + msk1[y0:y0+crop_size, x0:x0+crop_size].sum()\n","              if _sc > bst_sc:\n","                  bst_sc = _sc\n","                  bst_x0 = x0\n","                  bst_y0 = y0\n","          x0 = bst_x0\n","          y0 = bst_y0\n","          img = img[y0:y0+crop_size, x0:x0+crop_size, :]\n","          img2 = img2[y0:y0+crop_size, x0:x0+crop_size, :]\n","          msk0 = msk0[y0:y0+crop_size, x0:x0+crop_size]\n","          msk1 = msk1[y0:y0+crop_size, x0:x0+crop_size]\n","          msk2 = msk2[y0:y0+crop_size, x0:x0+crop_size]\n","          msk3 = msk3[y0:y0+crop_size, x0:x0+crop_size]\n","          msk4 = msk4[y0:y0+crop_size, x0:x0+crop_size]\n","        except:\n","          None\n","        \n","        if crop_size != input_shape[0]:\n","            img = cv2.resize(img, input_shape, interpolation=cv2.INTER_LINEAR)\n","            img2 = cv2.resize(img2, input_shape, interpolation=cv2.INTER_LINEAR)\n","            msk0 = cv2.resize(msk0, input_shape, interpolation=cv2.INTER_LINEAR)\n","            msk1 = cv2.resize(msk1, input_shape, interpolation=cv2.INTER_LINEAR)\n","            msk2 = cv2.resize(msk2, input_shape, interpolation=cv2.INTER_LINEAR)\n","            msk3 = cv2.resize(msk3, input_shape, interpolation=cv2.INTER_LINEAR)\n","            msk4 = cv2.resize(msk4, input_shape, interpolation=cv2.INTER_LINEAR)\n","            \n","        try:\n","          if random.random() > 0.96:\n","              img = shift_channels(img, random.randint(-5, 5), random.randint(-5, 5), random.randint(-5, 5))\n","          elif random.random() > 0.96:\n","              img2 = shift_channels(img2, random.randint(-5, 5), random.randint(-5, 5), random.randint(-5, 5))\n","\n","          if random.random() > 0.96:\n","              img = change_hsv(img, random.randint(-5, 5), random.randint(-5, 5), random.randint(-5, 5))\n","          elif random.random() > 0.96:\n","              img2 = change_hsv(img2, random.randint(-5, 5), random.randint(-5, 5), random.randint(-5, 5))\n","        except:\n","          None\n","\n","        try:\n","          if random.random() > 0.9:\n","              if random.random() > 0.96:\n","                  img = clahe(img)\n","              elif random.random() > 0.96:\n","                  img = gauss_noise(img)\n","              elif random.random() > 0.96:\n","                  img = cv2.blur(img, (3, 3))\n","          elif random.random() > 0.9:\n","              if random.random() > 0.96:\n","                  img = saturation(img, 0.9 + random.random() * 0.2)\n","              elif random.random() > 0.96:\n","                  img = brightness(img, 0.9 + random.random() * 0.2)\n","              elif random.random() > 0.96:\n","                  img = contrast(img, 0.9 + random.random() * 0.2)\n","\n","          if random.random() > 0.9:\n","              if random.random() > 0.96:\n","                  img2 = clahe(img2)\n","              elif random.random() > 0.96:\n","                  img2 = gauss_noise(img2)\n","              elif random.random() > 0.96:\n","                  img2 = cv2.blur(img2, (3, 3))\n","          elif random.random() > 0.9:\n","              if random.random() > 0.96:\n","                  img2 = saturation(img2, 0.9 + random.random() * 0.2)\n","              elif random.random() > 0.96:\n","                  img2 = brightness(img2, 0.9 + random.random() * 0.2)\n","              elif random.random() > 0.96:\n","                  img2 = contrast(img2, 0.9 + random.random() * 0.2)\n","        except:\n","          None\n","\n","        try:  \n","          if random.random() > 0.96:\n","              el_det = self.elastic.to_deterministic()\n","              img = el_det.augment_image(img)\n","\n","          if random.random() > 0.96:\n","              el_det = self.elastic.to_deterministic()\n","              img2 = el_det.augment_image(img2)\n","        except:\n","          None\n","\n","        msk0 = msk0[..., np.newaxis]\n","        msk1 = msk1[..., np.newaxis]\n","        msk2 = msk2[..., np.newaxis]\n","        msk3 = msk3[..., np.newaxis]\n","        msk4 = msk4[..., np.newaxis]\n","\n","        msk = np.concatenate([msk0, msk1, msk2, msk3, msk4], axis=2)\n","        msk = (msk > 127)\n","\n","        msk[..., 0] = True\n","        msk[..., 1] = dilation(msk[..., 1], square(5))\n","        msk[..., 2] = dilation(msk[..., 2], square(5))\n","        msk[..., 3] = dilation(msk[..., 3], square(5))\n","        msk[..., 4] = dilation(msk[..., 4], square(5))\n","        msk[..., 1][msk[..., 2:].max(axis=2)] = False\n","        msk[..., 3][msk[..., 2]] = False\n","        msk[..., 4][msk[..., 2]] = False\n","        msk[..., 4][msk[..., 3]] = False\n","        msk[..., 0][msk[..., 1:].max(axis=2)] = False\n","        msk = msk * 1\n","\n","        lbl_msk = msk.argmax(axis=2)\n","\n","        img = np.concatenate([img, img2], axis=2)\n","        img = preprocess_inputs(img)\n","\n","        img = torch.from_numpy(img.transpose((2, 0, 1))).float()\n","        msk = torch.from_numpy(msk.transpose((2, 0, 1))).long()\n","\n","        sample = {'img': img, 'msk': msk, 'lbl_msk': lbl_msk, 'fn': fn}\n","        return sample\n","\n","\n","class ValData(Dataset):\n","    def __init__(self, image_idxs):\n","        super().__init__()\n","        self.image_idxs = image_idxs\n","\n","    def __len__(self):\n","        return len(self.image_idxs)\n","\n","    def __getitem__(self, idx):\n","        _idx = self.image_idxs[idx]\n","\n","        fn = all_files[_idx]\n","\n","        img = cv2.imread(fn, cv2.IMREAD_COLOR)\n","        img2 = cv2.imread(fn.replace('_pre_disaster', '_post_disaster'), cv2.IMREAD_COLOR)\n","        msk_loc = cv2.imread(fn.replace('/images/', '/targets/').replace('.png', '_target.png'), cv2.IMREAD_UNCHANGED)# > (0.3*255)\n","\n","        msk0 = cv2.imread(fn.replace('/images/', '/targets/').replace('.png', '_target.png'), cv2.IMREAD_UNCHANGED)\n","        lbl_msk1 = cv2.imread(fn.replace('/images/', '/targets/').replace('_pre_disaster', '_post_disaster').replace('.png', '_target.png'), cv2.IMREAD_UNCHANGED)\n","        msk1 = np.zeros_like(lbl_msk1)\n","        msk2 = np.zeros_like(lbl_msk1)\n","        msk3 = np.zeros_like(lbl_msk1)\n","        msk4 = np.zeros_like(lbl_msk1)\n","        msk1[lbl_msk1 == 1] = 255\n","        msk2[lbl_msk1 == 2] = 255\n","        msk3[lbl_msk1 == 3] = 255\n","        msk4[lbl_msk1 == 4] = 255\n","\n","        msk0 = msk0[..., np.newaxis]\n","        msk1 = msk1[..., np.newaxis]\n","        msk2 = msk2[..., np.newaxis]\n","        msk3 = msk3[..., np.newaxis]\n","        msk4 = msk4[..., np.newaxis]\n","\n","        msk = np.concatenate([msk0, msk1, msk2, msk3, msk4], axis=2)\n","        msk = (msk > 127)\n","\n","        msk = msk * 1\n","\n","        lbl_msk = msk[..., 1:].argmax(axis=2)\n","        \n","        img = np.concatenate([img, img2], axis=2)\n","        img = preprocess_inputs(img)\n","\n","        img = torch.from_numpy(img.transpose((2, 0, 1))).float()\n","        msk = torch.from_numpy(msk.transpose((2, 0, 1))).long()\n","\n","        sample = {'img': img, 'msk': msk, 'lbl_msk': lbl_msk, 'fn': fn, 'msk_loc': msk_loc}\n","        return sample\n","\n","\n","def validate(net, data_loader):\n","    dices0 = []\n","\n","    tp = np.zeros((5,))\n","    fp = np.zeros((5,))\n","    fn = np.zeros((5,))\n","\n","    _thr = 0.3\n","\n","    with torch.no_grad():\n","        for i, sample in enumerate(tqdm(data_loader)):\n","            msks = sample[\"msk\"].numpy()\n","            lbl_msk = sample[\"lbl_msk\"].numpy()\n","            imgs = sample[\"img\"].cuda(non_blocking=True)\n","            msk_loc = sample[\"msk_loc\"].numpy() * 1\n","            out = model(imgs)\n","\n","            msk_pred = msk_loc\n","            msk_damage_pred = torch.softmax(out, dim=1).cpu().numpy()[:, 1:, ...]\n","            \n","            for j in range(msks.shape[0]):\n","                tp[4] += np.logical_and(msks[j, 0] > 0, msk_pred[j] > 0).sum()\n","                fn[4] += np.logical_and(msks[j, 0] < 1, msk_pred[j] > 0).sum()\n","                fp[4] += np.logical_and(msks[j, 0] > 0, msk_pred[j] < 1).sum()\n","\n","\n","                targ = lbl_msk[j][msks[j, 0] > 0]\n","                pred = msk_damage_pred[j].argmax(axis=0)\n","                pred = pred * (msk_pred[j] > _thr)\n","                pred = pred[msks[j, 0] > 0]\n","                for c in range(4):\n","                    tp[c] += np.logical_and(pred == c, targ == c).sum()\n","                    fn[c] += np.logical_and(pred != c, targ == c).sum()\n","                    fp[c] += np.logical_and(pred == c, targ != c).sum()\n","\n","    d0 = 2 * tp[4] / (2 * tp[4] + fp[4] + fn[4])\n","\n","    f1_sc = np.zeros((4,))\n","    for c in range(4):\n","        f1_sc[c] = 2 * tp[c] / (2 * tp[c] + fp[c] + fn[c])\n","\n","    f1 = 4 / np.sum(1.0 / (f1_sc + 1e-6))\n","\n","    sc = 0.3 * d0 + 0.7 * f1\n","    print(\"Val Score: {}, Dice: {}, F1: {}, F1_0: {}, F1_1: {}, F1_2: {}, F1_3: {}\".format(sc, d0, f1, f1_sc[0], f1_sc[1], f1_sc[2], f1_sc[3]))\n","    return sc\n","\n","\n","def evaluate_val(data_val, best_score, model, snapshot_name, current_epoch):\n","    model = model.eval()\n","    d = validate(model, data_loader=data_val)\n","\n","    if d > best_score:\n","        torch.save({\n","            'epoch': current_epoch + 1,\n","            'state_dict': model.state_dict(),\n","            'best_score': d,\n","        }, path.join(models_folder, snapshot_name + '_best'))\n","        best_score = d\n","\n","    print(\"score: {}\\tscore_best: {}\".format(d, best_score))\n","    return best_score\n","\n","\n","def train_epoch(current_epoch, seg_loss, ce_loss, seg_seesaw, model, optimizer, scheduler, train_data_loader):\n","    losses = AverageMeter()\n","    losses1 = AverageMeter()\n","\n","    dices = AverageMeter()\n","\n","    iterator = tqdm(train_data_loader)\n","    model.train()\n","    for i, sample in enumerate(iterator):\n","        imgs = sample[\"img\"].cuda(non_blocking=True)\n","        msks = sample[\"msk\"].cuda(non_blocking=True)\n","        lbl_msk = sample[\"lbl_msk\"].cuda(non_blocking=True)\n","        \n","        out = model(imgs)\n","\n","        # loss0 = seg_loss(out[:, 0, ...], msks[:, 0, ...])\n","        # loss1 = seg_loss(out[:, 1, ...], msks[:, 1, ...])\n","        # loss2 = seg_loss(out[:, 2, ...], msks[:, 2, ...])\n","        # loss3 = seg_loss(out[:, 3, ...], msks[:, 3, ...])\n","        # loss4 = seg_loss(out[:, 4, ...], msks[:, 4, ...])\n","\n","        loss5 = ce_loss(out, lbl_msk)\n","        #loss5 = seg_seesaw(out, lbl_msk)\n","        loss = loss5\n","        #loss = 0.1 * loss0 + 0.1 * loss1 + 0.3 * loss2 + 0.3 * loss3 + 0.2 * loss4 + loss5 * 2\n","\n","        with torch.no_grad():\n","            _probs = 1 - torch.sigmoid(out[:, 0, ...])\n","            dice_sc = 1 - dice_round(_probs, 1 - msks[:, 0, ...])\n","\n","        losses.update(loss.item(), imgs.size(0))\n","        losses1.update(loss5.item(), imgs.size(0))\n","\n","        dices.update(dice_sc, imgs.size(0))\n","\n","        iterator.set_description(\n","            \"epoch: {}; lr {:.7f}; Loss {loss.val:.4f} ({loss.avg:.4f}); cce_loss {loss1.val:.4f} ({loss1.avg:.4f}); Dice {dice.val:.4f} ({dice.avg:.4f})\".format(\n","                current_epoch, scheduler.get_lr()[-1], loss=losses, loss1=losses1, dice=dices))\n","        \n","        optimizer.zero_grad()\n","        # loss.backward()\n","        with amp.scale_loss(loss, optimizer) as scaled_loss:\n","            scaled_loss.backward()\n","        torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), 0.999)\n","        optimizer.step()\n","\n","    scheduler.step()\n","\n","    print(\"epoch: {}; lr {:.7f}; Loss {loss.avg:.4f}; CCE_loss {loss1.avg:.4f}; Dice {dice.avg:.4f}\".format(\n","            current_epoch, scheduler.get_lr()[-1], loss=losses, loss1=losses1, dice=dices))\n","    \n","def train_epoch(current_epoch, seg_loss, ce_loss, seg_seesaw, model, optimizer, scheduler, train_data_loader):\n","    losses = AverageMeter()\n","    losses1 = AverageMeter()\n","\n","    dices = AverageMeter()\n","\n","    iterator = tqdm(train_data_loader)\n","    model.train()\n","    for i, sample in enumerate(iterator):\n","        if sample[\"img\"] is None or sample[\"msk\"] is None or sample[\"lbl_msk\"] is None:\n","              continue\n","        imgs = sample[\"img\"].cuda(non_blocking=True)\n","        msks = sample[\"msk\"].cuda(non_blocking=True)\n","        lbl_msk = sample[\"lbl_msk\"].cuda(non_blocking=True)\n","        \n","        out = model(imgs)\n","\n","        loss5 = ce_loss(out, lbl_msk)\n","        loss = loss5\n","\n","        with torch.no_grad():\n","            _probs = 1 - torch.sigmoid(out[:, 0, ...])\n","            dice_sc = 1 - dice_round(_probs, 1 - msks[:, 0, ...])\n","\n","        losses.update(loss.item(), imgs.size(0))\n","        losses1.update(loss5.item(), imgs.size(0))\n","\n","        dices.update(dice_sc, imgs.size(0))\n","\n","        iterator.set_description(\n","            \"epoch: {}; lr {:.7f}; Loss {loss.val:.4f} ({loss.avg:.4f}); cce_loss {loss1.val:.4f} ({loss1.avg:.4f}); Dice {dice.val:.4f} ({dice.avg:.4f})\".format(\n","                current_epoch, scheduler.get_lr()[-1], loss=losses, loss1=losses1, dice=dices))\n","        \n","        optimizer.zero_grad()\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.999)\n","        optimizer.step()\n","\n","    scheduler.step()\n","\n","    print(\"epoch: {}; lr {:.7f}; Loss {loss.avg:.4f}; CCE_loss {loss1.avg:.4f}; Dice {dice.avg:.4f}\".format(\n","            current_epoch, scheduler.get_lr()[-1], loss=losses, loss1=losses1, dice=dices))"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2591214,"status":"ok","timestamp":1685490918554,"user":{"displayName":"Antonio Santos","userId":"03265893617080544823"},"user_tz":180},"id":"AL3hRfYVR6t7","outputId":"660bd2f5-108a-430f-8747-064d87e352c1"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 3705/3705 [43:10<00:00,  1.43it/s]\n","100%|██████████| 3334/3334 [00:00<00:00, 399994.55it/s]\n","100%|██████████| 3334/3334 [00:00<00:00, 412064.17it/s]\n"]}],"source":["# ttt = np.asarray([True, False, True, True])\n","# p1=ttt[0:].max()\n","# p2=ttt[1].max()\n","# ttt2 = np.asarray([True, True, False, False])\n","# p3=ttt2[1].max()\n","# p4=ttt2[2:3].max()\n","t0 = timeit.default_timer()\n","\n","makedirs(models_folder, exist_ok=True)\n","\n","seed = int(random.random() * 100) \n","#seed=0\n","# vis_dev = sys.argv[2]\n","\n","# os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n","# os.environ[\"CUDA_VISIBLE_DEVICES\"] = vis_dev\n","\n","cudnn.benchmark = True\n","\n","batch_size = 12\n","val_batch_size = 10\n","\n","snapshot_name = 'res50_cls_2Ssum_{}_0'.format(seed)\n","\n","file_classes = []\n","for fn in tqdm(all_files):\n","    fl = np.zeros((4,), dtype=bool)\n","    msk1 = cv2.imread(fn.replace('/images/', '/targets/').replace('_pre_disaster', '_post_disaster').replace('.png', '_target.png'), cv2.IMREAD_UNCHANGED)\n","    for c in range(1, 5):\n","        fl[c-1] = c in msk1\n","    file_classes.append(fl)\n","file_classes = np.asarray(file_classes)\n","\n","train_idxs0, val_idxs = train_test_split(np.arange(len(all_files)), test_size=0.1, random_state=seed)\n","\n","np.random.seed(seed + 1234)\n","random.seed(seed + 1234)\n","\n","train_idxs = []\n","for i in tqdm(train_idxs0):\n","    train_idxs.append(i)\n","    if file_classes[i, 1:].max():\n","        train_idxs.append(i)\n","    # if file_classes[i, 2].max():\n","    #     train_idxs.append(i)\n","low1 = len(train_idxs)\n","for i in tqdm(train_idxs0):\n","    if file_classes[i, 1:3].max():\n","        train_idxs.append(i)\n","# for i in train_idxs0:\n","#     if file_classes[i, 1].max():\n","#         train_idxs.append(i)\n","high1 = len(train_idxs)\n","\n","train_idxs = np.asarray(train_idxs)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1685490918555,"user":{"displayName":"Antonio Santos","userId":"03265893617080544823"},"user_tz":180},"id":"z7d7mCn4gspJ","outputId":"8372b480-0058-42ad-85e3-bf6d145a9740"},"outputs":[{"output_type":"stream","name":"stdout","text":["steps_per_epoch 541 validation_steps 37\n"]}],"source":["steps_per_epoch = len(train_idxs) // batch_size\n","validation_steps = len(val_idxs) // val_batch_size\n","\n","print('steps_per_epoch', steps_per_epoch, 'validation_steps', validation_steps)\n","\n","data_train = TrainData(train_idxs, low1, high1)\n","val_train = ValData(val_idxs)\n","\n","train_data_loader = DataLoader(data_train, batch_size=batch_size, num_workers=6, shuffle=True, pin_memory=False, drop_last=True)\n","val_data_loader = DataLoader(val_train, batch_size=val_batch_size, num_workers=6, shuffle=False, pin_memory=False)"]},{"cell_type":"code","source":["val_train[1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"It9dfrhCYj5e","executionInfo":{"status":"ok","timestamp":1685490921413,"user_tz":180,"elapsed":2862,"user":{"displayName":"Antonio Santos","userId":"03265893617080544823"}},"outputId":"ce0ef7e0-5478-4f72-e03d-e72573e6472f"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'img': tensor([[[-1.0000, -1.0000, -1.0000,  ..., -0.6378, -0.6457, -0.6299],\n","          [-1.0000, -1.0000, -1.0000,  ..., -0.6378, -0.6378, -0.6299],\n","          [-1.0000, -1.0000, -1.0000,  ..., -0.6378, -0.6378, -0.6378],\n","          ...,\n","          [-1.0000, -1.0000, -1.0000,  ..., -0.7008, -0.6614, -0.6772],\n","          [-1.0000, -1.0000, -1.0000,  ..., -0.6693, -0.6693, -0.6850],\n","          [-1.0000, -1.0000, -1.0000,  ..., -0.6693, -0.6693, -0.6850]],\n"," \n","         [[-1.0000, -1.0000, -1.0000,  ..., -0.2520, -0.2598, -0.2362],\n","          [-1.0000, -1.0000, -1.0000,  ..., -0.2520, -0.2520, -0.2362],\n","          [-1.0000, -1.0000, -1.0000,  ..., -0.2520, -0.2520, -0.2520],\n","          ...,\n","          [-1.0000, -1.0000, -1.0000,  ..., -0.3858, -0.3307, -0.3543],\n","          [-1.0000, -1.0000, -1.0000,  ..., -0.3386, -0.3465, -0.3701],\n","          [-1.0000, -1.0000, -1.0000,  ..., -0.3386, -0.3465, -0.3701]],\n"," \n","         [[-1.0000, -1.0000, -1.0000,  ..., -0.3150, -0.3307, -0.3071],\n","          [-1.0000, -1.0000, -1.0000,  ..., -0.3071, -0.3150, -0.3071],\n","          [-1.0000, -1.0000, -1.0000,  ..., -0.3071, -0.3150, -0.3228],\n","          ...,\n","          [-1.0000, -1.0000, -1.0000,  ..., -0.5591, -0.5039, -0.5354],\n","          [-1.0000, -1.0000, -1.0000,  ..., -0.5197, -0.5276, -0.5512],\n","          [-1.0000, -1.0000, -1.0000,  ..., -0.5197, -0.5276, -0.5512]],\n"," \n","         [[-1.0000, -1.0000, -1.0000,  ..., -0.2520, -0.2441, -0.2441],\n","          [-1.0000, -1.0000, -1.0000,  ..., -0.2598, -0.2362, -0.2126],\n","          [-1.0000, -1.0000, -1.0000,  ..., -0.2441, -0.2362, -0.2126],\n","          ...,\n","          [-1.0000, -1.0000, -1.0000,  ..., -0.8346, -0.8425, -0.8110],\n","          [-1.0000, -1.0000, -1.0000,  ..., -0.8346, -0.8189, -0.8031],\n","          [-1.0000, -1.0000, -1.0000,  ..., -0.8268, -0.8189, -0.8031]],\n"," \n","         [[-1.0000, -1.0000, -1.0000,  ...,  0.1260,  0.1260,  0.1260],\n","          [-1.0000, -1.0000, -1.0000,  ...,  0.1181,  0.1417,  0.1654],\n","          [-1.0000, -1.0000, -1.0000,  ...,  0.1339,  0.1417,  0.1654],\n","          ...,\n","          [-1.0000, -1.0000, -1.0000,  ..., -0.5433, -0.5669, -0.5118],\n","          [-1.0000, -1.0000, -1.0000,  ..., -0.5433, -0.5276, -0.4803],\n","          [-1.0000, -1.0000, -1.0000,  ..., -0.5276, -0.5039, -0.4646]],\n"," \n","         [[-1.0000, -1.0000, -1.0000,  ...,  0.2677,  0.2756,  0.2677],\n","          [-1.0000, -1.0000, -1.0000,  ...,  0.2677,  0.2913,  0.3307],\n","          [-1.0000, -1.0000, -1.0000,  ...,  0.2913,  0.2992,  0.3386],\n","          ...,\n","          [-1.0000, -1.0000, -1.0000,  ..., -0.8268, -0.8268, -0.7953],\n","          [-1.0000, -1.0000, -1.0000,  ..., -0.8268, -0.8189, -0.7874],\n","          [-1.0000, -1.0000, -1.0000,  ..., -0.8268, -0.8110, -0.7874]]]),\n"," 'msk': tensor([[[0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          ...,\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0]],\n"," \n","         [[0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          ...,\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0]],\n"," \n","         [[0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          ...,\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0]],\n"," \n","         [[0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          ...,\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0]],\n"," \n","         [[0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          ...,\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0],\n","          [0, 0, 0,  ..., 0, 0, 0]]]),\n"," 'lbl_msk': array([[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]]),\n"," 'fn': '/content/drive/MyDrive/Modeling Satelities Images Building Damaged/data/train/images/hurricane-harvey_00000520_pre_disaster.png',\n"," 'msk_loc': array([[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)}"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["try:\n","  del model\n","except:\n","  None"],"metadata":{"id":"VdMgzS3II4Mm","executionInfo":{"status":"ok","timestamp":1685490921413,"user_tz":180,"elapsed":2,"user":{"displayName":"Antonio Santos","userId":"03265893617080544823"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12302102,"status":"ok","timestamp":1685503223513,"user":{"displayName":"Antonio Santos","userId":"03265893617080544823"},"user_tz":180},"id":"_Cb3XWt7GGj5","outputId":"ce316119-db71-4002-f127-f4280eaa578e"},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"http://data.lip6.fr/cadene/pretrainedmodels/se_resnext50_32x4d-a260b3a4.pth\" to /root/.cache/torch/hub/checkpoints/se_resnext50_32x4d-a260b3a4.pth\n","100%|██████████| 105M/105M [05:10<00:00, 356kB/s]\n","  0%|          | 0/541 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","epoch: 0; lr 0.0002020; Loss 8.4890 (8.4890); cce_loss 8.4890 (8.4890); Dice 0.1805 (0.1805):   0%|          | 0/541 [00:39<?, ?it/s]<ipython-input-6-b49c52c0b773>:70: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1485.)\n","  exp_avg.mul_(beta1).add_(1 - beta1, grad)\n","epoch: 0; lr 0.0002020; Loss 0.2255 (0.2830); cce_loss 0.2255 (0.2830); Dice 0.3843 (0.4245): 100%|██████████| 541/541 [25:40<00:00,  2.85s/it]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 0; lr 0.0002020; Loss 0.2830; CCE_loss 0.2830; Dice 0.4245\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 38/38 [02:58<00:00,  4.70s/it]\n","<ipython-input-13-970eccf60d4a>:360: RuntimeWarning: invalid value encountered in double_scalars\n","  f1_sc[c] = 2 * tp[c] / (2 * tp[c] + fp[c] + fn[c])\n"]},{"output_type":"stream","name":"stdout","text":["Val Score: nan, Dice: 0.0, F1: nan, F1_0: nan, F1_1: nan, F1_2: nan, F1_3: nan\n","score: nan\tscore_best: 0\n"]},{"output_type":"stream","name":"stderr","text":["epoch: 1; lr 0.0002020; Loss 0.1922 (0.1786); cce_loss 0.1922 (0.1786); Dice 0.4968 (0.4386): 100%|██████████| 541/541 [05:23<00:00,  1.67it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 1; lr 0.0002020; Loss 0.1786; CCE_loss 0.1786; Dice 0.4386\n"]},{"output_type":"stream","name":"stderr","text":["epoch: 2; lr 0.0002020; Loss 0.2305 (0.1607); cce_loss 0.2305 (0.1607); Dice 0.5350 (0.4582): 100%|██████████| 541/541 [05:25<00:00,  1.66it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 2; lr 0.0002020; Loss 0.1607; CCE_loss 0.1607; Dice 0.4582\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 38/38 [00:40<00:00,  1.06s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Val Score: nan, Dice: 0.0, F1: nan, F1_0: nan, F1_1: nan, F1_2: nan, F1_3: nan\n","score: nan\tscore_best: 0\n"]},{"output_type":"stream","name":"stderr","text":["epoch: 3; lr 0.0002020; Loss 0.1240 (0.1514); cce_loss 0.1240 (0.1514); Dice 0.5353 (0.4844): 100%|██████████| 541/541 [05:26<00:00,  1.66it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 3; lr 0.0002020; Loss 0.1514; CCE_loss 0.1514; Dice 0.4844\n"]},{"output_type":"stream","name":"stderr","text":["epoch: 4; lr 0.0002020; Loss 0.1020 (0.1462); cce_loss 0.1020 (0.1462); Dice 0.3717 (0.4734): 100%|██████████| 541/541 [05:25<00:00,  1.66it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 4; lr 0.0000505; Loss 0.1462; CCE_loss 0.1462; Dice 0.4734\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 38/38 [00:40<00:00,  1.07s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Val Score: nan, Dice: 0.0, F1: nan, F1_0: nan, F1_1: nan, F1_2: nan, F1_3: nan\n","score: nan\tscore_best: 0\n"]},{"output_type":"stream","name":"stderr","text":["epoch: 5; lr 0.0000505; Loss 0.1228 (0.1311); cce_loss 0.1228 (0.1311); Dice 0.5616 (0.4707): 100%|██████████| 541/541 [05:26<00:00,  1.66it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 5; lr 0.0001010; Loss 0.1311; CCE_loss 0.1311; Dice 0.4707\n"]},{"output_type":"stream","name":"stderr","text":["epoch: 6; lr 0.0001010; Loss 0.0891 (0.1287); cce_loss 0.0891 (0.1287); Dice 0.3882 (0.4723): 100%|██████████| 541/541 [05:28<00:00,  1.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 6; lr 0.0001010; Loss 0.1287; CCE_loss 0.1287; Dice 0.4723\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 38/38 [00:40<00:00,  1.07s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Val Score: nan, Dice: 0.0, F1: nan, F1_0: nan, F1_1: nan, F1_2: nan, F1_3: nan\n","score: nan\tscore_best: 0\n"]},{"output_type":"stream","name":"stderr","text":["epoch: 7; lr 0.0001010; Loss 0.1345 (0.1296); cce_loss 0.1345 (0.1296); Dice 0.5475 (0.4527): 100%|██████████| 541/541 [05:27<00:00,  1.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 7; lr 0.0001010; Loss 0.1296; CCE_loss 0.1296; Dice 0.4527\n"]},{"output_type":"stream","name":"stderr","text":["epoch: 8; lr 0.0001010; Loss 0.1995 (0.1208); cce_loss 0.1995 (0.1208); Dice 0.4918 (0.4617): 100%|██████████| 541/541 [05:27<00:00,  1.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 8; lr 0.0001010; Loss 0.1208; CCE_loss 0.1208; Dice 0.4617\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 38/38 [00:40<00:00,  1.08s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Val Score: nan, Dice: 0.0, F1: nan, F1_0: nan, F1_1: nan, F1_2: nan, F1_3: nan\n","score: nan\tscore_best: 0\n"]},{"output_type":"stream","name":"stderr","text":["epoch: 9; lr 0.0001010; Loss 0.1970 (0.1225); cce_loss 0.1970 (0.1225); Dice 0.5326 (0.4466): 100%|██████████| 541/541 [05:26<00:00,  1.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 9; lr 0.0001010; Loss 0.1225; CCE_loss 0.1225; Dice 0.4466\n"]},{"output_type":"stream","name":"stderr","text":["epoch: 10; lr 0.0001010; Loss 0.1053 (0.1205); cce_loss 0.1053 (0.1205); Dice 0.4344 (0.4479): 100%|██████████| 541/541 [05:27<00:00,  1.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 10; lr 0.0001010; Loss 0.1205; CCE_loss 0.1205; Dice 0.4479\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 38/38 [00:40<00:00,  1.07s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Val Score: nan, Dice: 0.0, F1: nan, F1_0: nan, F1_1: nan, F1_2: nan, F1_3: nan\n","score: nan\tscore_best: 0\n"]},{"output_type":"stream","name":"stderr","text":["epoch: 11; lr 0.0001010; Loss 0.1589 (0.1230); cce_loss 0.1589 (0.1230); Dice 0.5909 (0.4440): 100%|██████████| 541/541 [05:28<00:00,  1.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 11; lr 0.0001010; Loss 0.1230; CCE_loss 0.1230; Dice 0.4440\n"]},{"output_type":"stream","name":"stderr","text":["epoch: 12; lr 0.0001010; Loss 0.1113 (0.1200); cce_loss 0.1113 (0.1200); Dice 0.5596 (0.4428): 100%|██████████| 541/541 [05:26<00:00,  1.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 12; lr 0.0000253; Loss 0.1200; CCE_loss 0.1200; Dice 0.4428\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 38/38 [00:40<00:00,  1.06s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Val Score: nan, Dice: 0.0, F1: nan, F1_0: nan, F1_1: nan, F1_2: nan, F1_3: nan\n","score: nan\tscore_best: 0\n"]},{"output_type":"stream","name":"stderr","text":["epoch: 13; lr 0.0000253; Loss 0.0733 (0.1087); cce_loss 0.0733 (0.1087); Dice 0.2742 (0.4678): 100%|██████████| 541/541 [05:27<00:00,  1.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 13; lr 0.0000505; Loss 0.1087; CCE_loss 0.1087; Dice 0.4678\n"]},{"output_type":"stream","name":"stderr","text":["epoch: 14; lr 0.0000505; Loss 0.1187 (0.1126); cce_loss 0.1187 (0.1126); Dice 0.4156 (0.4354): 100%|██████████| 541/541 [05:28<00:00,  1.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 14; lr 0.0000505; Loss 0.1126; CCE_loss 0.1126; Dice 0.4354\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 38/38 [00:40<00:00,  1.07s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Val Score: nan, Dice: 0.0, F1: nan, F1_0: nan, F1_1: nan, F1_2: nan, F1_3: nan\n","score: nan\tscore_best: 0\n"]},{"output_type":"stream","name":"stderr","text":["epoch: 15; lr 0.0000505; Loss 0.1314 (0.1091); cce_loss 0.1314 (0.1091); Dice 0.4730 (0.4397): 100%|██████████| 541/541 [05:28<00:00,  1.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 15; lr 0.0000505; Loss 0.1091; CCE_loss 0.1091; Dice 0.4397\n"]},{"output_type":"stream","name":"stderr","text":["epoch: 16; lr 0.0000505; Loss 0.1022 (0.1108); cce_loss 0.1022 (0.1108); Dice 0.4601 (0.4334): 100%|██████████| 541/541 [05:28<00:00,  1.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 16; lr 0.0000505; Loss 0.1108; CCE_loss 0.1108; Dice 0.4334\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 38/38 [00:40<00:00,  1.07s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Val Score: nan, Dice: 0.0, F1: nan, F1_0: nan, F1_1: nan, F1_2: nan, F1_3: nan\n","score: nan\tscore_best: 0\n"]},{"output_type":"stream","name":"stderr","text":["epoch: 17; lr 0.0000505; Loss 0.1831 (0.1073); cce_loss 0.1831 (0.1073); Dice 0.4757 (0.4502): 100%|██████████| 541/541 [05:28<00:00,  1.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 17; lr 0.0000505; Loss 0.1073; CCE_loss 0.1073; Dice 0.4502\n"]},{"output_type":"stream","name":"stderr","text":["epoch: 18; lr 0.0000505; Loss 0.0728 (0.1046); cce_loss 0.0728 (0.1046); Dice 0.3785 (0.4225): 100%|██████████| 541/541 [05:27<00:00,  1.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 18; lr 0.0000126; Loss 0.1046; CCE_loss 0.1046; Dice 0.4225\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 38/38 [00:40<00:00,  1.07s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Val Score: nan, Dice: 0.0, F1: nan, F1_0: nan, F1_1: nan, F1_2: nan, F1_3: nan\n","score: nan\tscore_best: 0\n"]},{"output_type":"stream","name":"stderr","text":["epoch: 19; lr 0.0000126; Loss 0.1104 (0.1038); cce_loss 0.1104 (0.1038); Dice 0.4952 (0.4348): 100%|██████████| 541/541 [05:27<00:00,  1.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 19; lr 0.0000253; Loss 0.1038; CCE_loss 0.1038; Dice 0.4348\n"]},{"output_type":"stream","name":"stderr","text":["epoch: 20; lr 0.0000253; Loss 0.1347 (0.1028); cce_loss 0.1347 (0.1028); Dice 0.3443 (0.4281): 100%|██████████| 541/541 [05:27<00:00,  1.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 20; lr 0.0000253; Loss 0.1028; CCE_loss 0.1028; Dice 0.4281\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 38/38 [00:40<00:00,  1.07s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Val Score: nan, Dice: 0.0, F1: nan, F1_0: nan, F1_1: nan, F1_2: nan, F1_3: nan\n","score: nan\tscore_best: 0\n"]},{"output_type":"stream","name":"stderr","text":["epoch: 21; lr 0.0000253; Loss 0.0655 (0.1041); cce_loss 0.0655 (0.1041); Dice 0.4158 (0.4215): 100%|██████████| 541/541 [05:27<00:00,  1.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 21; lr 0.0000253; Loss 0.1041; CCE_loss 0.1041; Dice 0.4215\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 38/38 [00:40<00:00,  1.06s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Val Score: nan, Dice: 0.0, F1: nan, F1_0: nan, F1_1: nan, F1_2: nan, F1_3: nan\n","score: nan\tscore_best: 0\n"]},{"output_type":"stream","name":"stderr","text":["epoch: 22; lr 0.0000253; Loss 0.0937 (0.1018); cce_loss 0.0937 (0.1018); Dice 0.3953 (0.4273): 100%|██████████| 541/541 [05:27<00:00,  1.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 22; lr 0.0000063; Loss 0.1018; CCE_loss 0.1018; Dice 0.4273\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 38/38 [00:40<00:00,  1.07s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Val Score: nan, Dice: 0.0, F1: nan, F1_0: nan, F1_1: nan, F1_2: nan, F1_3: nan\n","score: nan\tscore_best: 0\n"]},{"output_type":"stream","name":"stderr","text":["epoch: 23; lr 0.0000063; Loss 0.2676 (0.1045); cce_loss 0.2676 (0.1045); Dice 0.4645 (0.4251): 100%|██████████| 541/541 [05:27<00:00,  1.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 23; lr 0.0000126; Loss 0.1045; CCE_loss 0.1045; Dice 0.4251\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 38/38 [00:40<00:00,  1.07s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Val Score: nan, Dice: 0.0, F1: nan, F1_0: nan, F1_1: nan, F1_2: nan, F1_3: nan\n","score: nan\tscore_best: 0\n"]},{"output_type":"stream","name":"stderr","text":["epoch: 24; lr 0.0000126; Loss 0.0872 (0.1007); cce_loss 0.0872 (0.1007); Dice 0.3418 (0.4152): 100%|██████████| 541/541 [05:27<00:00,  1.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 24; lr 0.0000126; Loss 0.1007; CCE_loss 0.1007; Dice 0.4152\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 38/38 [00:40<00:00,  1.07s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Val Score: nan, Dice: 0.0, F1: nan, F1_0: nan, F1_1: nan, F1_2: nan, F1_3: nan\n","score: nan\tscore_best: 0\n"]},{"output_type":"stream","name":"stderr","text":["epoch: 25; lr 0.0000126; Loss 0.0876 (0.0982); cce_loss 0.0876 (0.0982); Dice 0.3525 (0.4123): 100%|██████████| 541/541 [05:27<00:00,  1.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 25; lr 0.0000126; Loss 0.0982; CCE_loss 0.0982; Dice 0.4123\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 38/38 [00:40<00:00,  1.07s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Val Score: nan, Dice: 0.0, F1: nan, F1_0: nan, F1_1: nan, F1_2: nan, F1_3: nan\n","score: nan\tscore_best: 0\n"]},{"output_type":"stream","name":"stderr","text":["epoch: 26; lr 0.0000126; Loss 0.0771 (0.1000); cce_loss 0.0771 (0.1000); Dice 0.3816 (0.4286): 100%|██████████| 541/541 [05:27<00:00,  1.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 26; lr 0.0000126; Loss 0.1000; CCE_loss 0.1000; Dice 0.4286\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 38/38 [00:40<00:00,  1.06s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Val Score: nan, Dice: 0.0, F1: nan, F1_0: nan, F1_1: nan, F1_2: nan, F1_3: nan\n","score: nan\tscore_best: 0\n"]},{"output_type":"stream","name":"stderr","text":["epoch: 27; lr 0.0000126; Loss 0.0877 (0.0958); cce_loss 0.0877 (0.0958); Dice 0.3417 (0.4208): 100%|██████████| 541/541 [05:28<00:00,  1.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 27; lr 0.0000032; Loss 0.0958; CCE_loss 0.0958; Dice 0.4208\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 38/38 [00:40<00:00,  1.08s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Val Score: nan, Dice: 0.0, F1: nan, F1_0: nan, F1_1: nan, F1_2: nan, F1_3: nan\n","score: nan\tscore_best: 0\n"]},{"output_type":"stream","name":"stderr","text":["epoch: 28; lr 0.0000032; Loss 0.0957 (0.0977); cce_loss 0.0957 (0.0977); Dice 0.4100 (0.4191): 100%|██████████| 541/541 [05:28<00:00,  1.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 28; lr 0.0000063; Loss 0.0977; CCE_loss 0.0977; Dice 0.4191\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 38/38 [00:40<00:00,  1.07s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Val Score: nan, Dice: 0.0, F1: nan, F1_0: nan, F1_1: nan, F1_2: nan, F1_3: nan\n","score: nan\tscore_best: 0\n"]},{"output_type":"stream","name":"stderr","text":["epoch: 29; lr 0.0000063; Loss 0.0969 (0.1021); cce_loss 0.0969 (0.1021); Dice 0.4217 (0.4193): 100%|██████████| 541/541 [05:27<00:00,  1.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 29; lr 0.0000063; Loss 0.1021; CCE_loss 0.1021; Dice 0.4193\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 38/38 [00:40<00:00,  1.07s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Val Score: nan, Dice: 0.0, F1: nan, F1_0: nan, F1_1: nan, F1_2: nan, F1_3: nan\n","score: nan\tscore_best: 0\n","Time: 248.269 min\n"]}],"source":["#model = SeResNext50_Unet_Double().cuda()\n","import ssl\n","ssl._create_default_https_context = ssl._create_unverified_context\n","model = SeResNext50_Unet_2Ssum().cuda()\n","\n","params = model.parameters()\n","\n","optimizer = AdamW(params, lr=0.000202, weight_decay=1e-6)     #0.002\n","\n","#model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\")\n","#model = nn.DataParallel(model).cuda()\n","\n","scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[5, 13, 19, 23, 28, 47, 50, 60, 70, 90, 110, 130, 150, 170, 180, 190], gamma=0.5)\n","#scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[5, 11, 15, 23,  29, 33, 47, 50, 60, 70, 90, 110, 130, 150, 170, 180, 190], gamma=0.5)\n","\n","#snap_to_load = 'res50_cls_cutmixCE1_{}_0_best'.format(seed)\n","#print(\"=> loading checkpoint '{}'\".format(snap_to_load))\n","#checkpoint = torch.load(path.join(models_folder, snap_to_load), map_location='cpu')\n","#loaded_dict = checkpoint['state_dict']\n","#sd = model.state_dict()\n","#for k in model.state_dict():\n","#    if k in loaded_dict and sd[k].size() == loaded_dict[k].size():\n","#        sd[k] = loaded_dict[k]\n","#loaded_dict = sd\n","#model.load_state_dict(loaded_dict)\n","#print(\"loaded checkpoint '{}' (epoch {}, best_score {})\"\n","#        .format(snap_to_load, checkpoint['epoch'], checkpoint['best_score']))\n","#del loaded_dict\n","#del sd\n","#del checkpoint\n","gc.collect()\n","torch.cuda.empty_cache()\n","\n","model = nn.DataParallel(model).cuda()\n","\n","seg_loss = ComboLoss({'dice': 0.5, 'focal': 2.0}, per_image=False).cuda()\n","#wei = [2., 2., 3., 3., 2.]\n","#wei = torch.tensor(wei)\n","ce_loss = nn.CrossEntropyLoss().cuda()\n","seg_lossSeesaw = None#SeesawLoss2().cuda()\n","\n","best_score = 0\n","torch.cuda.empty_cache()\n","for epoch in range(30):\n","    train_epoch(epoch, seg_loss, ce_loss, seg_lossSeesaw, model, optimizer, scheduler, train_data_loader)\n","    if epoch % 2 == 0 and epoch <= 20:\n","        torch.cuda.empty_cache()\n","        best_score = evaluate_val(val_data_loader, best_score, model, snapshot_name, epoch)\n","    if epoch > 20:\n","        torch.cuda.empty_cache()\n","        best_score = evaluate_val(val_data_loader, best_score, model, snapshot_name, epoch)\n","\n","torch.save(model.state_dict(), '/content/drive/MyDrive/Modeling Satelities Images Building Damaged/models/modelBDANet_test_train_2.pth')\n","\n","elapsed = timeit.default_timer() - t0\n","print('Time: {:.3f} min'.format(elapsed / 60))"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"pRg_hj2MH2e7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685503223515,"user_tz":180,"elapsed":65,"user":{"displayName":"Antonio Santos","userId":"03265893617080544823"}},"outputId":"8284a329-1499-4fd8-87fb-fe2f9236290c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":19}],"source":["model.load_state_dict(torch.load('/content/drive/MyDrive/Modeling Satelities Images Building Damaged/models/modelBDANet_test_train_2.pth'))"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["TlRP-duNXnpK","5rmjtBX5T9_W","yUSNtuVeTUwl","pTW3yt84TQMf","N5xl5qEyTN3v","FXa807PbTjxn","Ifa7HjK2FVf3","Jbp9HIBOoO4H"],"machine_shape":"hm","provenance":[],"gpuType":"A100","authorship_tag":"ABX9TyN/U9kFcGnPIo7qYdTUlsPp"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}